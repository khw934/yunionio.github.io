[{"body":"","excerpt":"","ref":"/v3.3/docs/quickstart/","title":"快速开始"},{"body":"功能介绍 云平台支持 Baremetal(物理机) 管理，提供的功能如下:\n  自动化上架: 物理机上架加电启动后，自动注册到云管平台，自动分配BMC IP地址，初始化IPMI账号密码，自动上报物理机硬件配置（CPU、内存、序列号、网卡、磁盘等）\n  自动化装机: 根据配置要求自动配置 RAID，自动分区格式化磁盘，自动部署操作系统镜像，自动初始化操作系统账号密码，自动分配IP地址，可以植入配置文件\n  生命周期管理: 支持物理机自动化开机，关机，重装系统，远程带外管理，卸载操作系统等操作\n  与虚拟机共享镜像: 使用虚拟机镜像部署物理机，便于虚拟机和物理机统一操作系统运行环境\n  API 支持: 以上操作均支持API操作，便于与其他系统的自动化流程集成\n  服务器型号支持: 支持Dell、HP、华为、浪潮、联想、超微等主流x86服务器厂商和机型\n  RAID 控制器支持: LSI MegaRaid, HP Smart Array, LSI MPT2SAS, LSI MPT3SAS, Mrarvell RAID等\n  转换为宿主机: 直接将物理机转换为运行虚拟机的宿主机\n  托管已有服务器： 托管已有并装好系统的物理机\n  服务架构 物理机管理服务架构如下:\n  Baremetal \u003c-\u003e DHCP Relay： 处理 PXE 网络启动\n  DHCP Relay \u003c-\u003e Baremetal Agent:\n 转发 PXE Boot 请求，获取网络启动相关的信息 通过 DHCP 和 TFTP 服务下发 PXE 配置  云平台定制的网络启动小系统(yunionos) kernel 和 initramfs: 运行 SSH 服务，制作 RAID，收集硬件信息等      Baremetal Agent \u003c-\u003e Region Server:\n 通过 Region Server 注册物理机记录 获取网络 IP 地址    Baremetal Agent \u003c-\u003e Baremetal:\n Baremetal 通知 Agent SSH 相关的登录信息 Agent 通过 SSH 配置 Baremetal 的 IPMI Agent 通过 IPMI 控制 Baremetal 开关机等操作 Agent 通过 SSH 执行做 RAID，装机，销毁等操作    Glance Server -\u003e Baremetal: Baremetal 从 Glance server 下载装机镜像\n  在交换机上开启 DHCP Relay 功能(或者使用 DHCP Relay软件)，relay 指向 Baremetal Agent\n 物理机上架通电后，设置 PXE 网络启动，DHCP Relay 会将 PXE Boot 请求转发到 Baremetal Agent，Baremetal Agent 收到 PXE Boot 请求，向 Region Server 注册物理机记录    技术细节 注册物理机 注册物理机有自动注册和手动注册两种方式，如果 Baremetal Agent 开启了自动注册功能，就会自动在云平台创建 baremetal 记录；如果为手动注册方式，就需要先调用物理机创建接口把对应的 PXE 网卡对应的 MAC 地址注册到平台。\n注册的流程如下:\n 物理机 PXE 启动时会发送 DHCP PXE boot 的请求，通过 DHCP Relay 请求会到 Baremetal Agent; Baremetal Agent 从 DHCP 请求中取出网卡 MAC 地址，拿 MAC 地址向 Region Server 过滤物理机记录; Region Server 告诉 Baremetal Agent 改 MAC 地址没有物理机，Baremetal Agent 就会新建记录，并从 Region Server 获取分配对应网段的 IP 地址, 通过内置 DHCP 服务回包给物理机; 物理机 PXE DHCP 请求获得分配的 IP 地址后，会通过 TFTP 从 Baremetal Agent 下载启动引导文件(kernel 和 initramfs)，然后使用 ramdisk 机制进入我们定制的 initramfs 小系统; initramfs 小系统启动后，会启动 sshd 服务，然后修改 root 用户密码，将这些登录信息通知回 Baremetal Agent; Baremetal Agent 收到通知后，记录 ssh 登录的信息，开始进行准备工作; 准备工作包括配置 IPMI，收集硬件信息等，当这些操作完成后，将所有信息上报给 Region Server 完成注册  yunionos 网络启动小系统 yunionos(https://github.com/yunionio/yunionos) 是我们使用 Buildroot 工具定制的用于 PXE 启动和管理物理机的小型 Linux 系统，作用如下:\n 运行 sshd 服务，提供 Baremetal Agent 远程执行命令 包含 LSI MegaRaid, HP Smart Array, LSI MPT2SAS, LSI MPT3SAS, Mrarvell RAID等驱动和工具，用于制作 RAID 包含 ipmitool 和相关 driver，用于配置和调用 IPMI BMC 管理物理机 包含 qemu-img, sgdisk, parted 等磁盘分区工具，用于创建操作系统  SSH 管理 当物理机通过 PXE 进入 yunionos 小系统后会启动 sshd 服务，并将 ssh login 信息通知给 Baremetal Agent，Baremetal Agent 会更新 ssh 相关的登录信息\nRAID 配置 RAID 配置由 Baremetal Agent 根据用户的配置，生成 raid 配置命令，通过 ssh 远程控制 yunionos 在物理机上制作 RAID\n安装操作系统 RAID 做完后，Baremetal Agent 会通过 ssh 远程控制 yunionos 安装操作系统和分区，流程如下:\n 调用 /lib/mos/rootcreate.sh 将系统创建到磁盘:   通过 wget 从 Glance Server 下载用户指定的 image 镜像 通过 qemu-img convert 命名将 image 写入到磁盘  创建好系统后，会根据用户的配置将系统盘 resize 分区 创建其它分区并格式化 Baremetal Agent 进行一些网络，磁盘配置的设置：比如 bonding，ip 设置, /etc/fstab, 改变 hostname 等  开关机 注册好的的物理机会配置好 IPMI, IPMI 相关的信息会记录在数据库，Baremetal Agent 通过 ipmitool 控制开关机\n重装操作系统 类似于安装操作系统，流程上会让安装了操作系统的物理机重新进入 yunionos 小系统，然后重新安装操作系统\n远程访问 Baremetal Agent 通过 ipmitool sol 接口提供串口控制界面\n删除操作系统 对正在运行操作系统的物理机重启进入 PXE 网络启动，进入 yunionos 小系统，调用 /lib/mos/partdestory.sh 销毁磁盘分区和相应的 raid 命令销毁 raid 配置\n","excerpt":"功能介绍 云平台支持 Baremetal(物理机) 管理，提供的功能如下:\n  自动化上架: 物理机上架加电启动后，自动注册到云管平台，自动 …","ref":"/v3.3/docs/howto/baremetal/intro/","title":"介绍"},{"body":"OneCloud 原生提供基于 kvm 的私有云虚拟机管理功能，运行 kvm 虚拟机的机器叫做宿主机，这种宿主机也叫作 “计算节点”，上面会运行管理虚拟机、网络和存储的一系列服务，如何部署并上线宿主机请参考: 安装部署/计算节点。\n宿主机操作 查询 通过 host-list 查询宿主机列表，host-show 查询宿主机详情。\n# 查询 kvm 这种类型的宿主机 $ climc host-list --hypervisor kvm # 查询被禁用的 kvm 宿主机 $ climc host-list --hypervisor kvm --disabled # 查询启用的 kvm 宿主机 $ climc host-list --hypervisor kvm --enabled 启用 kvm 宿主机上线后，默认是禁用的状态，需要启用才能创建虚拟机。\n# 找到禁用的宿主机 $ climc host-list --disabled # 启用 $ climc host-enable \u003chost_id\u003e 禁用 如果完全不想让宿主机创建虚拟机，可以禁用它。\n$ climc host-disable \u003chost_id\u003e ","excerpt":"OneCloud 原生提供基于 kvm 的私有云虚拟机管理功能，运行 kvm 虚拟机的机器叫做宿主机，这种宿主机也叫作 “计算节点”，上面会 …","ref":"/v3.3/docs/howto/host/kvm/","title":"KVM 宿主机"},{"body":"获取镜像 上传镜像之前需要先获取镜像，途径有多种，比如从发行版官网下载用于云平台的镜像，或者自己制作。\n发行版镜像 根据自己对发行版的需要下载发行版镜像，常用的 Linux 发行版会提供云平台虚拟机使用的镜像，地址如下:\n centos: http://cloud.centos.org/centos/7/images/ ubuntu: https://cloud-images.ubuntu.com/  制作镜像 参考: 制作镜像\n上传 下载或者制作完镜像后，使用 climc image-upload 上传到云平台的 glance 服务，下面以下载 CentOS 提供的 CentOS-7-x86_64-GenericCloud-1711 举例:\n# 下载 CentOS-7-x86_64-GenericCloud-1711.qcow2  $ wget http://cloud.centos.org/centos/7/images/CentOS-7-x86_64-GenericCloud-1711.qcow2 # 上传镜像到云平台并名为 CentOS-7-x86_64-GenericCloud-1711.qcow2 $ climc image-upload --format qcow2 --os-type Linux --os-arch x86_64 --standard CentOS-7-x86_64-GenericCloud-1711.qcow2 ./CentOS-7-x86_64-GenericCloud-1711.qcow2 上传时间长短取决于网络环境和镜像大小，上传完成后需要查询镜像的状态，当状态变为 ‘active’ 时，就可以拿来使用了。( 更多的关于镜像的查询参考: 镜像查询 )\n$ climc image-show CentOS-7-x86_64-GenericCloud-1711.qcow2 | grep status | status | active | 上传参数 使用 climc help image-upload 获取各个参数解释。\n","excerpt":"获取镜像 上传镜像之前需要先获取镜像，途径有多种，比如从发行版官网下载用于云平台的镜像，或者自己制作。\n发行版镜像 根据自己对发行版的需要下 …","ref":"/v3.3/docs/howto/image/upload/","title":"上传镜像"},{"body":"云平台的命令行管理工具是 climc, 可以通过该工具向后端各个服务发送API请求, 实现对资源的操控。\n通过快速开始的All in One安装或安装部署章节搭建开源版OneCloud环境时，控制节点都会安装climc，可直接跳过安装climc章节直接查看使用climc章节。\n下面介绍如何在非控制节点上安装climc。\n安装 可以通过 yum 或者源码编译的方式安装climc。\nRPM 安装 添加 yunion 的 yum 源，如果已经添加可以忽略这一步。\n$ cat \u003c\u003cEOF \u003e/etc/yum.repos.d/yunion.repo [yunion] name=Packages for Yunion Multi-Cloud Platform baseurl=https://iso.yunion.cn/yumrepo-3.2 sslverify=0 failovermethod=priority enabled=1 gpgcheck=0 EOF 安装 climc\n$ sudo yum install -y yunion-climc $ ls -alh /opt/yunion/bin/climc -rwxr-xr-x 1 root root 24M Jul 18 19:04 /opt/yunion/bin/climc 源码编译安装 首先需要搭建 go 的开发环境，然后 clone 代码，参考: 开发贡献\n# 编译 climc $ cd $GOPATH/src/yunion.io/x/onecloud $ make cmd/climc # 等待编译完成后，climc 在 _output/bin 目录下 $ ls -alh _output/bin/climc -rwxr-xr-x 1 lzx lzx 25M Jul 15 17:10 _output/bin/climc 可以根据自己的需要，将编译好的 climc 放到对应的目录，或者直接写 alias 对应到 $GOPATH/src/yunion.io/x/onecloud/_output/bin/climc 。\n使用 安装好 climc 后，可以将对应的可执行目录加入到 PATH 环境变量，下面假设 climc 所在的目录是 /opt/yunion/bin 。\n# 根据自己的需要加到 bash 或者 zsh 配置文件里面 $ echo 'export PATH=$PATH:/opt/yunion/bin' \u003e\u003e ~/.bashrc \u0026\u0026 source ~/.bashrc $ climc --help 认证配置 climc 请求云平台后端服务的流程如下:\n 通过配置信息，使用用户名密码从 keystone 获取 token token 中包含了后端服务的 endpoint 地址 climc 将对应资源的 CURD 请求发往所属的后端服务  所以在操作资源前，我们需要通过环境变量告诉 climc 想要操作的云平台和认证信息。\n目前climc支持两种认证方式：\n 通过用户名／密码认证 通过Access Key／Secret认证（从2.11开始支持）  控制节点认证配置 在控制节点上可直接通过以下命令认证配置。\n# 获取环境变量 $ ocadm cluster rcadmin export OS_AUTH_URL=https://192.168.0.246:5000/v3 export OS_USERNAME=sysadmin export OS_PASSWORD=3hV3***84srk export OS_PROJECT_NAME=system export YUNION_INSECURE=true export OS_REGION_NAME=region0 export OS_ENDPOINT_TYPE=publicURL # 认证环境变量 $ source \u003c(ocadm cluster rcadmin) 注意: 如果执行 climc 时出现 Error: Missing OS_AUTH_URL 的错误提示时，请重新执行 source \u003c(ocadm cluster rcadmin) 命令。\n非控制节点认证配置 在非控制节点做认证配置上首先需要在对应的控制节点上获取相关参数，并将认证信息保存到文件中，通过source命令认证配置。\n以下为用户名／密码认证的配置文件模板，通过OS_USERNAME, OS_DOMAIN_NAME, OS_PASSWORD, OS_PROJECT_NAME, OS_PROJECT_DOMAIN等字段指定用户的信息和项目的信息。\n# 在控制节点上获取认证所需要的配置信息。 # ocadm cluster rcadmin export OS_AUTH_URL=https://192.168.0.246:5000/v3 export OS_USERNAME=sysadmin export OS_PASSWORD=3hV3***84srk export OS_PROJECT_NAME=system export YUNION_INSECURE=true export OS_REGION_NAME=region0 export OS_ENDPOINT_TYPE=publicURL # 将认证信息保存到文件中，方便 source 使用 $ cat \u003c\u003cEOF \u003e ~/test_rc_admin # 用户名 export OS_USERNAME=sysadmin # 用户所属域名称(如果为Default域,可以省略) export OS_DOMAIN_NAME=Default # 用户密码 export OS_PASSWORD=*** # 用户所属项目名称 export OS_PROJECT_NAME=system # 项目所属域名称(如果为Default域,可以省略) export OS_PROJECT_DOMAIN=Default # keystone 认证地址 export OS_AUTH_URL=https://192.168.0.246:5000/v3 # 对应的 region export OS_REGION_NAME=Beijing EOF 以下为Access Key/Secret认证的配置文件模板，通过OS_ACCESS_KEY, OS_SECRET_KEY等两个字段指定用户的Access Key/secret。\n# 将认证信息保存到文件中，方便 source 使用 $ cat \u003c\u003cEOF \u003e ~/test_rc_admin # Access Key export OS_ACCESS_KEY=0d184a3c9c484e4c892f4855935e37e7 # Secret export OS_SECRET_KEY=VG***5mUXM= # keystone 认证地址 export OS_AUTH_URL=https://192.168.0.246:5000/v3 # 对应的 region export OS_REGION_NAME=Beijing EOF # 在控制节点上获取用户在一个项目中的Access Key/Secret # 生成 Secret Key $ climc credential-create-aksk +--------+----------------------------------------------+ | Field | Value | +--------+----------------------------------------------+ | expire | 0 | | secret | VGFxZkE3QTd2MmhCbmZkVkJDcFZFaGJYdUQ2c05mUXM= | +--------+----------------------------------------------+ # ID为 Access Key $ climc credential-list +-----------------------+------------+------------+-----------------------+---------+---------+-----------+---------+-----------------------+-------------+--------------+-----------------------+------+-----------------------+----------------------+----------+----------------------+ | blob | can_delete | can_update | created_at | deleted | domain | domain_id | enabled | id | is_emulated | name | project_id | type | update_version | updated_at | user | user_id | +-----------------------+------------+------------+-----------------------+---------+---------+-----------+---------+-----------------------+-------------+--------------+-----------------------+------+-----------------------+----------------------+----------+----------------------+ | {\"expire\":0,\"secret\": | true | true | 2020-06-15T11:43:32.0 | false | Default | default | true | 0d184a3c9c484e4c892f4 | false | --1592221412 | d53ea650bfe144da8ee8f | aksk | 0 | 2020-06-15T11:43:32. | sysadmin | a063d8e2cd584cc48194 | | \"VGFxZkE3QTd2MmhCbmZk | | | 00000Z | | | | | 855935e37e7 | | | 3fba417b904 | | | 000000Z | | 5e7169280435 | | VkJDcFZFaGJYdUQ2c05mU | | | | | | | | | | | | | | | | | | XM=\"} | | | | | | | | | | | | | | | | | +-----------------------+------------+------------+-----------------------+---------+---------+-----------+---------+-----------------------+-------------+--------------+-----------------------+------+-----------------------+----------------------+----------+----------------------+ *** Total: 1 Pages: 1 Limit: 2048 Offset: 0 Page: 1 *** 模板配置完成后，通过以下名称认证环境变量。\n# source 认证环境变量 $ source ~/test_rc_admin # 执行climc。例如，查看虚拟机列表 $ climc server-list 注意: 如果执行 climc 时出现 Error: Missing OS_AUTH_URL 的错误提示时，请 source 或设置认证云平台的环境变量。\n可以通过查看 climc 的版本号来获取构建的信息。\n$ climc --version Yunion API client version: { \"major\": \"0\", \"minor\": \"0\", \"gitVersion\": \"v3.1.9-20200609.1\", \"gitBranch\": \"tags/v3.1.8^0\", \"gitCommit\": \"5591bbec4\", \"gitTreeState\": \"clean\", \"buildDate\": \"2020-06-09T12:00:48Z\", \"goVersion\": \"go1.13.9\", \"compiler\": \"gc\", \"platform\": \"linux/amd64\" } 运行模式 climc 有命令行运行和交互两种运行模式。\n 命令行运行: 执行完对应的资源操作命令就退出，这种模式你知道自己在做什么，并且可以作为 bash function/script 的一部分。  # 删除 server1, server2, server3 for id in server1 server2 server3; do climc server-update --delete enable $id climc server-delete $id done  交互模式: 在 shell 输入 climc，就会进入交互模式，这种模式下有自动补全和参数提示。   子命令语法 云平台有很多资源，对应 climc 的子命令, 比如 climc server-list 中的 server-list 就是子命令，可以查询虚拟机的列表。通用格式如下:\n\u003cResource\u003e-\u003cAction\u003e: Resource 表示资源, Action 表示行为 语法举例:\n server-delete: 删除虚拟机  server 是资源, delete 是行为   host-list: 查询宿主机列表  host 是资源, list 是行为    CRUD 举例:\n C: server-create, disk-create 创建资源 R: server-show, disk-list 查询资源 U: server-update, host-update 更新资源 D: server-delete, image-delete 删除资源  行为举例:\n- 中的 Action 会对应资源的操作，不同的资源会根据可进行的操作进行命名。\n server-migrate: migrate 表示迁移虚拟机 server-change-config: change-config 表示调整虚拟机配置 host-ipmi: ipmi 表示查询宿主机的 IPMI 信息  想要知道资源有哪些操作，可以进入交互模式补全查询。\n使用帮助 help climc 的子命令有很多参数，参数分为必填参数和可选参数，使用 climc help \u003csubcommand\u003e 这种格式，help 子命令会获取  提供的参数和各个参数的解释。\n比如我要查看 image-upload 命令的参数和解释:\n$ climc help image-upload ... Upload a local image Positional arguments: \u003cNAME\u003e Image Name \u003cFILE\u003e The local image filename to Upload Optional arguments: [--private] Make image private [--format {raw,qcow2,iso,vmdk,docker,vhd}] Image format [--protected] ... 高级过滤 filter TODO\nDebug 模式 如果想要知道 climc 操作资源时究竟和服务端发生了哪些请求，可以在子命令前面使用 –debug 参数，使用方式如下:\nclimc --debug \u003cResource\u003e-\u003cAction\u003e 加上 –debug 参数后，终端会有彩色的输出提示，比如 climc --debug server-list 输出如下:\n其中 CURL 部分是可以直接粘贴出来在命令行执行的。\n颜色约定  Request 使用黄色 CURL 使用蓝绿色 根据状态码显示不同颜色，可参考代码: https://github.com/yunionio/onecloud/blob/master/pkg/util/httputils/httputils.go#L234  在bash或zsh下的命令行参数提示补全 climc支持bash或zsh的命令行参数自动提示补全。\n下面以bash为例说明，在使用climc之前，执行如下命令初始化环境。\n# 启用bash命令行参数自动补全 source \u003c(climc --completion bash) 之后在bash中可以在输入climc命令后，通过tab获得命令行参数的提示。\n为了方便使用，推荐将该命令放到$HOME/.bashrc或$HOME/.bash_profile中自动初始化环境。\n","excerpt":"云平台的命令行管理工具是 climc, 可以通过该工具向后端各个服务发送API请求, 实现对资源的操控。\n通过快速开始的All in One …","ref":"/v3.3/docs/howto/climc/","title":"命令行工具"},{"body":"前提 注意 本章内容是通过部署工具快速搭建 OneCloud 服务，如果想了解部署的细节或者部署高可用环境请参考: 安装部署 。  环境准备 OneCloud 相关的组件运行在 kubernetes 之上。\n服务器配置要求  操作系统: Centos 7.6 最低配置要求: CPU 4核, 内存 8G, 存储 100G  以下为待部署机器的环境:\n   IP 登录用户 操作系统     10.168.26.216 root Centos 7.6    提示  10.168.26.216 是本次测试环境 ip，请根据自己的环境做相应修改。\n  OneCloud相关软件依赖  数据库: mariadb Ver 15.1 Distrib 5.5.56-MariaDB docker: ce-19.03.9 kubernetes: v1.15.8  本地环境配置要求 本地环境即用户进行实际操作部署的环境。本次测试的本地环境为MAC操作系统的笔记本，也可在待部署机器上进行操作。\n ssh: 开启 ssh 免密登录 本地环境安装部署 ansbile，Windows操作系统不支持安装 ansible  配置 ssh 免密登录 # 生成本机的 ssh 秘钥 (如果本地已有 ~/.ssh/id_rsa.pub 则跳过此步骤) $ ssh-keygen # 将生成的 ~/.ssh/id_rsa.pub 公钥拷贝到待部署机器 $ ssh-copy-id -i ~/.ssh/id_rsa.pub root@10.168.26.216 # 尝试免密登录待部署机器，应该不需要输入登录密码即可拿到部署机器的 hostname $ ssh root@10.168.26.216 \"hostname\" 开始部署 部署的工具是 https://github.com/yunionio/ocboot , 然后根据需要部署机器的配置， 利用 ansbile 远程登录到待部署的机器安装配置 onecloud 服务，以下操作都在本地环境上进行操作。操作步骤如下:\n下载 ocboot # 本地安装 ansible $ pip install ansible # 下载 ocboot 工具到本地 $ git clone -b release/3.3 https://github.com/yunionio/ocboot \u0026\u0026 cd ./ocboot 编写部署配置 # 编写 config-allinone.yml 文件 $ cat \u003c\u003cEOF \u003e./config-allinone.yml # mariadb_node 表示需要部署 mariadb 服务的节点 mariadb_node: # 待部署节点 ip hostname: 10.168.26.216 # 待部署节点登录用户 user: root # mariadb 的用户 db_user: root # mariadb 用户密码 db_password: your-sql-password # primary_master_node 表示运行 k8s 和 onecloud 服务的节点 primary_master_node: hostname: 10.168.26.216 user: root # 数据库连接地址 db_host: 10.168.26.216 # 数据库用户 db_user: root # 数据库密码 db_password: your-sql-password # k8s 控制节点的 ip controlplane_host: 10.168.26.216 # k8s 控制节点的端口 controlplane_port: \"6443\" # onecloud 登录用户 onecloud_user: admin # onecloud 登录用户密码 onecloud_user_password: admin@123 # 该节点作为 OneCloud 私有云计算节点 as_host: true EOF 开始部署 当填写完 config-allinone.yml 部署配置文件后，便可以执行 ocboot 里面的 ./run.py ./config-allinone.yml 部署集群了。\n# 开始部署 $ ./run.py ./config-allinone.yml .... # 部署完成后会有如下输出，表示运行成功 # 浏览器打开 https://10.168.26.216 # 使用 admin/admin@123 用户密码登录就能访问前端界面 Initialized successfully! Web page: https://10.168.26.216 User: admin Password: admin@123 然后用浏览器访问 https://10.168.26.216 ，用户名输入 admin，密码输入 admin@123 就会进入 OneCloud 的界面。\nFAQ 1. 在 All in One 中找不到虚拟机界面？ All in One 部署的节点会部署 OneCloud host 计算服务，作为宿主机，具有创建和管理私有云虚拟机的能力。没有虚拟机界面应该是 OneCloud 环境中没有启用宿主机。\n请到 管理后台 界面，点击 主机/基础资源/宿主机 查看宿主机列表，启用相应的宿主机，刷新界面就会出现虚拟机界面。\n注意 如果要使用 OneCloud 私有云虚拟机，需要宿主机使用 OneCloud 编译的内核，可使用以下命令查看宿主机是否使用 OneCloud 内核(包含 yn 关键字)。\n# 查看是否使用 yn 内核 $ uname -a | grep yn Linux office-controller 3.10.0-1062.4.3.el7.yn20191203.x86_64 # 如果内核不是带有 yn 关键字的版本，可能是第一次使用 ocboot 安装，重启即可进入 yn 内核 $ reboot   2. 如何导入公有云或者其它私有云平台资源？ 在 多云管理 菜单，选择 云账号 并新建，根据自己的需求填写对应云平台的认证信息，配置完云账号后 OneCloud 服务就会同步相应云平台的资源，同步完成后即可在前端查看。\n3. 其它问题？ 其它问题欢迎在 OneCloud github issues 界面提交: https://github.com/yunionio/onecloud/issues , 我们会尽快回复。\n","excerpt":"前提 注意 本章内容是通过部署工具快速搭建 OneCloud 服务，如果想了解部署的细节或者部署高可用环境请参考: 安装部署 。 …","ref":"/v3.3/docs/quickstart/allinone/","title":"All in One 安装"},{"body":"前提 注意 本章内容是方便快速体验OneCloud, 通过MiniKube快速搭建OneCloud服务，如果想了解部署的细节或者部署高可用环境请参考: 安装部署 。  环境准备 OneCloud 相关的组件运行在MiniKube之上，环境以及相关的软件依赖如下:\n 操作系统: Centos 7.6 最低配置要求: CPU 4核, 内存 8G, 存储 100G 数据库: mariadb Ver 15.1 Distrib 5.5.56-MariaDB  安装MySQL开启远程访问\n# 此密码为上面设置的 MySQL root 密码，为了方便，只读账号也使用此密码 $ MYSQL_PASSWD='your-sql-passwd' $ mysql -uroot -p$MYSQL_PASSWD -e \"GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY '$MYSQL_PASSWD' WITH GRANT OPTION;FLUSH PRIVILEGES\" 开始部署 启动minikube 下载minikue/kubectl, 并启动minikube集群, 具体请参考： https://kubernetes.io/docs/tasks/tools/install-minikube/\nminikube config -p onecloud set memory 8192 minikube start --nodes 2 -p onecloud minikube dashboard -p onecloud 部署local-path-storage 参考：https://github.com/rancher/local-path-provisioner, 在minikube部署local-path-storage\nwget https://raw.githubusercontent.com/rancher/local-path-provisioner/master/deploy/local-path-storage.yaml -O local-path-storage.yaml kubectl apply -f local-path-storage.yaml 部署onecloud k8s operator onecloud k8s operator地址： https://github.com/yunionio/onecloud-operator\nwget https://raw.githubusercontent.com/yunionio/onecloud-operator/master/manifests/onecloud-operator.yaml -O onecloud-operator.yaml kubectl apply -f onecloud-operator.yaml 部署onecloud 集群 wget https://raw.githubusercontent.com/yunionio/onecloud-operator/master/manifests/example-onecloud-cluster.yaml -O onecloud-cluster.yaml vim onecloud-cluster.yaml  修改onecloud-cluster.yaml mysql相关配额   host: $MYSQL_HOST port: $MYSQL_PORT username: \"$MYSQL_USERNAME\" password: \"$MYSQL_PASSWD\"  其他集群配置请参考： OnecloudClusterSpec:: 启动onecloud集群  kubectl apply -f onecloud-cluster.yaml 打开K8s Dashboard确认相关服务正常启动完成\n创建账号登录WebUI 创建账号\nkubectl exec -n onecloud `kubectl -n onecloud get pods | grep \"example-onecloud-cluster-climc\"| cut -f1 -d\" \"` -c climc -i -t -- /bin/bash -il $ climc user-create demo --password demo123A --system-account --enabled 登陆webUI\nkubectl -n onecloud port-forward `kubectl -n onecloud get pods | grep \"example-onecloud-cluster-web\"| cut -f1 -d\" \"` 9999:443 --address=0.0.0.0 打开浏览器：https://localhost:9999\n待解决的问题 4类Pod启动失败，问题还在分析中，但不影响体验onecloud\n example-onecloud-cluster-notify example-onecloud-cluster-host-deployer example-onecloud-cluster-monitor example-onecloud-cluster-autoupdate  集群清理 kubectl delete -f onecloud-cluster.yaml kubectl delete -f onecloud-operator.yaml kubectl delete -f local-path-storage.yaml minikube -p onecloud stop ","excerpt":"前提 注意 本章内容是方便快速体验OneCloud, 通过MiniKube快速搭建OneCloud服务，如果想了解部署的细节或者部署高可用环 …","ref":"/v3.3/docs/quickstart/minikube/","title":"MiniKube 安装"},{"body":"","excerpt":"","ref":"/v3.3/docs/setup/","title":"安装部署"},{"body":"OneCloud 目前仅支持在 Centos 7 上运行，待部署组件/服务如下:\n   服务组件 用途 安装方式 运行方式     mariadb 关系型数据库 rpm systemd   docker 容器运行时 rpm systemd   kubelet 管理 kubernetes pod rpm systemd   keystone 认证服务 k8s deployment container   region api 控制器 k8s deployment container   scheduler 调度服务 k8s deployment container   glance 镜像存储 k8s deployment container   webconsole 虚拟机访问界面 k8s deployment container   influxdb 监控数据库 k8s deployment container   host 管理虚拟机 k8s daemonset container   sdnagent 管理虚拟机网络 rpm systemd   baremetal-agent 管理物理机 k8s deployment container   climc 命令行工具 rpm shell   ocadm 部署服务管理工具 rpm shell    其中 host 和 baremetal-agent 可以根据需求选择性部署:\n 管理 kvm 虚拟机: 部署 host 服务 管理物理机: 部署 baremetal-agent 服务  ","excerpt":"OneCloud 目前仅支持在 Centos 7 上运行，待部署组件/服务如下: …","ref":"/v3.3/docs/setup/intro/","title":"组件概览"},{"body":"  镜像(image): 是用于新建云服务器(虚拟机)、裸金属(物理机)使用的模板文件，常用类型为 qcow2, vmdk, raw, vhd, iso。\n  镜像服务(glance): 云平台的镜像服务叫做 glance，用于存储转换用户上传或外部导入的镜像，提供下载功能。\n  缓存镜像(cached-image): 创建公/私有云虚拟机时，可以直接使用各个云平台已有的镜像，这些镜像不会存储在 glance，云平台只是保存元信息，创建机器时会直接使用。\n  image 和 cached-image 两种资源的区别如下：\n image: glance 管理的镜像，由用户上传或者外部导入; cached-image:  包括公有云和其他私有云的镜像，不由 glance 管理，一般在创建 OneCloud 之外的公/私有云主机的时候用到; 不提供创建接口，只能查询，刷新和删除;    ","excerpt":"  镜像(image): 是用于新建云服务器(虚拟机)、裸金属(物理机)使用的模板文件，常用类型为 qcow2, vmdk, raw, …","ref":"/v3.3/docs/howto/image/","title":"镜像"},{"body":"在部署生产可用的 kubernetes 集群之前，需要先部署 LoadBalancer 环境，这里使用 keepalived + haproxy 的方式实现负载均衡和高可用。\n环境说明 单独拿两个节点部署 keepalived 和 haproxy 作为后端 kubernetes 控制平面的负载均衡器，拓扑结构如下:\n两个节点上面分别部署 keepalived 和 haproxy 组成负载均衡集群，haproxy 的 backend 为后端的 kubernetes control plane node，vip(虚ip) 在这两个节点之间漂移形成高可用。\n另外 OneCloud 服务使用 Mariadb，如果没有专门的数据库集群，可以单独拿两个节点部署 Mariadb 高可用。参考 部署 DB HA 环境 。\n部署 keepalived 的主要作用是为 haproxy 提供 vip，在2个 haproxy 实例之间提供主备，降低当其中一个haproxy失效的时对服务的影响。\n部署配置 keepalived 设置相关的环境变量，根据不同的环境自行配置。\n# keepalived vip 地址 export K8SHA_VIP=10.168.222.18 # keepalived auth toke export K8SHA_KA_AUTH=412f7dc3bfed32194d1600c483e10ad1d # keepalived network interface export K8SHA_NETIF=eth0 设置 sysctl 选项\n$ cat \u003c\u003cEOF \u003e\u003e/etc/sysctl.conf net.ipv4.ip_forward = 1 net.ipv4.ip_nonlocal_bind = 1 EOF $ sysctl -p 安装 keepalived\n$ yum install -y keepalived 添加配置\n$ cat \u003c\u003cEOF \u003e/etc/keepalived/keepalived.conf ! Configuration File for keepalived global_defs { router_id LVS_DEVEL } vrrp_script check_haproxy { script \"pidof haproxy\" interval 3 weight -2 fall 10 rise 2 } vrrp_instance VI_1 { state MASTER interface $K8SHA_NETIF virtual_router_id 51 priority 250 advert_int 1 authentication { auth_type PASS auth_pass $K8SHA_KA_AUTH } virtual_ipaddress { $K8SHA_VIP } track_script { check_haproxy } } EOF 启动 keepalived\n$ systemctl enable --now keepalived $ ip addr show $K8SHA_NETIF 2: eth0: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1500 qdisc mq state UP qlen 1000 link/ether 00:22:ff:95:87:f7 brd ff:ff:ff:ff:ff:ff inet 10.168.222.189/24 brd 10.168.222.255 scope global eth0 valid_lft forever preferred_lft forever inet 10.168.222.18/32 scope global eth0 valid_lft forever preferred_lft forever inet6 fe80::222:ffff:fe95:87f7/64 scope link valid_lft forever preferred_lft forever 部署配置 haproxy 此处的 haproxy 为 apiserver 提供反向代理，haproxy 将所有请求轮询转发到每个master节点上。\n系统配置\nexport K8S_MASTER0=10.168.222.218 export K8S_MASTER1=10.168.222.197 export K8S_MASTER2=10.168.222.207 安装 haproxy\n$ yum install -y haproxy 配置 haproxy\n$ cat \u003c\u003cEOF \u003e/etc/haproxy/haproxy.cfg #--------------------------------------------------------------------- # Global settings #--------------------------------------------------------------------- global # to have these messages end up in /var/log/haproxy.log you will # need to: # # 1) configure syslog to accept network log events. This is done # by adding the '-r' option to the SYSLOGD_OPTIONS in # /etc/sysconfig/syslog # # 2) configure local2 events to go to the /var/log/haproxy.log # file. A line like the following can be added to # /etc/sysconfig/syslog # # local2.* /var/log/haproxy.log # log 127.0.0.1 local2 chroot /var/lib/haproxy pidfile /var/run/haproxy.pid maxconn 4000 user haproxy group haproxy daemon # turn on stats unix socket stats socket /var/lib/haproxy/stats #--------------------------------------------------------------------- # common defaults that all the 'listen' and 'backend' sections will # use if not designated in their block #--------------------------------------------------------------------- defaults mode http log global option httplog option dontlognull option http-server-close option forwardfor except 127.0.0.0/8 option redispatch retries 3 timeout http-request 10s timeout queue 1m timeout connect 10s timeout client 1m timeout server 1m timeout http-keep-alive 10s timeout check 10s maxconn 3000 #--------------------------------------------------------------------- # kubernetes apiserver frontend which proxys to the backends #--------------------------------------------------------------------- frontend kubernetes-apiserver mode tcp bind *:6443 option tcplog default_backend kubernetes-apiserver #--------------------------------------------------------------------- # round robin balancing between the various backends #--------------------------------------------------------------------- backend kubernetes-apiserver mode tcp balance roundrobin server master-0 $K8S_MASTER0:6443 check server master-1 $K8S_MASTER1:6443 check server master-2 $K8S_MASTER2:6443 check #--------------------------------------------------------------------- # collection haproxy statistics message #--------------------------------------------------------------------- listen stats bind *:1080 stats auth admin:awesomePassword stats refresh 5s stats realm HAProxy\\ Statistics stats uri /admin?stats EOF 启动并检测服务\n$ systemctl enable haproxy.service --now $ systemctl status haproxy.service $ netstat -tulnp | egrep '6443|1080' tcp 0 0 0.0.0.0:6443 0.0.0.0:* LISTEN 10033/haproxy tcp 0 0 0.0.0.0:1080 0.0.0.0:* LISTEN 10033/haproxy 部署 kubernetes 集群 参考 部署集群 。\n","excerpt":"在部署生产可用的 kubernetes 集群之前，需要先部署 LoadBalancer 环境，这里使用 keepalived + …","ref":"/v3.3/docs/setup/controlplane-ha/","title":"部署 HA 环境"},{"body":"","excerpt":"","ref":"/v3.3/docs/contribute/","title":"开发相关"},{"body":"安装 Go Golang 版本要求 1.12 以上\n安装go环境参考: Install doc\n安装 ceph 依赖 On rpm based systems (dnf, yum, etc):\nsudo rpm --import https://download.ceph.com/keys/release.asc sudo yum install -y https://download.ceph.com/rpm-luminous/el7/noarch/ceph-release-1-1.el7.noarch.rpm sudo yum install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm sudo yum install -y libcephfs-devel librbd-devel librados-devel On debian systems (apt):\nwget -q -O- 'https://download.ceph.com/keys/release.asc' | sudo apt-key add - echo deb https://download.ceph.com/debian-luminous/ $(lsb_release -sc) main | sudo tee /etc/apt/sources.list.d/ceph.list apt-get update \u0026\u0026 apt-get install -y libcephfs-dev librbd-dev librados-dev 编译 onecloud 组件 Fork 仓库 访问 https://github.com/yunionio/onecloud ，将仓库 fork 到自己的 github 用户下。\nClone 源码 git clone 前确保 GOPATH 等环境变量已经设置好，clone 你自己 fork 的仓库\n$ git clone https://github.com/\u003cyour_name\u003e/onecloud $GOPATH/src/yunion.io/x/onecloud $ cd $GOPATH/src/yunion.io/x/onecloud $ git remote add upstream https://github.com/yunionio/onecloud 编译 # 编译所有组件 $ make # cmd 目录下面存放着所有的组件: $ ls cmd ... ansibleserver climc glance keystone qcloudcli ucloudcli awscli cloudir host lbagent region webconsole # 可以编译cmd下制定的组件，比如：编译 region 和 host 组件 $ make cmd/region cmd/host # 查看编译好的二进制文件 $ ls _output/bin region host 本地开发调试 3.0 版本后我们的服务都已经容器化运行在 k8s 集群中，快速开发调试并不方便。 通过Telepresence 提供远程k8s上下文，可以在本地开发调试。\n安装 确保有一个已部署的onecloud k8s集群，参考安装部署。 这里介绍Centos7的本地环境安装，其他发行版可参考官方文档：Installing Telepresence。\n 不建议k8s集群的部署和开发在同一个环境，使用Telepresence会有端口冲突。\n # 安装依赖 $ yum install -y python3 sshfs conntrack iptables torsocks sshuttle sudo yum-utils # 安装 kubectl 用于连接 k8s 集群 $ cat \u003c\u003cEOF \u003e/etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=0 repo_gpgcheck=0 gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF $ yum install -y kubectl-1.15.8-0 # 需要自行配置kubctl config # 测试kubctl可以访问之前部署的k8s集群 $ kubctl version # 源码安装 telepresence 到 /usr/local/bin/telepresence $ git clone https://github.com/telepresenceio/telepresence $ cd telepresence $ sudo env PREFIX=/usr/local ./install.sh 使用 利用 telepresence 本地连通远端 k8s 的特性，我们就可以做到在本地编译运行 region，keystone 等服务，同时又能访问远端 k8s 其它服务的环境。\n比如以下是本地编译运行 region 服务的流程：\n# 切换到 onecloud 代码目录 $ cd $GOPATH/src/yunion.io/x/onecloud # 编译 region 服务 $ make cmd/region # 使用 telepresence 替换 k8s 里面的 default-region deployment # 该命令在 k8s 集群中启动一个 deployment 替换掉原来的 default-regoin # 然后把流量的访问导向本地 # 如果想要使用特定的 shell，比如 zsh，可以在后面加上\"--run /bin/zsh\" $ telepresence --swap-deployment default-region --namespace onecloud 到这里已经进入到 telepresence 隔离的 namespace 里面了， $TELEPRESENCE_ROOT 这个目录 是通过 sshfs 挂载的远端 k8s pod 的文件系统。 接下来我们就可以在这个 namespace 里面运行 region 服务了：\n# 设置 max_user_namespaces $ cat /proc/sys/user/max_user_namespaces 0 # 如果 max_user_namespaces 为 0，需要设置下 user_namespaces $ echo 640 \u003e /proc/sys/user/max_user_namespaces # 启动一个新的 namespace , 但不共享 mount namespace，这样接下来的 mount bind 操作就不会影响到宿主机 $ unshare --map-root-user --mount # bind k8s /var/run/secrets $ mount --bind $TELEPRESENCE_ROOT/var/run /var/run $ ls /var/run/ secrets # bind onecloud config $ mkdir /etc/yunion $ mount --bind $TELEPRESENCE_ROOT/etc/yunion /etc/yunion $ ls /etc/yunion/ pki region.conf # 启动 region 服务 $ ./_output/bin/region --config /etc/yunion/region.conf # 这个时候如果我们在外部调用 climc $ climc server-list # 就会发现相关的请求已经被转发到本地开发机启动 region 服务了 更多用法，以及 telepresence 的原理请参考官方文档。\n开发流程  从 master checkout 出 feature 或者 bugfix 分支  # checkout 新分支 $ git fetch upstream --tags $ git checkout -b feature/implement-x upstream/master  在新的分支上进行开发 开发完成后，进行提交PR前的准备操作  $ git fetch upstream # 同步远程 upstream master 代码 $ git rebase upstream/master # 有冲突则解决冲突 $ git push origin feature/implement-x # push 分支到自己的 repo  在GitHub的Web界面完成提交PR的流程   提完 PR 后请求相关开发人员 review，并设置Labels来表明提交的代码属于哪一个模块或者哪几个模块   或者通过添加评论的方式来完成上一步；评论 “/cc” 并 @ 相关人员完成设置reviewer，评论/area 并填写label完成设置Labels  ​\t所有Label都可以在issues——Labels下查询到，带area/前缀的Label均可以使用评论\"/area\"的形式添加\n 如果是 bugfix 或者需要合并到之前 release 分支的 feature PR，需要额外使用脚本将此PR cherry-pick 到对应的 release 分支  # 自行下载安装 github 的 cli 工具：https://github.com/github/hub # OSX 使用: brew install hub # Debian: sudo apt install hub # 二进制安装: https://github.com/github/hub/releases # 设置github的用户名 $ export GITHUB_USER=\u003cyour_username\u003e # 使用脚本自动 cherry-pick PR 到 release 分支 # 比如现在有一个提交的PR的编号为8，要把它合并到 release/2.8.0 $ ./scripts/cherry_pick_pull.sh upstream/release/2.8.0 8 # cherry pick 可能会出现冲突，冲突时开另外一个 terminal，解决好冲突，再输入 'y' 进行提交 $ git add xxx # 解决完冲突后 $ git am --continue # 回到执行 cherry-pick 脚本的 terminal 输入 'y' 即可 去 upstream 的 PR 页面, 就能看到自动生成的 cherry-pick PR，上面操作的PR的标题前缀就应该为：Automated cherry pick of #8，然后重复 PR review 流程合并到 release\n","excerpt":"安装 Go Golang 版本要求 1.12 以上\n安装go环境参考: Install doc\n安装 ceph 依赖 On rpm …","ref":"/v3.3/docs/contribute/contrib/","title":"开发贡献"},{"body":"OneCloud 服务使用 Mariadb，这里使用 keepalived 和 Mariadb 的主主复制功能来实现 DB 的高可用。\n部署 keepalived 的主要作用是为 Mariadb 提供 vip，在2个 Mariadb 实例之间切换，不间断的提供服务。\n部署配置 Mariadb 主主复制 安装并启动 Mariadb\n$ yum install -y mariadb-server $ systemctl enable --now mariadb 运行 Mariadb 安全配置向导，设置密码等\n$ mysql_secure_installation ... ... Change the root password? [Y/n] y New password: Re-enter new password: Password updated successfully! Reloading privilege tables.. ... Success! ... ... Remove anonymous users? [Y/n] y ... Success! ... ... Disallow root login remotely? [Y/n] y ... Success! ... ... Remove test database and access to it? [Y/n] y - Dropping test database... ... Success! - Removing privileges on test database... ... Success! ... ... Reload privilege tables now? [Y/n] y ... Success! ... ... 修改 Mariadb 配置文件，准备配置主主复制\n# 主节点 $ cat \u003c\u003cEOF \u003e /etc/my.cnf [mysqld] datadir=/var/lib/mysql socket=/var/lib/mysql/mysql.sock # Disabling symbolic-links is recommended to prevent assorted security risks symbolic-links=0 # Settings user and group are ignored when systemd is used. # If you need to run mysqld under a different user or group, # customize your systemd unit file for mariadb according to the # instructions in http://fedoraproject.org/wiki/Systemd # skip domain name resolve skip_name_resolve # auto delete binlog older than 30 days expire_logs_days=30 innodb_file_per_table=ON max_connections = 300 server-id = 1 auto_increment_offset = 1 auto_increment_increment = 2 log-bin = mysql-bin binlog-format = row log-slave-updates max_binlog_size = 1G replicate-ignore-db = information_schema replicate-ignore-db = performance_schema max_connections = 1000 max_connect_errors = 0 max_allowed_packet = 1G slave-net-timeout=10 master-retry-count=0 slow_query_log = 1 long_query_time = 2 slow_query_log_file = /var/log/mariadb/slow-query.log [mysql] no-auto-rehash [mysqld_safe] log-error=/var/log/mariadb/mariadb.log pid-file=/var/run/mariadb/mariadb.pid # # include all files from the config directory # !includedir /etc/my.cnf.d EOF # 备节点 $ cat \u003c\u003cEOF \u003e /etc/my.cnf [mysqld] datadir=/var/lib/mysql socket=/var/lib/mysql/mysql.sock # Disabling symbolic-links is recommended to prevent assorted security risks symbolic-links=0 # Settings user and group are ignored when systemd is used. # If you need to run mysqld under a different user or group, # customize your systemd unit file for mariadb according to the # instructions in http://fedoraproject.org/wiki/Systemd # skip domain name resolve skip_name_resolve # auto delete binlog older than 30 days expire_logs_days=30 innodb_file_per_table=ON max_connections = 300 server-id = 2 auto_increment_offset = 2 auto_increment_increment = 2 log-bin = mysql-bin binlog-format = row log-slave-updates max_binlog_size = 1G replicate-ignore-db = information_schema replicate-ignore-db = performance_schema max_connections = 1000 max_connect_errors = 0 max_allowed_packet = 1G slave-net-timeout=10 master-retry-count=0 slow_query_log = 1 long_query_time = 2 slow_query_log_file = /var/log/mariadb/slow-query.log [mysql] no-auto-rehash [mysqld_safe] log-error=/var/log/mariadb/mariadb.log pid-file=/var/run/mariadb/mariadb.pid # # include all files from the config directory # !includedir /etc/my.cnf.d EOF # 重启服务 $ systemctl restart mariadb 主节点创建只读账号，导出全部数据，导入备节点。记录binlog日志文件名和position。\n# 以下命令在主节点执行 # 此密码为上面设置的 Mariadb root 密码，为了方便，只读账号也使用此密码 $ MYSQL_PASSWD='your-sql-passwd' # 开启 Mariadb 的远程访问 $ mysql -uroot -p$MYSQL_PASSWD -e \"GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY '$MYSQL_PASSWD' WITH GRANT OPTION;FLUSH PRIVILEGES\" # 创建只读账号 $ mysql -u root -p$MYSQL_PASSWD -e \"GRANT REPLICATION SLAVE ON *.* TO repl@'%' IDENTIFIED BY '$MYSQL_PASSWD';FLUSH PRIVILEGES\" # \u0008示例是全新安装的 Mariadb ，还没有使用。如果是正在使用的数据库做主主复制，需要锁表后再导出数据 $ mysql -uroot -p$MYSQL_PASSWD -e \"SHOW PROCESSLIST\" +----+------+-----------+------+---------+------+-------+------------------+----------+ | Id | User | Host | db | Command | Time | State | Info | Progress | +----+------+-----------+------+---------+------+-------+------------------+----------+ | 4 | root | localhost | NULL | Query | 0 | NULL | SHOW PROCESSLIST | 0.000 | +----+------+-----------+------+---------+------+-------+------------------+----------+ # 记录binlog日志文件名和position $ mysql -u root -p$MYSQL_PASSWD -e \"SHOW MASTER STATUS\\G\" *************************** 1. row *************************** File: mysql-bin.000001 Position: 2023 Binlog_Do_DB: Binlog_Ignore_DB: # 导出全部数据 $ mysqldump --all-databases -p$MYSQL_PASSWD \u003e alldb.db # 拷贝 alldb.db 到备节点 $ scp alldb.db db2:/root/ # 以下命令在备节点执行 # 此密码为上面设置的 Mariadb root 密码 $ MYSQL_PASSWD='your-sql-passwd' # 导入主节点导出的数据 mysql -u root -p$MYSQL_PASSWD \u003c alldb.db # 重载权限 mysql -u root -p$MYSQL_PASSWD -e \"FLUSH PRIVILEGES\" # 记录binlog日志文件名和position mysql -u root -p$MYSQL_PASSWD -e \"SHOW MASTER STATUS\\G\" *************************** 1. row *************************** File: mysql-bin.000001 Position: 509778 Binlog_Do_DB: Binlog_Ignore_DB: 设置主主复制\n# 以下命令在主节点执行 # 修改MASTER_HOST为备节点IP，修改MASTER_LOG_FILE和MASTER_LOG_POS为上面备节点记录的信息 mysql -u root -p$MYSQL_PASSWD -e \"CHANGE MASTER TO MASTER_HOST='192.168.199.99',MASTER_USER='repl',MASTER_PASSWORD='$MYSQL_PASSWD',MASTER_PORT=3306,MASTER_LOG_FILE='mysql-bin.000001',MASTER_LOG_POS=509778,MASTER_CONNECT_RETRY=2;START SLAVE\" # 以下命令在备节点执行 # 修改MASTER_HOST为主节点IP，修改MASTER_LOG_FILE和MASTER_LOG_POS为上面主节点记录的信息 mysql -u root -p$MYSQL_PASSWD -e \"CHANGE MASTER TO MASTER_HOST='192.168.199.98',MASTER_USER='repl',MASTER_PASSWORD='$MYSQL_PASSWD',MASTER_PORT=3306,MASTER_LOG_FILE='mysql-bin.000001',MASTER_LOG_POS=2023,MASTER_CONNECT_RETRY=2;START SLAVE\" # 主备都执行，验证同步状态，都输出2个 Yes 表示正常 mysql -u root -p$MYSQL_PASSWD -e \"SHOW SLAVE STATUS\\G\" | grep Running Slave_IO_Running: Yes Slave_SQL_Running: Yes 至此，DB 主主复制部署完成，可以测试在任一节点进行数据库操作，另一节点验证。不过对外提供服务还是需要通过 vip，不然发生切换还需要业务端切换 ip，下面配置 keepalived 对外提供服务。\n部署配置 keepalived 设置相关的环境变量，根据不同的环境自行配置。\n# keepalived vip 地址 export DB_VIP=192.168.199.97 # keepalived auth toke export DBHA_KA_AUTH=onecloud # keepalived network interface export DB_NETIF=eth0 设置 sysctl 选项\n$ cat \u003c\u003cEOF \u003e\u003e/etc/sysctl.conf net.ipv4.ip_forward = 1 net.ipv4.ip_nonlocal_bind = 1 EOF $ sysctl -p 安装 keepalived nc\n$ yum install -y keepalived nc 添加配置\n# 请确保 virtual_router_id 不会和局域网内的其他 keepalived 集群冲突 $ cat \u003c\u003cEOF \u003e/etc/keepalived/keepalived.conf global_defs { router_id onecloud } vrrp_script chk_mysql { script \"/etc/keepalived/chk_mysql\" interval 1 } vrrp_instance VI_1 { state MASTER interface $DB_NETIF virtual_router_id 99 priority 100 advert_int 1 nopreempt authentication { auth_type PASS auth_pass $DBHA_KA_AUTH } track_script { chk_mysql } virtual_ipaddress { $DB_VIP } } EOF $ cat \u003c\u003cEOF \u003e /etc/keepalived/chk_mysql #!/bin/bash echo | nc 127.0.0.1 3306 \u0026\u003e/dev/null EOF $ chmod +x /etc/keepalived/chk_mysql 启动 keepalived\n$ systemctl enable --now keepalived $ ip addr show $DB_NETIF 2: eth0: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:22:cf:40:1e:29 brd ff:ff:ff:ff:ff:ff inet 192.168.199.99/24 brd 192.168.199.255 scope global dynamic eth0 valid_lft 100651906sec preferred_lft 100651906sec inet 192.168.199.97/32 scope global eth0 valid_lft forever preferred_lft forever inet6 fe80::222:cfff:fe40:1e29/64 scope link valid_lft forever preferred_lft forever 至此，DB 高可用部署完成，任一节点的 Mariadb 或 keepalived 服务异常，或者任一节点宕机，都不影响对外服务。\n","excerpt":"OneCloud 服务使用 Mariadb，这里使用 keepalived 和 Mariadb 的主主复制功能来实现 DB 的高可用。 …","ref":"/v3.3/docs/setup/db-ha/","title":"部署 DB HA 环境"},{"body":"架构简介 OneCloud 服务组件较多，接下来分别介绍每个组件的功能:\n   服务组件 功能用途     keystone 认证权限管理   region 多云资源控制器   scheduler 资源调度器   glance 虚拟机镜像管理   host 私有云虚拟机管理   baremetal 私有云物理机管理   esxi-agent vmware esxi 实例管理   lb-agent 私有云负载均衡   webconsole 提供 vnc, ssh 访问   logger 记录审计日志   apigateway api 网关，能通过该服务访问后端所有 api   climc 命令行管理工具    组件架构见下图，分为接入层，控制层和资源层三个主要部分。\n接入层 接入层实现云管平台的访问功能，允许用户通过如下3种方式访问云管平台的功能：\n  API访问: 通过REST API访问云管平台功能，用户可以直接通过http接口访问云管平台的REST API，也可以使用云管平台提供的SDK。目前SDK支持Java，Python和Golang等三种语言。\n  命令行访问: 通过云管平台提供的climc命令行工具访问云管平台功能，允许用户通过脚本调用climc，实现一些自动化运维功能。Climc使用Golang语言，基于云管平台的Golang SDK开发。\n  Web控制台访问: 通过Web UI访问云管平台的功能。允许用户通过主流web浏览器访问云管平台。Web控制台提供管理员使用的管理后台以及普通用户使用的普通功能页面，能够提供大部分的管理和使用功能。Web控制台基于Vue 2.0 JavaScript SPA框架实现。\n  控制层   控制层实现云管平台的管理和控制功能。主要由API网关，认证服务，镜像服务，云控制器和调度器，以及 webconsole vnc, ssh 代理服务等组件构成。\n  API网关提供Web控制台对各个服务的统一REST API访问接口。实现Web控制台的登录验证，session 控制，以及对后端各个服务的API调用。API网关由Golang完全自主开发，完全无状态架构，具备水平扩展能力。\n  认证服务提供平台的账户管理和认证体系，并提供基于项目的多租户支持，同时提供服务目录功能。认证服务支持多种认证源，允许和企业的LDAP／AD对接，允许用户以企业统一的账户体系登入系统。认证服务2.10之前版本基于OpenStack Keystone Pika版本，开发语言为Python。在开源版本基础上，我们修正了BUG，并做了若干改进。2.10之后版本采用golang语言开发。Keystone采用无状态架构，支持水平扩展，可以水平拆分实现服务高可用。\n  镜像服务提供云管平台各种主机资源的操作系统镜像的管理功能。提供镜像存储，元数据管理等功能。镜像服务1.x版本基于OpenStack Glance Folsom版本改进而来，开发语言为Python。在开源版本基础上，我们修正了BUG，并做了若干改进。2.x版本采用golang语言开发。Glance采用无状态架构，支持水平扩展，可以水平拆分实现服务高可用。\n  云控制器是整个云管平台的中枢，负责机房网络，宿主机，网络，存储，虚拟机等各类资源的元数据信息管理，以及对虚拟机，裸机等的自动化管理操作认证的调度，协调管理。云控制器内置基于REST API接口的分布式异步任务管理框架，实现对在计算节点进行的开关机，创建删除等耗时操作任务的管理协调工作。云控制器完全自主开发，云控制器采用无状态架构，可以水平扩展，通过水平拆分实现高可用。\n  调度器负责云管平台资源调度功能，是云管平台中资源获取决策的唯一执行者，根据用户对资源的要求，给出资源的最优提供者。调度器支持批量调度，调度性能优异，可扩展性好。调度器完全自主开发，基于Golang语言开发。\n  资源层  资源层实现对KVM虚拟机，裸机，VMWare虚拟机等计算资源的管理和控制功能。云管平台目前主要支持对KVM虚拟机，裸机，VMWare虚拟机，常用私有云openstack, zstack 以及公有云阿里云，Azure，腾讯云，AWS等公有云资源的管理。  ","excerpt":"架构简介 OneCloud 服务组件较多，接下来分别介绍每个组件的功能:\n   服务组件 功能用途     keystone …","ref":"/v3.3/docs/contribute/services/","title":"服务组件介绍"},{"body":"环境准备 OneCloud 相关的组件运行在 kubernetes 之上，环境以及相关的软件依赖如下:\n 操作系统: Centos 7.6 最低配置要求: CPU 4核, 内存 8G, 存储 150G 数据库: mariadb (CentOS 7自带的版本：Ver 15.1 Distrib 5.5.56-MariaDB） docker: ce-19.03.9 kubernetes: v1.15.8  需要能访问如下网址，如果企业有外网隔离规则，则需要打开相应白名单：\n CentOS YUM网络安装源 https://iso.yunion.cn/ https://registry.cn-beijing.aliyuncs.com https://meta.yunion.cn https://yunionmeta.oss-cn-beijing.aliyuncs.com  安装配置 mariadb mariadb 作为服务数据持久化的数据库，可以部署在其它节点或者使用单独维护的。下面假设还没有部署 mariadb，在控制节点上安装设置 mariadb。\n为了方便运行维护，mariadb推荐打开两个参数设施：\n skip_name_resolve：取消域名解析 expire_logs_days=30：设置binlog的超时时间为30天，超过30天的binglog自动删除  $ MYSQL_PASSWD='your-sql-passwd' # 安装 mariadb $ yum install -y epel-release mariadb-server $ systemctl enable --now mariadb $ mysqladmin -u root password \"$MYSQL_PASSWD\" $ cat \u003c\u003cEOF \u003e/etc/my.cnf [mysqld] datadir=/var/lib/mysql socket=/var/lib/mysql/mysql.sock # Disabling symbolic-links is recommended to prevent assorted security risks symbolic-links=0 # Settings user and group are ignored when systemd is used. # If you need to run mysqld under a different user or group, # customize your systemd unit file for mariadb according to the # instructions in http://fedoraproject.org/wiki/Systemd # skip domain name resolve skip_name_resolve # auto delete binlog older than 30 days expire_logs_days=30 [mysqld_safe] log-error=/var/log/mariadb/mariadb.log pid-file=/var/run/mariadb/mariadb.pid # # include all files from the config directory # !includedir /etc/my.cnf.d EOF $ mysql -uroot -p$MYSQL_PASSWD \\  -e \"GRANT ALL ON *.* to 'root'@'%' IDENTIFIED BY '$MYSQL_PASSWD' with grant option; FLUSH PRIVILEGES;\" $ systemctl restart mariadb 安装配置 docker 安装 docker\n$ yum install -y yum-utils bash-completion # 添加 yunion onecloud rpm 源 $ yum-config-manager --add-repo https://iso.yunion.cn/yumrepo-3.3/yunion.repo $ yum install -y docker-ce-19.03.9 docker-ce-cli-19.03.9 containerd.io 配置 docker\n$ mkdir -p /etc/docker $ cat \u003c\u003cEOF \u003e/etc/docker/daemon.json { \"bridge\": \"none\", \"iptables\": false, \"exec-opts\": [ \"native.cgroupdriver=systemd\" ], \"data-root\": \"/opt/docker\", \"live-restore\": true, \"log-driver\": \"json-file\", \"log-opts\": { \"max-size\": \"100m\" }, \"registry-mirrors\": [ \"https://lje6zxpk.mirror.aliyuncs.com\", \"https://lms7sxqp.mirror.aliyuncs.com\", \"https://registry.docker-cn.com\" ] } EOF 启动 docker\n$ systemctl enable --now docker 安装 onecloud 依赖内核 这里需要安装我们编译的内核，这个内核是基于上游 Centos 3.10.0-1062 编译的，默认添加了 nbd 模块，nbd 模块用于镜像相关的操作。\n# 安装内核 $ yum install -y \\  kernel-3.10.0-1062.4.3.el7.yn20191203 \\  kernel-devel-3.10.0-1062.4.3.el7.yn20191203 \\  kernel-headers-3.10.0-1062.4.3.el7.yn20191203 # 重启系统进入内核 $ reboot # 重启完成后，查看当前节点内核信息 # 确保为 3.10.0-1062.4.3.el7.yn20191203.x86_64 $ uname -r 3.10.0-1062.4.3.el7.yn20191203.x86_64 安装配置 kubelet 从 yunion onecloud rpm 的 yum 源安装 kubernetes 1.15.8，并设置 kubelet 开机自启动\n$ yum install -y bridge-utils ipvsadm conntrack-tools \\  jq kubelet-1.15.8-0 kubectl-1.15.8-0 kubeadm-1.15.8-0 $ echo 'source \u003c(kubectl completion bash)' \u003e\u003e ~/.bashrc \u0026\u0026 source ~/.bashrc $ source /etc/profile $ systemctl enable kubelet 安装完 kubernetes 相关的二进制后，还需要对系统做一些配置并启用 ipvs 作为 kube-proxy 内部的 service 负载均衡\n# 禁用 swap $ swapoff -a # 如果设置了自动挂载 swap，需要去 /etc/fstab 里面注释掉挂载 swap 那一行 # 关闭 selinux $ setenforce 0 $ sed -i 's/SELINUX=enforcing/SELINUX=disabled/' /etc/selinux/config # 禁用 firewalld $ systemctl stop firewalld $ systemctl disable firewalld # 禁用 NetworkManager $ systemctl stop NetworkManager $ systemctl disable NetworkManager # 做一些 sysctl 的配置, kubernetes 要求 $ modprobe br_netfilter $ cat \u003c\u003cEOF \u003e\u003e /etc/sysctl.conf net.bridge.bridge-nf-call-iptables=1 net.bridge.bridge-nf-call-ip6tables=1 net.ipv4.ip_forward=1 EOF $ sysctl -p # 配置并开启 ipvs $ cat \u003c\u003cEOF \u003e /etc/sysconfig/modules/ipvs.modules #!/bin/bash ipvs_modules=\"ip_vs ip_vs_lc ip_vs_wlc ip_vs_rr ip_vs_wrr ip_vs_lblc ip_vs_lblcr ip_vs_dh ip_vs_sh ip_vs_fo ip_vs_nq ip_vs_sed ip_vs_ftp nf_conntrack_ipv4\" for kernel_module in \\${ipvs_modules}; do /sbin/modinfo -F filename \\${kernel_module} \u003e /dev/null 2\u003e\u00261 if [ $? -eq 0 ]; then /sbin/modprobe \\${kernel_module} fi done EOF $ chmod 755 /etc/sysconfig/modules/ipvs.modules \u0026\u0026 bash /etc/sysconfig/modules/ipvs.modules \u0026\u0026 lsmod | grep ip_vs 部署集群 提示  如果要部署高可用集群，请先搭建负载均衡集群，参考 部署 HA 环境。\n  安装部署工具 先安装部署工具 ocadm 和云平台的命令行工具 climc:\n# 安装 climc 云平台命令行工具 和 ocadm 部署工具 $ yum install -y yunion-climc yunion-ocadm # climc 在 /opt/yunion/bin 目录下，根据自己的需要加到 bash 或者 zsh 配置文件里面 $ echo 'export PATH=$PATH:/opt/yunion/bin' \u003e\u003e ~/.bashrc \u0026\u0026 source ~/.bashrc # 安装必要的服务，并启动和设置为开机自启 $ yum install -y yunion-executor-server \u0026\u0026 systemctl enable --now yunion-executor 部署 kubernetes 集群 接下来会现在当前节点启动 v1.15.8 的 kubernetes 服务，然后部署 OneCloud 控制节点相关的服务到 kubernetes 集群。\n拉取必要的 docker 镜像\n$ ocadm config images pull 使用 ocadm 部署 kubernetes 集群\n提示  如果要进行高可用部署，并已经搭建好了负载均衡集群，需要在 ocadm init 命令加上 --control-plane-endpoint \u003cvip\u003e:6443 参数，告诉 kubernetes 集群前端的 LoadBalancer vip，之后生成的配置就会都用这个 vip 当做控制节点的入口。\n  # 假设 mariadb 部署在本地，如果是使用已有的数据库，请改变对应的 ip $ MYSQL_HOST=$(ip route get 1 | awk '{print $NF;exit}') # 如果是高可用部署，记得在设置 EXTRA_OPT=' --control-plane-endpoint 10.168.222.18:6443' $ EXTRA_OPT=\"\" $ #EXTRA_OPT=' --control-plane-endpoint 10.168.222.18:6443' # 开始部署 kubernetes 以及 onecloud 必要的控制服务，稍等 3 分钟左右，kubernetes 集群会部署完成 $ ocadm init --mysql-host $MYSQL_HOST \\  --mysql-user root --mysql-password $MYSQL_PASSWD $EXTRA_OPT ... Your Kubernetes and Onecloud control-plane has initialized successfully! ...  提示  kubernetes 高可用部署需要 3 个节点，主要是 etcd 需要至少 3 个节点组成高可用集群。如果是高可用部署，请在另外两个节点执行 ocadm join --control-plane \u003cvip\u003e:6443 部署控制服务，join 的另外两个节点会自动和当前的控制节点组成高可用集群。参考: 加入控制节点\n  kubernetes 集群部署完成后，通过以下命令来确保相关的 pod (容器) 都已经启动, 变成 running 的状态。\n$ mkdir -p $HOME/.kube $ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config $ sudo chown $(id -u):$(id -g) $HOME/.kube/config $ kubectl get pods --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE kube-system calico-kube-controllers-648bb4447c-57gjb 1/1 Running 0 5h1m kube-system calico-node-j89jg 1/1 Running 0 5h1m kube-system coredns-69845f69f6-f6wnv 1/1 Running 0 5h1m kube-system coredns-69845f69f6-sct6n 1/1 Running 0 5h1m kube-system etcd-lzx-ocadm-test2 1/1 Running 0 5h kube-system kube-apiserver-lzx-ocadm-test2 1/1 Running 0 5h kube-system kube-controller-manager-lzx-ocadm-test2 1/1 Running 0 5h kube-system kube-proxy-2fwgf 1/1 Running 0 5h1m kube-system kube-scheduler-lzx-ocadm-test2 1/1 Running 0 5h kube-system traefik-ingress-controller-qwkfb 1/1 Running 0 5h1m local-path-storage local-path-provisioner-5978cff7b7-7h8df 1/1 Running 0 5h1m onecloud onecloud-operator-6d4bddb8c4-tkjkh 1/1 Running 0 3h37m 创建 onecloud 集群 当 kubernetes 集群部署完成后，就可以通过 ocadm cluster create 创建 onecloud 集群，该集群由 onecloud namespace 里面 onecloud-operator deployment 自动部署和维护。\n# 创建集群 # 如果要部署企业版的组件可以在 cluster create 的时候加上 --use-ee 参数 $ ocadm cluster create --wait 执行完 ocadm cluster create --wait 命令后，onecloud-operator 会自动创建各个服务组件对应的 pod，等待一段该命令执行完毕， 就可以通过访问 ‘https://本机IP:443’ 登入前端界面。\n创建登录用户 当控制节点部署完成后，需要创建一个用于前端登录的用户。云平台的管理员认证信息由 ocadm cluster rcadmin 命令可以得到 , 这些认证信息在使用 climc 控制云平台资源时会用到。\n# 获取连接 onecloud 集群的环境变量 $ ocadm cluster rcadmin export OS_AUTH_URL=https://10.168.222.218:30357/v3 export OS_USERNAME=sysadmin export OS_PASSWORD=3hV3qAhvxck84srk export OS_PROJECT_NAME=system export YUNION_INSECURE=true export OS_REGION_NAME=region0 export OS_ENDPOINT_TYPE=publicURL  提示  如果是高可用部署，这些 endpoint 的 public url 会是 vip，如果要在 kubernetes 集群外访问需要到 haproxy 节点上添加对应的 frontend 和 backend，其中frontend的端口对应 endpoint 里面的端口，backend 对应 3 个 controlplane node 的 ip 和对应端口。\n  创建用户\n# 初始化连接集群的管理员认证信息 $ source \u003c(ocadm cluster rcadmin) # 设置想要创建的用户名和密码 $ OC_USERNAME=demo $ OC_PASSWORD=demo@123 # 创建指定的用户 $ climc user-create --password $OC_PASSWORD --enabled $OC_USERNAME # 将用户加入 system 项目并赋予 admin 角色 $ climc project-add-user system $OC_USERNAME admin 访问前端 # 获取本机 IP $ ip route get 1 | awk '{print $NF;exit}' 10.168.222.218 # 测试连通性 $ curl -k https://10.168.222.218 用浏览器访问 ‘https://本机IP’ 会跳转到 web 界面，使用 创建登录用户 里面指定的用户名和密码登录后，界面如下:\n删除环境 如果安装过程中失败，或者想清理环境，可执行以下命令删除 kubernetes 集群。\n$ ocadm reset --force 后续 如果没有意外，现在应该已经部署好了 onecloud on kubernetes 的集群，以下是一些后续的环节说明，可以根据自己的需要来进行额外的操作。\n添加计算节点 当控制节点搭建完成后，可以参考 计算节点 一节的内容，添加计算节点，组建一套私有云集群。\n控制节点作为计算节点 默认情况下 ocadm init 创建的节点是控制节点，不会运行 onecloud 计算节点的服务。如果需要把控制节点也作为计算节点，需要执行以下步骤:\n  安装计算节点需要的依赖，参考 “计算节点/安装依赖”，这里主要是要安装我们的内核和运行虚拟机的 qemu 等软件。\n  在控制节点启用该节点作为计算节点，命令如下:\n  # 用 kubectl get nodes 拿到当前的节点名称 $ kubectl get nodes NAME STATUS ROLES AGE controller01 Ready master 116d controller02 Ready master 40d node01 Ready \u003cnone\u003e 25d # 假设我要把 controller01 和 controller02 作为计算节点 $ ocadm node enable-host-agent \\  --node controller01 \\  --node controller02 # 等待并查看运行在 controller01/02 上的计算节点服务 $ kubectl get pods -n onecloud -o wide | grep host default-host-7b5cr 2/2 Running 218 18h 192.168.222.4 controller01 default-host-ctx5s 2/2 Running 218 18h 192.168.222.5 controller02 升级/回滚组件版本 ocadm init 的时候使用 --onecloud-version 选项设置了组件的版本，可以使用 ocadm cluster update 命令升级组件到指定的版本，保持更新。\n# 查看现在 onecloud cluster 的版本 $ kubectl get oc -n onecloud default -o jsonpath='{.spec.version}' v3.0.0-20200112.0 # 升级到 v3.0.0-20200113.0 $ ocadm cluster update --version v3.0.0-20200113.0 --wait ","excerpt":"环境准备 OneCloud 相关的组件运行在 kubernetes 之上，环境以及相关的软件依赖如下:\n 操作系统: Centos 7.6  …","ref":"/v3.3/docs/setup/controlplane/","title":"部署集群"},{"body":"介绍云平台后端服务所用的框架和相关库的使用方法，建议先阅读 “开发相关/服务组件介绍” 了解各个服务大概的功能。\n后端服务框架 keystone, region, glance 等后端服务，都是用的同一套后端服务框架，这个框架是我们自己定义实现的，核心模块如下:\n  REST API: 负责解析客户端发送的 CRUD http 请求，将不同的请求对应到 Model Dispatcher 模块。\n  Model Dispatcher: 将客户端的请求分发到对应资源的业务操作。\n  Model: 定义云平台各种资源，会进行数据库读写相关操作，如果具体业务需要进行耗时操作，会通过 Task 机制来执行耗时任务。\n  Task: 后台处理异步耗时任务的模块，会通过更新 Model 的状态来更新任务的执行结果。\n  onecloud 代码结构  build: 打包rpm脚本 cmd: 可执行binary入口程序 pkg: 库  appsrv: 通用http服务框架 cloudcommon: 云平台服务框架，基于appsrv扩展  cloudcommon/options: 通用options cloudcommon/app: 通用服务初始化代码 cloudcommon/db: Model dispatcher和Models的基础实现 cloudcommon/db/lockman: 锁实现 cloudcommon/db/taskman: 异步任务框架      认证部分  客户端向服务发起请求前，需要从keystone获得token 客户端通过携带用户名密码调用keystone的/v3/auth/tokens接口获得token 客户端向服务发起的每次API请求都会在HTTP头携带该token，比如: X-Auth-Token: {token} 后端服务向keystone验证该token，获得用户的身份信息，执行后续API的流程 每个服务都有一个keystone注册的服务用户账号（user/password)，并且以admin角色加入system项目 服务启动后，会向keystone发起认证，获得admin token 用户通过API访问服务时，将在header携带token 使用这个admin token访问keystone的token验证接口，验证这个token，获得用户的身份信息  Model Dispatcher 把 REST API 和 Model 的方法进行一一映射\n   REST 请求 Model 方法 说明     GET /\u003cresources\u003e AllowListItems List的权限判断   - ListItemFilter 过滤   - GetCustomizeColumns 获得扩展字段的信息   GET /\u003cresources\u003e/\u003cres_id\u003e AllowGetDetails Get 的权限判断   - GetExtraDetails 获取扩展字段的信息   GET /\u003cresources\u003e/\u003cres_id\u003e/\u003cspec\u003e AllowGetDetails\u003cSpec\u003e 获取资源特定属性的权限判断   - GetDetails\u003cSpec\u003e 获取资源特定属性   POST /\u003cresources\u003e AllowCreateItem 创建操作的鉴权   - ValidateCreateData 校验和处理创建的数据   - CustomizeCreate 自定义的创建操作   - PostCreate 创建后的hook   - OnCreateComplete 创建完成的hook   POST /\u003cresources\u003e/\u003cres_id\u003e/\u003caction\u003e AllowPerformAction\u003cAction\u003e 某个资源执行特定操作的鉴权判断   - Perform\u003cAction\u003e 某个资源执行特定操作   PUT /\u003cresources\u003e/\u003cres_id\u003e AllowUpdateItem 对指定资源更新操作的鉴权   - ValidateUpdateData 校验和处理更新操作的数据   - PreUpdate 自定义的创建操作   - PostUpdate 创建后的hook   DELETE /\u003cresources\u003e/\u003cres_id\u003e AllowDeleteItem 删除指定资源的鉴权   - CustomizeDelete 自定义的删除操作   - PreDelete 删除前的hook   - Delete 执行删除操作   - PostDelete 删除后的hook    具体 restful 请求的绑定函数在: pkg/appsrv/dispatcher/dispatcher.go 文件中的 AddModelDispatcher 函数。\n数据库 ORM 模型 代码位于 cloudcommon/db\n 接口  IModelManager: 对应资源在数据库里面的表 IModel: 对应资源在数据库里面的单条数据   数据结构  SResourceBase: 基础资源  SStandaloneResourceBase: 基础设施的物理资源，没有具体ownerId的资源，如zone, host  SVirtualResourceBase: 虚拟资源，如虚拟机（guest)  SSharableVirtualResourceBase: 虚拟的可以共享的虚拟资源，如disk, network  SAdminSharableVirtualInfoBase: 管理配置用的可共享虚拟资源，如security group       SJointResourceBase: 联合数据类型，如虚拟网卡是虚拟机和网络的联合，虚拟磁盘挂在：虚拟机和虚拟磁盘的联合      举例 用虚拟机的 model 来举例，代码在: pkg/compute/models/guests.go。\nGuestManager 对应数据库里面的 guests_tbl，该对象嵌套 db.SVirtualResourceBaseManager 表示是虚拟资源的 Manager，这样会默认实现 db.IModelManager 接口，然后根据业务需要重写一些方法会比较方便。\nSGuest 对应 guests_tbl 数据库里面的每一行数据，由 GuestManager 管理，嵌套 db.SVirtualResourceBase 结构，默认就会有虚拟资源所需要的表结构，然后再定义一些虚拟机独有的属性比如 VcpuCount 表示 cpu 核数，VmemSize 表示内存大小。 在代码抽象后表示虚拟机实例，该对象会绑定对虚拟机具体的业务操作实现函数。\nimport \"yunion.io/x/onecloud/pkg/cloudcommon/db\" ...... type SGuestManager struct { db.SVirtualResourceBaseManager } var GuestManager *SGuestManager func init() { GuestManager = \u0026SGuestManager{ SVirtualResourceBaseManager: db.NewVirtualResourceBaseManager( SGuest{}, \"guests_tbl\", \"server\", \"servers\", ), } GuestManager.SetVirtualObject(GuestManager) GuestManager.SetAlias(\"guest\", \"guests\") } type SGuest struct { db.SVirtualResourceBase db.SExternalizedResourceBase SBillingResourceBase VcpuCount int `nullable:\"false\" default:\"1\" list:\"user\" create:\"optional\"` // Column(TINYINT, nullable=False, default=1) \tVmemSize int `nullable:\"false\" list:\"user\" create:\"required\"` // Column(Integer, nullable=False)  BootOrder string `width:\"8\" charset:\"ascii\" nullable:\"true\" default:\"cdn\" list:\"user\" update:\"user\" create:\"optional\"` // Column(VARCHAR(8, charset='ascii'), nullable=True, default='cdn')  DisableDelete tristate.TriState `nullable:\"false\" default:\"true\" list:\"user\" update:\"user\" create:\"optional\"` // Column(Boolean, nullable=False, default=True) \tShutdownBehavior string `width:\"16\" charset:\"ascii\" default:\"stop\" list:\"user\" update:\"user\" create:\"optional\"` // Column(VARCHAR(16, charset='ascii'), default=SHUTDOWN_STOP)  KeypairId string `width:\"36\" charset:\"ascii\" nullable:\"true\" list:\"user\" create:\"optional\"` // Column(VARCHAR(36, charset='ascii'), nullable=True)  HostId string `width:\"36\" charset:\"ascii\" nullable:\"true\" list:\"admin\" get:\"admin\" index:\"true\"` // Column(VARCHAR(36, charset='ascii'), nullable=True) \tBackupHostId string `width:\"36\" charset:\"ascii\" nullable:\"true\" list:\"user\" get:\"user\"` Vga string `width:\"36\" charset:\"ascii\" nullable:\"true\" list:\"user\" update:\"user\" create:\"optional\"` // Column(VARCHAR(36, charset='ascii'), nullable=True) \tVdi string `width:\"36\" charset:\"ascii\" nullable:\"true\" list:\"user\" update:\"user\" create:\"optional\"` // Column(VARCHAR(36, charset='ascii'), nullable=True) \tMachine string `width:\"36\" charset:\"ascii\" nullable:\"true\" list:\"user\" update:\"user\" create:\"optional\"` // Column(VARCHAR(36, charset='ascii'), nullable=True) \tBios string `width:\"36\" charset:\"ascii\" nullable:\"true\" list:\"user\" update:\"user\" create:\"optional\"` // Column(VARCHAR(36, charset='ascii'), nullable=True) \tOsType string `width:\"36\" charset:\"ascii\" nullable:\"true\" list:\"user\" update:\"user\" create:\"optional\"` // Column(VARCHAR(36, charset='ascii'), nullable=True)  FlavorId string `width:\"36\" charset:\"ascii\" nullable:\"true\" list:\"user\" create:\"optional\"` // Column(VARCHAR(36, charset='ascii'), nullable=True)  SecgrpId string `width:\"36\" charset:\"ascii\" nullable:\"true\" get:\"user\" create:\"optional\"` // Column(VARCHAR(36, charset='ascii'), nullable=True) \tAdminSecgrpId string `width:\"36\" charset:\"ascii\" nullable:\"true\" get:\"admin\"` // Column(VARCHAR(36, charset='ascii'), nullable=True)  Hypervisor string `width:\"16\" charset:\"ascii\" nullable:\"false\" default:\"kvm\" list:\"user\" create:\"required\"` // Column(VARCHAR(16, charset='ascii'), nullable=False, default=HYPERVISOR_DEFAULT)  InstanceType string `width:\"64\" charset:\"ascii\" nullable:\"true\" list:\"user\" create:\"optional\"` } ...... 数据库锁 代码位于 cloudcommon/db/lockman:\n LockClass/ReleaseClass: 锁住一类实例，一般创建资源时候需要锁 LockObject/ReleaseObject: 锁住一个实例，一般修改资源实例是需要锁 LockRawObject/RelaseRawObject: 通用的锁  举例 pkg/cloudcommon/db/db_dispatcher.go 里面的 DoCreate 函数会创建对应 Model 的对象并插入数据到数据库，这个时候就需要加锁。\nfunc DoCreate(manager IModelManager, ctx context.Context, userCred mcclient.TokenCredential, query jsonutils.JSONObject, data jsonutils.JSONObject, ownerId mcclient.IIdentityProvider) (IModel, error) { lockman.LockClass(ctx, manager, GetLockClassKey(manager, ownerId)) defer lockman.ReleaseClass(ctx, manager, GetLockClassKey(manager, ownerId)) return doCreateItem(manager, ctx, userCred, ownerId, nil, data) } worker队列管理 为了避免不可预期的并发度，所有异步执行的代码都应该在worker内执行，以便于管理并发度。\n代码位于 appsrv/workers.go\nworkerman := appsrv.NewWorkerManager(name, parallel_cnt, …) workerman.Run(func() {…}, nil, nil) Task 机制 云平台的异步耗时任务会放在 Task 机制里面去执行，比如创建虚拟机操作，用户提交了请求，region 控制器校验参数合格后，会记录数据到数据库，然后马上返回客户端对应的虚拟机记录，与此同时，会开始执行创建虚拟机的 task，这个 task 会立即在后台执行，会通过更新虚拟机 SGuest model 的状态和记录操作日志来表示执行的成功或失败。\ntask 也是记录在数据库 tasks_tbl 里面的记录，对应的定义在: pkg/cloudcommon/db/taskman/tasks.go 里面，数据结构如下:\ntype STaskManager struct { db.SResourceBaseManager } var TaskManager *STaskManager func init() { TaskManager = \u0026STaskManager{ SResourceBaseManager: db.NewResourceBaseManager(STask{}, \"tasks_tbl\", \"task\", \"tasks\") } TaskManager.SetVirtualObject(TaskManager) } type STask struct { db.SResourceBase Id string `width:\"36\" charset:\"ascii\" primary:\"true\" list:\"user\"` // Column(VARCHAR (36, charset='ascii'), primary_key=True, default=get_uuid) ObjName string `width:\"128\" charset:\"utf8\" nullable:\"false\" list :\"user\"` // Column(VARCHAR(128, charset='utf8'), nullable=False)  ObjId string `width:\"128\" charset:\"ascii\" nullable:\"false\" lis t:\"user\" index:\"true\"` // Column(VARCHAR(ID_LENGTH, charset='ascii'), nullable=False)  TaskName string `width:\"64\" charset:\"ascii\" nullable:\"false\" list :\"user\"` // Column(VARCHAR(64, charset='ascii'), nullable=False)  UserCred mcclient.TokenCredential `width:\"1024\" charset:\"utf8\" nullable:\"false\" get :\"user\"` // Column(VARCHAR(1024, charset='ascii'), nullable=False)  // OwnerCred string `width:\"512\" charset:\"ascii\" nullable:\"true\"` // Column(VARCHAR (512, charset='ascii'), nullable=True) Params *jsonutils.JSONDict `charset:\"utf8\" length:\"medium\" nullable:\"false\" get:\"us er\"` // Column(MEDIUMTEXT(charset='ascii'), nullable=False)  Stage string `width:\"64\" charset:\"ascii\" nullable:\"false\" default:\"on_init\" list:\"u ser\"` // Column(VARCHAR(64, charset='ascii'), nullable=False, default='on_init')  taskObject db.IStandaloneModel `ignore:\"true\"` taskObjects []db.IStandaloneModel `ignore:\"true\"` } ......  Id: STask 里面的 Id 是该 task 记录的 Id ObjId: 对应资源对象的 Id，用于记录执行该 task 的对应操作的资源，比如某台虚拟机、磁盘的 Id UserCred: 存储执行 task 的用户信息 Params: 执行 task 的参数 TaskName: 对应 task 的名称 Stage: task 执行的阶段，默认为 OnInit  举例 以虚拟机关机这个操作来举例:\n 客户端发起 POST /servers/\u003cserver_id\u003e/stop 请求后，通过服务框架会执行 func (self *SGuest) PerformStop 函数，代码片段如下(位于: pkg/compute/models/guest_actions.go):  func (self *SGuest) PerformStop(ctx context.Context, userCred mcclient.TokenCredential, query jsonutils.JSONObject, data jsonutils.JSONObject) (jsonutils.JSONObject, error) { // XXX if is force, force stop guest \tvar isForce = jsonutils.QueryBoolean(data, \"is_force\", false) if isForce || utils.IsInStringArray(self.Status, []string{api.VM_RUNNING, api.VM_STOP_FAILED}) { return nil, self.StartGuestStopTask(ctx, userCred, isForce, \"\") } else { return nil, httperrors.NewInvalidStatusError(\"Cannot stop server in status %s\", self.Status) } }  SGuest 会执行 self.StartGuestStopTask 函数，该函数会去调用虚拟机不同的 Driver 执行关机操作  // pkg/compute/models/guest_actions.go func (self *SGuest) StartGuestStopTask(ctx context.Context, userCred mcclient.TokenCredential, isForce bool, parentTaskId string) error { ...... return self.GetDriver().StartGuestStopTask(self, ctx, userCred, params, parentTaskId) } // pkg/compute/guestdrivers/virtualization.go import \"yunion.io/x/onecloud/pkg/cloudcommon/db/taskman\" ...... func (self *SVirtualizedGuestDriver) StartGuestStopTask(guest *models.SGuest, ctx context.Context, userCred mcclient.TokenCredential, params *jsonutils.JSONDict, parentTaskId string) error { task, err := taskman.TaskManager.NewTask(ctx, \"GuestStopTask\", guest, userCred, params, parentTaskId, \"\", nil) if err != nil { return err } task.ScheduleRun(nil) return nil } ......   taskman.TaskManager.NewTask(ctx, “GuestStopTask”, …) 这里面的 GuestStopTask 对应 pkg/compute/tasks/guest_stop_task.go 里面的 GuestStopTask，是通过 taskman 里面维护的一个 map 查找的。\n  task.ScheduleRun(nil) 会开始执行对应的 Task，默认会从 task 的默认 Stage OnInit 函数开始执行，所以通过 task 机制就会执行到 GuestStopTask.OnInit 函数。OnInit 函数最终会调用对应虚拟机的 driver 执行 RequestStopOnHost 函数并更新设置自己的 Stage 为 OnMasterStopTaskComplete。\n  对于虚拟机来说 RequestStopOnHost 函数会请求虚拟机所在的 host agent 关闭虚拟机，关机成功后会回调 region task 框架，该框架会根据 taskId 从数据库 load 回来 GuestStopTask，接着它设置的 Stage OnMasterStopTaskComplete 执行。\n  提示  这里失败会自动调用 OnGuestStopTaskCompleteFailed 函数，所以编写对应 task stage 函数时如果写 \u003cOnSometingComplete\u003e 函数时，必须也同时写 \u003cOnSometingCompleteFailed\u003e 函数来处理失败情况。\n   如果成功关机，OnMasterStopTaskComplete 调用 OnGuestStopTaskComplete 函数，该函数会把虚拟机的状态设置为 ready，并记录一条关机操作日志；如果失败会调用 OnGuestStopTaskCompleteFailed 函数，该函数会虚拟机状态设置为关机失败，并记录失败的原因。  func (self *GuestStopTask) OnInit(ctx context.Context, obj db.IStandaloneModel, data jsonutils.JSONObject) { guest := obj.(*models.SGuest) db.OpsLog.LogEvent(guest, db.ACT_STOPPING, nil, self.UserCred) self.stopGuest(ctx, guest) } func (self *GuestStopTask) stopGuest(ctx context.Context, guest *models.SGuest) { host := guest.GetHost() if host == nil { self.OnGuestStopTaskCompleteFailed(ctx, guest, jsonutils.NewString(\"no associated host\")) return } if !self.IsSubtask() { guest.SetStatus(self.UserCred, api.VM_STOPPING, \"\") } self.SetStage(\"OnMasterStopTaskComplete\", nil) err := guest.GetDriver().RequestStopOnHost(ctx, guest, host, self) ...... } func (self *GuestStopTask) OnMasterStopTaskComplete(ctx context.Context, guest *models.SGuest, data jsonutils.JSONObject) { ...... self.OnGuestStopTaskComplete(ctx, guest, data) } func (self *GuestStopTask) OnMasterStopTaskCompleteFailed(ctx context.Context, obj db.IStandaloneModel, reason jsonutils.JSONObject) { guest := obj.(*models.SGuest) self.OnGuestStopTaskCompleteFailed(ctx, guest, reason) } func (self *GuestStopTask) OnGuestStopTaskComplete(ctx context.Context, guest *models.SGuest, data jsonutils.JSONObject) { ...... guest.SetStatus(self.UserCred, api.VM_READY, \"\") ...... logclient.AddActionLogWithStartable(self, guest, logclient.ACT_VM_STOP, \"\", self.Us erCred, true) } func (self *GuestStopTask) OnGuestStopTaskCompleteFailed(ctx context.Context, guest *models.SGuest, reason jsonutils.JSONObject) { ...... db.OpsLog.LogEvent(guest, db.ACT_STOP_FAIL, reason.String(), self.UserCred) self.SetStageFailed(ctx, reason.String()) logclient.AddActionLogWithStartable(self, guest, logclient.ACT_VM_STOP, reason.String(), self.UserCred, false) } 如何增加一个新的服务  在keystone注册一个服务启用用的账户 在keystone注册service和endpoint 参考 onecloud/pkg/logger实现服务代码 为服务准备一个配置文件，包含以下基础信息  假设服务名为 svc，用户和密码为 svcuser, svcuserpassword，服务监听地址为: http://localhost:8866, region 为 LocalTest，对应操作如下:\n# 创建 service $ climc service-create --enabled svc svc # 创建 endpoint，对应的 service 为 svc $ climc endpoint-create svc LocalTest internal http://localhost:8866 # 创建 user $ climc user-create --password svcuserpassword --enabled svcuser # 把 user 加入 system 项目 $ climc project-add-user system svcuser admin 配置信息如下\nregion:LocalTestport:8866auth_url:https://\u003ckeystone_url\u003e:35357/v3admin_user:svcuseradmin_password:svcuserpasswordadmin_tenant_name:system","excerpt":"介绍云平台后端服务所用的框架和相关库的使用方法，建议先阅读 “开发相关/服务组件介绍” 了解各个服务大概的功能。 …","ref":"/v3.3/docs/contribute/framework/","title":"后端服务框架"},{"body":"部署完集群后，整个 kubernetes 集群只有一个节点，onecloud 相关服务都运行在了该节点上，为了服务的高可用，我们可以继续添加节点到 kubernetes 集群。\n环境准备 参考 “部署集群/环境准备” 的流程，安装好 docker 和 kubelet。\n获取加入集群 token 然后在控制节点使用 ocadm 拿到加入集群的 token，在待部署节点使用 ocadm 加入集群，操作如下:\n在控制节点获取加入节点的 token\n$ ocadm token list | grep bootstrap 4s4meb.xvgk2bwpmbospn3s 23h 2019-07-10T15:41:10+08:00 authentication,signing The default bootstrap token generated by 'ocadm init'. system:bootstrappers:kubeadm:default-node-token  提示  如果 token 过期了，可以在管理节点使用 ocadm token create 创建新的 token 。\n  加入节点 加入已有 kubernetes 集群的节点有两种角色，‘controlplane’ 和 ‘node’。\ncontrolplane 角色的节点会运行 kube-apiserver、kube-controller-manager、kube-scheduler 和 etcd，加入 controlplane 节点的好处是让 kubernetes 控制相关服务和 etcd 变为高可用。\nnode 角色的节点只会运行 kubelet，运行负载容器。\n加入 controlplane 加入控制节点需要从已有的 kubernetes 集群下载证书，证书使用 certificate key 加密，通过以下方法获取 certificate-key\n$ ocadm init phase upload-certs [upload-certs] Storing the certificates in Secret \"kubeadm-certs\" in the \"kube-system\" Namespace [upload-certs] Using certificate key: afa5e18bacb3f50b424cbf815fce6d1bd916fe91b58ba467053dc6b460198c55 # 这里的 10.168.222.18 是控制节点的 ip，如果是高可用部署则为负载均衡器的 vip，请根据你的环境修改 $ ocadm join --control-plane 10.168.222.18:6443 \\  --token 4s4meb.xvgk2bwpmbospn3s \\  --certificate-key afa5e18bacb3f50b424cbf815fce6d1bd916fe91b58ba467053dc6b460198c55 \\  --discovery-token-unsafe-skip-ca-verification 加入 node # 这里的 10.168.222.18 是控制节点的 ip，如果是高可用部署则为负载均衡器的 vip, 请根据你的环境修改 $ ocadm join 10.168.222.18:6443 \\  --token 4s4meb.xvgk2bwpmbospn3s \\  --discovery-token-unsafe-skip-ca-verification ... This node has joined the cluster: * Certificate signing request was sent to apiserver and a response was received. * The Kubelet was informed of the new secure connection details. Run 'kubectl get nodes' on the control-plane to see this node join the cluster. ","excerpt":"部署完集群后，整个 kubernetes 集群只有一个节点，onecloud 相关服务都运行在了该节点上，为了服务的高可用，我们可以继续添加 …","ref":"/v3.3/docs/setup/components/","title":"添加 K8S 节点"},{"body":"查询物理机 # list baremetal 记录 climc host-list --baremetal true # list 已经安装系统的物理机 climc host-list --baremetal true --occupied # list 未安装系统的物理机 climc host-list --baremetal true --empty # 查询物理机详情，包括硬件信息，机房信息 climc host-show \u003chost_id\u003e 注册物理机 climc host-create \u003chost_id\u003e 重新准备物理机 climc host-prepare \u003chost_id\u003e 获取物理机登录信息 climc host-logininfo \u003chost_id\u003e 获取串口登录控制台 climc webconsole-baremetal \u003chost_id\u003e 开/关机 climc host-start/host-stop \u003chost_id\u003e 进入/退出维护模式 climc host-maintenance/host-unmaintenance \u003chost_id\u003e 删除物理机 climc host-delete \u003chost_id\u003e 转换/回收宿主机 climc host-convert-hypervisor climc host-undo-convert \u003chost_id\u003e 裸金属服务器相关 安装操作系统 climc server-create \\  --hypervisor baremetal \\ # 指定 server 的类型为 baremetal --ncpu 24 \\ # 创建到 24 核 cpu 的物理机 --raid-config 'raid1:2:MegaRaid' \\ # 第1块盘，使用 MegaRaid 控制器上的(0-1)号两块物理盘做 raid1 --raid-config 'none:1' \\ # 第2块盘，使用 MegaRaid 控制器上的(2)号物理盘，不做 raid --raid-config 'raid10:4:MegaRaid' \\ # 第3快盘, 使用 MegaRaid 控制器上的(3-6)号四块物理盘做raid10 --disk CentOS-7.5.qcow2:100g \\ # 系统盘使用 CentOS-7.5.qcow2 镜像作为操作系统，大小为 100g，使用第1块 raid1 的盘 --disk 'autoextend:ext4:/opt' \\ # 分区挂载到 /opt, 使用第1块 raid1 的盘，文件系统为 ext4, 大小为(第一块盘总大小 - 该盘其他分区的大小(100g)) --disk 'autoextend:xfs:/data-nonraid' \\ # 分区挂载到 /data-nonraid, 使用第2块没做 raid 的盘, 文件系统为 xfs，使用所有空间 --disk 'autoextend:ext4:/data-raid10' \\ # 分区挂载到 /data-raid10, 使用第3块 raid10 的盘，文件系统为 ext4, 使用所有空间 \u003cserver_name\u003e \\ # 裸金属服务器名称 64g # 创建到 64g 内存大小的物理机 raid 配置和分区 调用 server-create 接口时通过 ‘–raid-config’ 传递参数来配置 raid，每个 raid-config 对应到操作系统可见的磁盘设备(/dev/sdx)。\n‘–disk’ 参数对应不同磁盘上的分区，分区对应到磁盘的逻辑为: 分区按照顺序创建到第1块磁盘上，当 disk 设置 autoextend 参数后，表示接下来的 disk 分区会创建到下一个磁盘，以此类推。\n raid 配置 API 参数:     Key Type value 解释     type(磁盘类型) string rotate(机械盘), ssd(固态盘), hybrid(未知) -   conf (raid) string none, raid0, raid1, raid5, raid10 做raid几或者不做   count (磁盘数量) int e.g. 0, 2, 4 小于等于物理机实际的盘数   range (磁盘范围) []int e.g. [0,1,2,3], [4,7], [5,6] 物理磁盘在控制器上的索引号   splits (切割物理盘) string (30%,20%,), (300g,100g,) 做好 raid 的物理盘再切割为多块物理盘   adapter (控制器号) int 0, 1 对应driver的 Adapter 控制器   driver (控制器名称) string MegaRaid,HPSARaid,Mpt2SAS,MarvelRaid,Linux,PCIE 1台物理机上有多个控制器时用于选择盘   strip (设置raid strip 大小) *int e.g. 64*1024 设置strip size, 可选   ra *bool  设置读模式   wt   设置写模式   cachedbadbbu *bool     direct *bool        命令行格式:\n‘(none,raid0,raid1,raid5,raid10):%d:(MegaRaid|HPSARaid|Mpt2SAS|MarvelRaid|Linux|PCIE):(rotate|ssd|hybrid):[0-n]:strip%dk:adapter%d:ra:nora:wt:wb:direct:cachedbadbbu:nocachedbadbbu’\n  查询裸金属服务器 climc server-list --hypervisor baremetal climc server-show \u003cserver_id\u003e 重装操作系统 climc server-rebuild --image \u003cimage_id\u003e \u003cserver_id\u003e 开/关机 climc server-start \u003cserver_id\u003e climc server-stop \u003cserver_id\u003e 删除裸金属服务器 删除 server 裸金属服务器会销毁物理机上的操作系统和 raid 配置，对应的 baremetal 重新进入未分配状态\nclimc server-delete \u003cserver_id\u003e ","excerpt":"查询物理机 # list baremetal 记录 climc host-list --baremetal true # list 已经安装 …","ref":"/v3.3/docs/howto/baremetal/operator/","title":"操作相关"},{"body":"climc server-create 命令提供创建云主机的操作。 OneCloud 可以同时管理多个私有云和公有云，不同供应商有各自的认证方式，在创建云主机之前需要做一些不同的准备工作。\n环境准备 OneCloud 虚拟机 OneCloud 提供自研的 kvm 虚拟机私有云管理平台，创建 kvm 虚拟机时需要有相应的宿主机，如果还没有添加 kvm 宿主机，请参考 安装部署/计算节点 注册对应的宿主机到云平台。\nVMware ESXI 虚拟机 TODO\n私有云 私有云和公有云都有自己的认证体系，为了让 OneCloud 能够管理各个云平台，需要把他们的认证信息导入到 OneCloud 平台。\n   平台 准备工作     openstack TODO   zstack TODO    公有云    平台 准备工作     阿里云 TODO   腾讯云 TODO   华为云 TODO   AWS TODO   Azure TODO   UCloud TODO    创建机器 创建机器命令为 server-create，可以使用 climc help server-create 查看创建 server 的所有参数，常用的参数如下：\n   参数名称 类型 作用     –ncpu int 虚拟机 cpu 个数   –disk []string 指定创建的系统盘镜像，指定多次表示虚拟机创建多块磁盘   –net []string 指定虚拟机使用的网络，指定多次将在虚拟机里面添加多个网卡   –allow-delete bool 允许删除虚拟机   –auto-start bool 创建完自动启动   –password string 设置虚拟机密码   –tenant string 创建到指定的项目   –prefer-region string 创建到指定的 region   –prefer-zone string 创建到指定的 zone   –prefer-host string 创建到指定的 host    注意以下几点:\n 名称、内存或者套餐类型在创建主机时必须使用; 系统盘的镜像通过 image-list 或者 cached-image-list，公有云的镜像列表通过 cached-image-list 接口查询，参考: 查询镜像;  下面以举例的方式创建机器：\n私有云主机 待创建规格:\n   名称 平台 套餐 内存 cpu 系统盘 网络 其他     vm1 kvm - 4g 4 centos7.qcow2 60g net1 2块数据盘， 一块100g ext4 挂载到 /opt，另外一块 50g xfs 挂载到 /data; 自动启动   vm2 esxi - 2g 2 ubuntu18.04.qcow2 100g net2 允许删除   vm3 opnstack t2.nano - - centos6.qcow2 net3 -    # 创建 kvm vm1 $ climc server-create --hypervisor kvm --disk centos7.qcow2:60g --disk 100g:ext4:/opt --disk 50g:xfs:/data --ncpu 4 --net net1 --auto-start vm1 4g # 创建 esxi vm2 $ climc server-create --hypervisor esxi --disk ubuntu18.04.qcow2:100g --net net2 --ncpu 2 --allow-delete vm2 2g # 创建 openstack vm3 $ climc server-create --hypervisor openstack --disk centos6.qcow2 --net net3 vm3 t2.nano 公有云主机 创建共有云主机和虚拟机的参数一致，但通常情况下需要通过 cloud-region-list 、zone-list 和 vpc-list 子命令挑选出各个公有云可用的 region, zone 和 network。\n然后 server-create 的时候通过 --prefer-region 或 --prefer-zone 创建到指定的区域，--net 创建到指定的 vpc 子网。\n# 查询 aliyun 的可用的 vpc $ climc vpc-list --provider Aliyun --details +--------------------------------------+-------------------------------------------+---------+-----------+--------------------------------------+------------+----------------+------------------------+ | ID | Name | Enabled | Status | Cloudregion_Id | Is_default | Cidr_Block | Region | +--------------------------------------+-------------------------------------------+---------+-----------+--------------------------------------+------------+----------------+------------------------+ | 6aabd4c5-8a6a-4ffb-83cd-39f924f773b7 | test12 | false | available | 9b0fdc39-701b-44fc-8842-664fe89359f1 | false | 192.168.0.0/16 | 阿里云 华北2（北京） | | 8f4d444f-cce4-4797-8441-e1b58c72ed26 | ali-yunion-bj | false | available | 9b0fdc39-701b-44fc-8842-664fe89359f1 | true | 172.17.0.0/16 | 阿里云 华北2（北京） | | bb8c1ec5-4577-4f84-8117-efab6586b799 | ali-transit-bj | false | available | 9b0fdc39-701b-44fc-8842-664fe89359f1 | false | 10.0.0.0/8 | 阿里云 华北2（北京） | | c4e1a012-5f2a-48fc-80ef-4ac0371006eb | hello | false | available | dbbfea2f-8bf4-4676-8036-4ad6f6e6b1ea | false | 10.0.0.0/8 | 阿里云 阿联酋（迪拜） | ... # 查询 vpc 6aabd4c5-8a6a-4ffb-83cd-39f924f773b7 下可用的 network $ climc network-list --vpc 6aabd4c5-8a6a-4ffb-83cd-39f924f773b7 +--------------------------------------+------------+----------------+-----------------+---------------+--------------------------------------+-----------+--------------+-----------------+-------------+-----------+ | ID | Name | Guest_ip_start | Guest_ip_end | Guest_ip_mask | wire_id | is_public | public_scope | guest_gateway | server_type | Status | +--------------------------------------+------------+----------------+-----------------+---------------+--------------------------------------+-----------+--------------+-----------------+-------------+-----------+ | b3dee5e6-0dce-403c-80b2-ad62880b662f | esrdfsfsd | 192.168.0.1 | 192.168.127.252 | 17 | a421934d-9cb4-4163-85b9-ad0038e9cb89 | true | system | 192.168.127.254 | guest | available | | d131de82-1be5-4f70-8b22-2303f4f409bb | sdfsdfdsff | 192.168.128.1 | 192.168.255.252 | 17 | 8ccdbe42-0c62-456f-842d-bc279a5c2786 | true | system | 192.168.255.254 | guest | available | +--------------------------------------+------------+----------------+-----------------+---------------+--------------------------------------+-----------+--------------+-----------------+-------------+-----------+ # 查询 region 9b0fdc39-701b-44fc-8842-664fe89359f1 下可用的 sku $ climc server-sku-list --region 9b0fdc39-701b-44fc-8842-664fe89359f1 --provider Aliyun # 创建 ecs.t5-lc2m1.nano aliyun vm4 虚拟机到 region 9b0fdc39-701b-44fc-8842-664fe89359f1 的子网 b3dee5e6-0dce-403c-80b2-ad62880b662f $ climc server-create --prefer-region 9b0fdc39-701b-44fc-8842-664fe89359f1 vm4 --hypervisor aliyun --net b3dee5e6-0dce-403c-80b2-ad62880b662f vm4 ecs.t5-lc2m1.nano ","excerpt":"climc server-create 命令提供创建云主机的操作。 OneCloud 可以同时管理多个私有云和公有云，不同供应商有各自的认证 …","ref":"/v3.3/docs/howto/server/create/","title":"创建云主机"},{"body":"列表 # 查询所有镜像列表 $ climc image-list # 查询所有缓存的镜像列表 $ climc cached-image-list # 查询包含 ubuntu 关键字的镜像 $ climc image-list --search ubuntu # 查询公有云包含 centos 关键字的缓存 $ climc cached-image-list --search centos --public-cloud # image-list 支持的查询条件 $ climc help image-list # cached-image-list 支持的查询条件 $ climc help cached-image-list 详情 根据 image-list 可以获取镜像的列表，第1、2列包含镜像的 id 和 name，通过 id 或 name 可以获取镜像的详情。\n# 查询名称包含 CentOS 的镜像 $ climc image-list --search centos +--------------------------------------+-----------------------------------------+-------------+-----------+-----------+-----------+-------------+----------+---------+--------+----------------------------------+----------------------------------+--------+----------------+ | ID | Name | Disk_format | Size | Is_public | Protected | Is_Standard | Min_disk | Min_ram | Status | Checksum | Tenant_Id | Tenant | is_guest_image | +--------------------------------------+-----------------------------------------+-------------+-----------+-----------+-----------+-------------+----------+---------+--------+----------------------------------+----------------------------------+--------+----------------+ | abf0fd6e-ec40-44ef-8fa2-cfb7187ea656 | CentOS-7-x86_64-GenericCloud-1711.qcow2 | qcow2 | 876740608 | false | true | true | 8192 | 0 | active | 317ecf7d1128e0e53cb285b8704dc3d3 | d53ea650bfe144da8ee8f3fba417b904 | system | false | +--------------------------------------+-----------------------------------------+-------------+-----------+-----------+-----------+-------------+----------+---------+--------+----------------------------------+----------------------------------+--------+----------------+ *** Total: 1 Pages: 1 Limit: 20 Offset: 0 Page: 1 *** # 查看 CentOS-7-x86_64-GenericCloud-1711.qcow2 的详情 $ climc image-show CentOS-7-x86_64-GenericCloud-1711.qcow2 +--------------------+-------------------------------------------------------------------------------------------------------------------+ | Field | Value | +--------------------+-------------------------------------------------------------------------------------------------------------------+ | can_delete | false | | can_update | true | | checksum | 317ecf7d1128e0e53cb285b8704dc3d3 | | created_at | 2020-06-16T09:17:57.000000Z | | delete_fail_reason | {\"error\":{\"class\":\"ForbiddenError\",\"code\":403,\"data\":{\"id\":\"image is protected\"},\"details\":\"image is protected\"}} | | disk_format | qcow2 | | domain_id | default | | fast_hash | 4c53ba2c464213ddc2a77c9b4c5ad3b7 | | id | abf0fd6e-ec40-44ef-8fa2-cfb7187ea656 | | is_data | false | | is_emulated | false | | is_guest_image | false | | is_public | false | | is_standard | true | | is_system | false | | min_disk | 8192 | | min_ram | 0 | | name | CentOS-7-x86_64-GenericCloud-1711.qcow2 | | oss_checksum | 317ecf7d1128e0e53cb285b8704dc3d3 | | owner | d53ea650bfe144da8ee8f3fba417b904 | | pending_deleted | false | | project_domain | Default | | project_src | local | | properties | {\"os_arch\":\"x86_64\",\"os_type\":\"Linux\"} | | protected | true | | public_scope | system | | size | 876740608 | | status | active | | tenant | system | | tenant_id | d53ea650bfe144da8ee8f3fba417b904 | | update_version | 8 | | updated_at | 2020-06-16T09:19:24.000000Z | +--------------------+-------------------------------------------------------------------------------------------------------------------+ ","excerpt":"列表 # 查询所有镜像列表 $ climc image-list # 查询所有缓存的镜像列表 $ climc …","ref":"/v3.3/docs/howto/image/query/","title":"查询镜像"},{"body":"你可能需要自己定制发行版的镜像，用于给不同的业务使用。本文介绍如何制作镜像。\n可以通过下载发行版操作系统的 iso , 然后本地启动虚拟机，将 iso 安装到虚拟机的磁盘，然后保存该磁盘，这个磁盘就可以作为镜像上传到 glance，但是这种方法人工参与的步骤太多，容易出错。\n推荐使用 packer 这个工具来自动化制作镜像，详细操作可以参考对应的文档 https://www.packer.io/docs/index.html 。\nhttps://github.com/yunionio/service-images 仓库包含了一些我们使用 packer 制作镜像的配置，可以参考使用。\n","excerpt":"你可能需要自己定制发行版的镜像，用于给不同的业务使用。本文介绍如何制作镜像。\n可以通过下载发行版操作系统的 iso , 然后本地启动虚拟机， …","ref":"/v3.3/docs/howto/image/create/","title":"制作镜像"},{"body":"云主机(server)指云平台管理的虚拟机和裸金属服务器。\n  虚拟机: 又叫做云服务器，包括我们提供的 kvm 虚拟机、vmware、openstack 和各个公有云的虚拟机。\n  裸金属: 云平台提供物理机(baremetal)装机功能，安装完操作系统并被云平台管理的服务器称为裸金属服务器。\n  现在支持的主机和平台的对应关系如下：\n   类型 平台     kvm onecloud 私有云虚拟机   baremetal onecloud 私有云裸金属   esxi vmware 虚拟机   openstack openstack 私有云虚拟机   zstack zstack 私有云虚拟机   aliyun 阿里云虚拟机   qcloud 腾讯云虚拟机   aws AWS 虚拟机   azure Azure 虚拟机   huawei 华为云虚拟机   ucloud UCloud 虚拟机    ","excerpt":"云主机(server)指云平台管理的虚拟机和裸金属服务器。\n  虚拟机: 又叫做云服务器，包括我们提供的 kvm 虚拟 …","ref":"/v3.3/docs/howto/server/","title":"云主机"},{"body":"主要结合应用场景介绍云平台各个资源的操作管理，首先会介绍命令行工具 climc 的用法，然后再具体介绍每种资源的操作。建议先熟悉命令行工具 climc 的使用过后在看后面的章节。\n熟悉命令行工具后，会分不同的部分介绍各种资源的操作和一些概念，云平台的资源大概分为 “虚拟资源” 和 “基础设施” 两类，有了基础设施类型的资源才能在其之上构建虚拟化的资源，具体分类如下:\n infra: 表示基础设施类型 virtual: 表示虚拟资源类型，属于具体的项目     名称 抽象资源 作用 类型     cloudregion 云平台地域 标记数据中心所在地域 infra   zone 云平台数据中心 标记数据中心 infra   vpc 逻辑隔离网络空间 抽象虚拟化网络的集合 infra   wire 对应二层扁平网络的广播域 抽象二层扁平网络广播域 infra   storage 存储 标记存储，提供云硬盘能力 infra   host 服务器 标记服务器，提供计算虚拟化 infra   server 云主机 运行在 host 上，使用虚拟化技术提供计算能力 virtual   disk 云硬盘 创建在 storage 上，使用虚拟化技术提供存储能力 virtual   network 网络 创建在 vpc 中，使用虚拟化技术提供网络 virtual   image 镜像 安装了操作系统的虚拟机磁盘，也属于 disk 一类 virtual   eip 外网浮动 ip 对应外网可用 ip virtual   loadbalancer 负载均衡器 标记负载均衡器，提供服务负载均衡 virtual    除了上面介绍的常见资源外，为了做多云管理，我们还引入了以下的概念:\n   名称 资源 作用 类型     cloudaccount 云平台的账户 对应各个云平台的认证信息 infra   project 项目 OneCloud 内部对虚拟机资源的划分 infra   schedtag 调度标签 可以标记多种资源，提供资源调度能力 infra   sku 套餐信息 对应创建虚拟资源的规格信息 infra    ","excerpt":"主要结合应用场景介绍云平台各个资源的操作管理，首先会介绍命令行工具 climc 的用法，然后再具体介绍每种资源的操作。 …","ref":"/v3.3/docs/howto/","title":"操作管理"},{"body":"如果需要构建内部私有云，就需要部署计算节点(宿主机)。计算节点主要负责虚拟机、网络和存储的管理，需要安装的组件如下:\n   组件 用途 安装方式 运行方式     host 管理 kvm 虚拟机和存储 - docker   host-deployer 虚拟机部署服务 - docker   sdnagent 管理虚拟机网络和安全组 - docker   openvswitch 虚拟机网络端口和流表配置 rpm systemd   qemu 运行虚拟机 rpm process   kernel onecloud 提供的内核 rpm -    环境   操作系统: Centos 7.x\n  硬件要求:\n Virtualization: CPU 要支持虚拟化，用于虚拟机 KVM 加速 打开 iommu，VT-d: 用于 GPU 透传(不用GPU可以不开)    网络:\n 当前可用的网段: 虚拟机可以直接使用和计算节点所在的扁平网段，需要预先划分保留对应端给云平台虚拟机使用，防止被其它设备占用，最后 IP 冲突    备注:\n 如果是以测试为目的，可以拿一台虚拟机部署计算节点的服务，但可能无法使用 KVM 加速和 GPU 透传    安装依赖 计算节点所需的依赖以 rpm 的方式安装\n# 添加 yum 源 $ cat \u003c\u003cEOF \u003e/etc/yum.repos.d/yunion.repo [yunion] name=Packages for Yunion Multi-Cloud Platform baseurl=https://iso.yunion.cn/yumrepo-3.3 sslverify=0 failovermethod=priority enabled=1 gpgcheck=0 EOF # 禁用防火墙和selinux $ systemctl disable firewalld $ sed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/config 安装 rpm 包\n$ yum --disablerepo='*' --enablerepo='yunion*' install -y \\  epel-release libaio jq libusb lvm2 nc ntp fetchclient fuse fuse-devel fuse-libs \\  oniguruma pciutils spice spice-protocol sysstat tcpdump usbredir \\  yunion-qemu-2.12.1 yunion-executor-server \\  kernel-3.10.0-1062.4.3.el7.yn20191203 \\  kernel-devel-3.10.0-1062.4.3.el7.yn20191203 \\  kernel-headers-3.10.0-1062.4.3.el7.yn20191203 \\  kmod-openvswitch \\  openvswitch net-tools $ systemctl enable --now yunion-executor # 安装完成后需要重启进入我们的内核 $ reboot # 重启完成后，查看当前节点内核信息，确保为 yn 内核 $ uname -r 3.10.0-1062.4.3.el7.yn20191203.x86_64 安装 docker 和 kubelet 参考 “部署集群/环境准备” 的流程，安装好 docker 和 kubelet。\n控制节点操作 以下操作在控制节点进行。\n创建计算节点所在的网段 我的环境计算节点的 ip 为 10.168.222.140，就创建一个对应的 计算节点(host)网段。\n提示 需要根据自己的计算节点环境创建对应的网段，如果不创建该网段，计算节点就没法注册进来。  # 查看当前环境的 zone $ climc zone-list +--------------------------------------+-------+--------+----------------+ | ID | Name | Status | Cloudregion_ID | +--------------------------------------+-------+--------+----------------+ | f73a2120-1206-45fa-8d43-de374ab0f494 | zone0 | enable | default | +--------------------------------------+-------+--------+----------------+ # 在 zone0 里面创建一个 wire bcast0，该资源抽象计算节点所在的二层广播域信息 $ climc wire-create zone0 bcast0 1000 # 在 wire bcast0 之上创建一个计算节点的网络，计算节点的 host 服务注册会用到，如果 host 注册时没有在云平台找到对应的网络，将会注册失败 $ climc network-create --gateway 10.168.222.1 --server-type baremetal bcast0 adm0 10.168.222.140 10.168.222.140 24 计算节点(host)操作 以下操作在计算节点进行，计算节点也叫 host，私有云计算节点上面会运行 host 服务来管理 kvm 虚拟机。\n配置 host 服务 参考 “添加节点/获取加入集群token” 的流程获取join所需的信息\n# 使用 ocadm join 来创建一台计算节点 # 可选参数 --host-networks: 配置host服务的网络，比如: 'eth0/br0/10.168.222.140', eth0是物理网卡，br0是网桥名称，10.168.222.140是宿主机的ip # 获取计算节点 IP $ host_addr=$(ip route get 1 | awk '{print $NF;exit}') $ echo $host_addr 10.168.222.140 # 可选参数 --host-local-image-path: 配置host服务磁盘的存储路径，比如: '/opt/cloud/workspace/disks' # 注意：容器部署的host服务只会挂载/opt/cloud目录 # 如果有其他挂载点需要bind mount到/opt/cloud下，可在fstab中添加一行如'/src /opt/cloud/dst none defaults,bind 0 0' # 可选参数 --host-hostname: 配置宿主机的hostname, 比如: 'node1' $ ./ocadm join $api_server_addr \\  --enable-host-agent \\  --token $token \\  --discovery-token-unsafe-skip-ca-verification # 然后等待宿主机上的host pod和host-deployer pod为running状态 控制节点启用 host 回到控制节点，启用刚才上报的计算节点，只有启用的宿主机才能运行虚拟机。\n# 使用 climc 查看注册的 host 列表 $ climc host-list +--------------------------------------+-------------------------+-------------------+----------------+----------------------------+---------+---------+-------------+----------+-----------+------------+---------------+--------------+------------+-------------------------+--------------+ | ID | Name | Access_mac | Access_ip | Manager_URI | Status | enabled | host_status | mem_size | cpu_count | node_count | sn | storage_type | host_type | version | storage_size | +--------------------------------------+-------------------------+-------------------+----------------+----------------------------+---------+---------+-------------+----------+-----------+------------+---------------+--------------+------------+-------------------------+--------------+ | 3830870e-a499-459d-89df-bb6979b5e1ff | lzx-allinone-standalone | 00:22:39:4c:6c:e9 | 10.168.222.140 | http://10.168.222.140:8885 | running | false | online | 8192 | 4 | 1 | Not Specified | rotate | hypervisor | master(7ab047419092301) | 50141 | +--------------------------------------+-------------------------+-------------------+----------------+----------------------------+---------+---------+-------------+----------+-----------+------------+---------------+--------------+------------+-------------------------+--------------+ *** Total: 0 Pages: 0 Limit: 20 Offset: 0 Page: 1 *** # 启动 host $ climc host-enable lzx-allinone-standalone 创建虚拟机测试 上传 cirrors 测试镜像 # 下载 cirros 测试镜像 $ wget https://iso.yunion.cn/yumrepo-2.10/images/cirros-0.4.0-x86_64-disk.qcow2 # 将镜像上传到 glance $ climc image-upload --format qcow2 --os-type Linux --min-disk 10240 cirros-0.4.0-x86_64-disk.qcow2 ./cirros-0.4.0-x86_64-disk.qcow2 # 查看上传的镜像 $ climc image-list +--------------------------------------+--------------------------------+-------------+----------+-----------+----------+---------+--------+----------------------------------+ | ID | Name | Disk_format | Size | Is_public | Min_disk | Min_ram | Status | Checksum | +--------------------------------------+--------------------------------+-------------+----------+-----------+----------+---------+--------+----------------------------------+ | 63f6f2af-4db2-4e30-85f5-0ad3baa27bd9 | cirros-0.4.0-x86_64-disk.qcow2 | qcow2 | 22806528 | false | 30720 | 0 | active | 76dc07d1a730a92d0db7fb2d3c305ecd | +--------------------------------------+--------------------------------+-------------+----------+-----------+----------+---------+--------+----------------------------------+ # 如果使用虚拟机作为计算节点，存储可能不大，可以把镜像的默认大小30g调整到10g $ climc image-update --min-disk 10240 cirros-0.4.0-x86_64-disk.qcow2 创建测试网络 下面是随机创建了一个主机间不可达的网络用于测试，如果有划分好的扁平二层可用网络，可以直接拿来给虚拟机使用。\n$ climc network-create --gateway 10.20.30.1 --server-type guest bcast0 vnet0 10.20.30.2 10.20.30.254 24 $ climc network-public vnet0 创建虚拟机 # 创建虚拟机 testvm01，512M内存, 1个CPU, 系统盘 10g, 第二块磁盘 5g 格式化为 ext4 并挂载到 /opt 的虚拟机 $ climc server-create --auto-start --allow-delete \\ \t--disk cirros-0.4.0-x86_64-disk.qcow2:10g --disk 5g:ext4:/opt \\ \t--net vnet0 --ncpu 1 --mem-spec 512M testvm01 # 查看创建的虚拟机，1分钟后应该会变为 running 状态 $ climc server-list --details +--------------------------------------+----------+--------------+--------------+-------+---------+------------+-----------+----------+-----------------------------+------------+---------+-------------------------+--------+-----------+ | ID | Name | Billing_type | IPs | Disk | Status | vcpu_count | vmem_size | Secgroup | Created_at | Hypervisor | os_type | Host | Tenant | is_system | +--------------------------------------+----------+--------------+--------------+-------+---------+------------+-----------+----------+-----------------------------+------------+---------+-------------------------+--------+-----------+ | bcda7d18-decc-4b5f-8654-2d201a84d1fb | testvm01 | postpaid | 10.20.30.254 | 35840 | running | 1 | 512 | Default | 2019-09-23T05:08:49.000000Z | kvm | Linux | lzx-allinone-standalone | system | false | +--------------------------------------+----------+--------------+--------------+-------+---------+------------+-----------+----------+-----------------------------+------------+---------+-------------------------+--------+-----------+ *** Total: 0 Pages: 0 Limit: 20 Offset: 0 Page: 1 *** # 获取虚拟机登录信息 $ climc server-logininfo testvm01 +-----------+------------------------------------------+ | Field | Value | +-----------+------------------------------------------+ | login_key | 49wqh5OWGW3jSr1A8RfrMoH69iRRECzaMZITBA== | | password | zS27FwwUFr96 | | updated | 2019-09-23T05:11:29.306403Z | | username | root | +-----------+------------------------------------------+ # 在计算节点联通测试网络(如果你是直接用的二层网络，应该能直接 ping 通虚拟机的 ip 了，不需要做这一步) $ ip address add 10.20.30.1/24 dev br0 # 用之前 server-logininfo 命令获取的用户名密码，直接登录到虚拟机里面 $ ssh root@10.20.30.254 PING 10.20.30.254 (10.20.30.254) 56(84) bytes of data. 64 bytes from 10.20.30.254: icmp_seq=1 ttl=64 time=1.31 ms # 如果网络不通，也可以通过 vnc 的方式打开虚拟机的 tty 登录界面，操作如下 # 打开 vnc 链接，用浏览器打开下面的链接 # 打开 vnc 链接时会出现不安全认证，导致 websocket 无法握手，需要在浏览器信任 webconsole server 对应的 endpoint $ climc endpoint-list --details | grep webconsole | grep public | 3da1e476aa7b4ff68e206754aed72d8f | region0 | 16120e8f3eec46dc86c59b3e426b0502 | webconsole | webconsole | https://10.168.222.218:8899 | public | true | # 然后用浏览器访问下 https://10.168.222.218:8899 , 信任该链接即可 # 在通过 webconsole-server 命令获取 vnc web 界面的链接地址，然后用浏览器打开该地址 $ climc webconsole-server testvm01 https://console.yunion.cn/web-console?access_token=FI-VXQSAonhzfSnxVTKCCbwHinp7swlRkmi-4p6s-4OfZpg6TG9YhWuwbHEUA1D7XoKu_w%3D%3D\u0026api_server=https%3A%2F%2F10.168.222.216%3A8899\u0026password=65xB2kaE\u0026protocol=vnc ","excerpt":"如果需要构建内部私有云，就需要部署计算节点(宿主机)。计算节点主要负责虚拟机、网络和存储的管理，需要安装的组件如下:\n   组件 用途 安装 …","ref":"/v3.3/docs/setup/host/","title":"添加计算节点"},{"body":"启用 baremetal-agent 之前需要部署 onecloud 集群，详见 “安装部署/部署集群”\n待集群准备完毕后指定 node 来部署 baremetal-agent 服务\n启用 baremetal-agent 在通过 pxe 引导流程中，baremetal-agent 只会处理来自 dhcp relay 服务器的请求, 所以你需要事先在交换机配置 dhcp relay 或者使用 onecloud host 服务的 dhcp relay 功能。\n如何配置 host 服务 启用 dhcp relay # 登录到已经部署好计算节点的服务器上修改 /etc/yunion/host.conf，添加 dhcp_relay 配置项： dhcp_relay: - 10.168.222.198 # baremetal agent dhcp服务监听地址 - 67 # baremetal agent dhcp服务监听端口 # 然后重启host服务 $ kubectl get pods -n onecloud -o wide | grep host default-host-p6d8h 2/2 Running 0 78m 10.168.222.189 k8s-dev1 \u003cnone\u003e \u003cnone\u003e default-host-xdc7x 2/2 Running 0 78m 10.168.222.150 k8s-dev2 \u003cnone\u003e \u003cnone\u003e # 找到对应的 pod 删除等待 host 服务自动重启 $ kubectl delete pods -n onecloud default-host-xdc7x 启用 baremetal-agent 然后选择 node 启用 baremetal-agent。\n# $listen_interface 指的是 baremetal-agent 监听的网卡名称 $ ocadm baremetal enable --node $node_name --listen-interface $listen_interface # 观察 baremetal agent pod 状态查看是否启动成功 $ watch \"kubectl get pods -n onecloud | grep baremetal\" default-baremetal-agent-7c84996c9b-hhllw 1/1 Running 0 3m10s # 启动成功确认 baremetal-agent 注册到控制节点 $ climc agent-list +--------------------------------------+--------------------------+----------------+-----------------------------+---------+------------+------------------------------------------+--------------------------------------+ | ID | Name | Access_ip | Manager_URI | Status | agent_type | version | zone_id | +--------------------------------------+--------------------------+----------------+-----------------------------+---------+------------+------------------------------------------+--------------------------------------+ | f3c2c671-c41d-4f30-8d04-e022b49bb9b5 | baremetal-10.168.222.150 | 10.168.222.150 | https://10.168.222.150:8879 | enabled | baremetal | remotes/origin/master(5e415506120011509) | 6230b485-2e54-480e-8284-33360b8202a8 | +--------------------------------------+--------------------------+----------------+-----------------------------+---------+------------+------------------------------------------+--------------------------------------+ 部署完成后可以参考 “操作管理/物理机” 来进行对物理机的注册管理\n禁用 baremetal-agent 可以在启用 baremetal-agent 的节点中选择节点禁止 baremetal-agent 调度到该节点。\nocadm baremetal disable --node $node_name ","excerpt":"启用 baremetal-agent 之前需要部署 onecloud 集群，详见 “安装部署/部署集群”\n待集群准备完毕后指定 node 来 …","ref":"/v3.3/docs/setup/baremetal/","title":"物理机管理服务"},{"body":"默认情况下部署好的版本是 开源版本(CE: Community Edition)，可以使用 ocadm cluster update 命令切换成 企业版本(EE: Enterprise Edition)。\n切换操作 # 切换到企业版 $ ocadm cluster update --use-ee --wait # 切换到开源版的 web 前端 $ ocadm cluster update --use-ce --wait ocadm cluster update --use-ee/--use-ce 命令会更新替换当前的 default-web deployment，执行该命令后等到新的 pod 启动后，重新刷新前端页面，即可进入(开源版/企业版)前端。\n常见问题 访问前端出现错误 问题原因: 开源与企业版本的前端分别依赖不同的 default-web configmap，直接切换过去会导致 default-web configmap 没有更新，会造成企业版本使用开源版本 configmap 的问题。\n解决办法: 在控制节点上删除 web 服务的 nginx configmap 配置文件，并重启 web 服务即可。\n# 删除 default-web 的 configmap 文件 $ kubectl delete configmap -n onecloud default-web # 重启 default-web 服务 $ kubectl rollout restart deployment -n onecloud default-web ","excerpt":"默认情况下部署好的版本是 开源版本(CE: Community Edition)，可以使用 ocadm cluster update 命令切 …","ref":"/v3.3/docs/setup/ce-ee-switch/","title":"切换到企业版"},{"body":"","excerpt":"","ref":"/v3.3/docs/contact/","title":"联系我们"},{"body":"宿主机(host): 指运行虚拟机的机器，云平台的抽象的宿主机根据 hypervisor 字段判断不同平台的宿主机。现在支持的类型如下：\n   类型 平台     hypervisor onecloud 私有云宿主机   baremetal onecloud 私有云物理机   esxi vmware 宿主机   openstack openstack 私有云宿主机   zstack zstack 私有云宿主机    ","excerpt":"宿主机(host): 指运行虚拟机的机器，云平台的抽象的宿主机根据 hypervisor 字段判断不同平台的宿主机。现在支持的类型如下： …","ref":"/v3.3/docs/howto/host/","title":"宿主机"},{"body":"创建好主机后，登录的方式大概分为以下几种：\n ssh: linux 通用，要求主机网络可达; rdp: windows 远程桌面，要求主机网络可达； vnc: vnc 链接，对主机网络没有要求，只要能链接云平台 vnc proxy 即可; ipmi sol: 只对装有 BMC 的物理机可用;  针对以上的链接方式，我们提供以下接口链接云主机：\nvnc 链接 climc webconsole-server 命令提供通过 vnc 的方式链接虚拟机，该方式对裸金属服务器不可用。\n$ climc webconsole-server \u003cserver_id\u003e ssh 链接 查询 server 的 ip\n# 可通过 server-list --search --details 的方式找到主机的 ip $ climc server-list --search \u003cserver_name\u003e --details # 或者通过 server-show \u003cserver_id\u003e 的方式得到 ip $ climc server-show \u003cserver_name\u003e | grep ip | ips | 10.168.222.226 | 查询 server 的登录信息\n$ climc server-logininfo \u003cserver_name\u003e +----------+-----------------------------+ | Field | Value | +----------+-----------------------------+ | password | @2aWXB6AmCbV | | updated | 2019-07-03T10:00:20.801716Z | | username | root | +----------+-----------------------------+ ssh 登录\n$ ssh root@10.168.222.226 通过 webconsole 登录\n$ climc webconsole-ssh 10.168.222.226 https://console.yunion.cn/web-console?access_token=y7bjpBwtvJHLHpwOUMzNVvsYiAgY1vskIuVwB-aINfH4mm8MsZqwxKSfHqm2pCvY6O8bBA%3D%3D\u0026api_server=https%3A%2F%2Foffice.yunion.io\u0026protocol=tty 在浏览器打开 webconsole 放回的 url ，就会到对应虚拟机的登录界面\n","excerpt":"创建好主机后，登录的方式大概分为以下几种：\n ssh: linux 通用，要求主机网络可达; rdp: windows 远程桌面，要求主机网 …","ref":"/v3.3/docs/howto/server/connect/","title":"登录云主机"},{"body":"开关机 # 开机 $ climc server-start \u003cserver_id\u003e # 关机 $ climc server-stop \u003cserver_id\u003e # 强制关机 $ climc server-stop --is-force \u003cserver_id\u003e # 重启 $ climc server-restart \u003cserver_id\u003e 删除 # 删除至回收站 $ climc server-delete \u003cserver_id\u003e # 彻底删除 $ climc server-delete -f \u003cserver_id\u003e 重装密码 $ climc server-deploy --reset-password --password \u003cyour_password\u003e \u003cserver_id\u003e TODO\n","excerpt":"开关机 # 开机 $ climc server-start \u003cserver_id\u003e # 关机 $ climc server-stop …","ref":"/v3.3/docs/howto/server/others/","title":"其他操作"},{"body":"术语解释   Baremetal: 指尚未安装操作系统的服务器， 也叫作物理机\n  PXE (Preboot eXecution Environment): 使用网络接口启动计算机的机制。这种机制不依赖本地数据存储设备（如硬盘）或本地已安装的操作系统，使用 DHCP 协议查找引导服务器并获取 IP，再通过 TFTP 协议下载初始引导程序和附加文件启动\n  DHCP (Dynamic Host Configuration Protocol): 动态主机设置协议是一个局域网的网络协议，使用UDP协议工作，为机器分配 IP\n  TFTP (Trivial File Transfer Protocol): 小型文件传输协议，使用UDP协议传输文件\n  DHCP Relay: 在不同子网和物理网段之间处理和转发dhcp信息的功能\n  IPMI (Intelligent Platform Management Interface)：管理服务器硬件的标准，特性是独立于操作系统外自行运行，即使在缺少操作系统或系统管理软件、或受监控的系统关机但有接电源的情况下仍能远程管理系统，也能在操作系统引导后运行\n  BMC (Baseboard management controller): 基板管理控制器，支持行业标准的 IPMI 规范\n  SSH (Secure Shell): 用于远程登录控制服务器\n  RAID (Redundant Array of Independent Disks): 磁盘阵列，把多个硬盘组合成为一个逻辑扇区，操作系统只会把它当作一个硬盘\n  Region Service: 云平台控制服务，提供 baremetal 相关 API\n  Baremetal Agent: 云平台管理 baremetal 的服务\n  Glance Service: 云平台镜像服务，提供物理机装机的 Image 镜像\n  裸金属服务器: baremetal 物理机安装操作系统后，在云平台创建的 server 的记录\n  宿主机: 可以运行云平台虚拟机的节点\n  ","excerpt":"术语解释   Baremetal: 指尚未安装操作系统的服务器， 也叫作物理机\n  PXE (Preboot eXecution …","ref":"/v3.3/docs/howto/baremetal/","title":"物理机"},{"body":"支持将libvirt管理的虚拟机导入到OneCloud\n注意事项   首先需要在libvirt管理的宿主机上安装我们的计算节点\n  安装好计算节点后需要添加的虚拟机的网络到控制节点\n  确保libvirt服务关闭\n  相关操作  准备好需要导入虚拟机的信息文件servers.yaml， 格式如下:  hosts: - host_ip: 10.168.222.137 xml_file_path: /etc/libvirt/qemu monitor_path: /var/lib/libvirt/qemu servers: - mac: 52:54:00:4A:19:AF ip: 10.168.222.53 - mac: 52:54:00:4A:19:CC ip: 10.168.222.54 - host_ip: 10.168.222.130 xml_file_path: /etc/libvirt/qemu monitor_path: /var/lib/libvirt/qemu servers: - mac: 53:54:00:4A:19:EC ip: 11.168.222.50 - mac: 53:54:00:4A:19:EE ip: 11.168.222.51 - `host_ip` 是要导入的宿主机的ip - `xml_file_path`是libvirt存储虚拟机xml文件的路径， - `monitor_path`是libvirt存储虚拟机monitor socket文件的路径， - `servers`是需要导入的虚拟机，里面描述了虚拟机的ip和mac对应关系    执行 climc servers-import-from-libvirt 开始导入  # 导入前确认libvirt服务关闭 $ climc servers-import-from-libvirt servers.yaml ","excerpt":"支持将libvirt管理的虚拟机导入到OneCloud\n注意事项   首先需要在libvirt管理的宿主机上安装我们的计算节点\n  安装好计 …","ref":"/v3.3/docs/howto/server/import/","title":"libvirt管理虚机导入"},{"body":"目前仅支持 OneCloud kvm 虚拟机使用 GPU，使用的 PCI Passthrough 的方式将宿主机上的 Nvidia/AMD GPU 透传给虚拟机使用。\n相关操作 创建 GPU 云主机  查询 gpu 列表  $ climc isolated-device-list --gpu +--------------------------------------+----------+---------------------+---------+------------------+--------------------------------------+ | ID | Dev_type | Model | Addr | Vendor_device_id | Host_id | +--------------------------------------+----------+---------------------+---------+------------------+--------------------------------------+ | 273f4f72-06b6-49aa-8456-4beceec44997 | GPU-HPC | GeForce GTX 1050 Ti | 41:00.0 | 10de:1c82 | 3bce9607-2597-469f-8d9b-977345456739 | | a77333e9-08d9-45c6-87eb-a7d8d902c5f5 | GPU-HPC | Quadro FX 580 | 05:00.0 | 10de:0659 | 3bce9607-2597-469f-8d9b-977345456739 | +--------------------------------------+----------+---------------------+---------+------------------+--------------------------------------+  创建 server  server-create 中的 --isolated-device 参数指定透传的设备到云主机，可以重复使用多次，透传多个 gpu 到云主机，但要求透传到同一云主机的 gpu 必须在同一宿主机。其余创建参数和创建普通云主机是一样的。\n$ climc server-create --hypervisor kvm --isolated-device 273f4f72-06b6-49aa-8456-4beceec44997 ... 查询 GPU 云主机 $ climc server-list --gpu 关联 GPU 如果云主机所在的宿主机有可用的 gpu，在主机关机的情况下，可以通过 server-attach-isolated-device 命令将 gpu 和云主机关联起来，下次主机启动后就可以使用该 gpu 。\n$ climc server-attach-isolated-device \u003cserver_id\u003e \u003cdevice_id\u003e 卸载 GPU 如果云主机关联了 gpu，可以通过 server-detach-isolated-device 卸载主机的某一 gpu。\n$ climc server-detach-isolated-device \u003cserver_id\u003e \u003cdevice_id\u003e ","excerpt":"目前仅支持 OneCloud kvm 虚拟机使用 GPU，使用的 PCI Passthrough 的方式将宿主机上的 Nvidia/AMD …","ref":"/v3.3/docs/howto/server/gpu/","title":"GPU相关"},{"body":"TODO\n","excerpt":"TODO\n","ref":"/v3.3/docs/howto/network/","title":"网络"},{"body":"TODO\n","excerpt":"TODO\n","ref":"/v3.3/docs/howto/lb/","title":"负载均衡"},{"body":"TODO\n","excerpt":"TODO\n","ref":"/v3.3/docs/howto/storage/","title":"存储"},{"body":"TODO\n","excerpt":"TODO\n","ref":"/v3.3/docs/howto/multicloud/","title":"多云管理"},{"body":"TODO\n","excerpt":"TODO\n","ref":"/v3.3/docs/howto/auth/","title":"认证与权限"},{"body":"TODO\n","excerpt":"TODO\n","ref":"/v3.3/docs/howto/server/migrate/","title":"迁移相关"},{"body":"","excerpt":"","ref":"/v3.3/docs/howto/container/","title":"容器集群"},{"body":"TODO\n","excerpt":"TODO\n","ref":"/v3.3/docs/howto/server/backup/","title":"主备机"},{"body":"TODO\n","excerpt":"TODO\n","ref":"/v3.3/docs/howto/scheduler/","title":"资源调度"},{"body":"导入镜像 云平台的 glance 镜像服务支持从外部 url 导入镜像，对应 climc 的子命令为 image-import　。\n# 导入 https://iso.yunion.cn/yumrepo-3.2/images/cirros-0.4.0-x86_64-disk.qcow2 镜像 $ climc image-import --format qcow2 --os-type Linux cirros-test.qcow2 https://iso.yunion.cn/yumrepo-3.2/images/cirros-0.4.0-x86_64-disk.qcow2 使用 image-list 或 image-show 查询导入镜像的状态，变为 active 时表明可以使用。\n下载镜像 如果需要将云平台的镜像导出到本地，就需要用 climc image-download 把 glance 存的镜像下载下来。\n参考 查询镜像 查询你想要下载的镜像，获取镜像 id 或 name。\n下载镜像:\n# OUTPUT 指定镜像的保存路径和文件名称，如/root/test.qcow2 $ climc image-download [--output OUTPUT] \u003cimage_id\u003e 删除镜像 镜像默认启用了删除保护，当镜像确定不用了，需要先通过climc image-update禁用删除保护，再通过 climc image-delete 删除镜像。\n# 禁用镜像删除保护 $ climc image-update --unprotected \u003cimage_id\u003e # 删除镜像 $ climc image-delete \u003cimage_id\u003e ","excerpt":"导入镜像 云平台的 glance 镜像服务支持从外部 url 导入镜像，对应 climc 的子命令为 image-import　。\n# …","ref":"/v3.3/docs/howto/image/operation/","title":"其他操作"},{"body":"本文介绍从 v3.2.x 升级到 v3.3.x 的步骤以及注意事项。\n版本升级建议从相邻的版本升级，比如从 v3.0.x 升级到 v3.2.x 需要以下的步骤：\n v3.0.x =\u003e v3.1.x v3.1.x =\u003e v3.2.x  直接跨多个版本升级可能会出现问题，建议参考以下的内容选择升级步骤:\n v3.1.x 升级到 v3.2.x  总体来说，升级的步骤如下:\n 更新 rpm 源，升级 ocadm 使用 ocadm 升级 OneCloud 服务  查看当前版本 可以使用 kubectl 查看当前集群的版本\n# 使用 kubectl 获得当前集群的版本为 v3.2.3 $ kubectl -n onecloud get onecloudclusters default -o=jsonpath='{.spec.version}' v3.2.3 更新 rpm repo ocadm 和 climc 这些命令行工具是以 yum rpm 包的方式安装，所以升级之前需要先更新这两个工具，然后再使用 ocadm 升级 OneCloud 服务。\n# 修改 baseurl，把 3.2 改成 3.3 $ sed -i 's|baseurl.*|baseurl=https://iso.yunion.cn/3.3|g' /etc/yum.repos.d/yunion.repo # 更新 yunion-ocadm, yunion-climc $ yum clean all $ yum install -y yunion-ocadm yunion-climc # 查看 ocadm 版本 $ ocadm version -o short tags/v3.3.0(bece1be20080211) 更新 OneCloud 服务 # 使用 ocadm 更新 onecloud operator 以及相关服务到 v3.3.0 版本 # 该步骤会因为拉取 docker 镜像等待较长时间，请耐心等待 $ ocadm cluster update --operator-version v3.3.0 --version v3.3.0 --wait # 另外可以在升级的过程中使用 kubectl 查看对应 pods 的升级情况 $ kubectl get pods -n onecloud --watch ","excerpt":"本文介绍从 v3.2.x 升级到 v3.3.x 的步骤以及注意事项。\n版本升级建议从相邻的版本升级，比如从 v3.0.x …","ref":"/v3.3/docs/setup/upgrade/","title":"升级相关"},{"body":"","excerpt":"","ref":"/v3.3/search/","title":"Search Results"},{"body":"    开源融合云平台   An open Source Unified Cloud platform\nTo unify many distinct clouds into the one that behaves like an integral cloud platform.        融合云  =   Embedded Private Cloud   +   Unified API 统一API   +   Unified Identity 统一认证   +   Unified Networking 融合网络   +   Kubernetes     融合云架构    支持云平台和技术               谁在用         @2020 Yunion.io       ","excerpt":"    开源融合云平台   An open Source Unified Cloud platform\nTo unify many …","ref":"/v3.3/","title":"TechOS"},{"body":"欢迎查看 OneCloud 文档，本文档会介绍 OneCloud 服务安装部署、资源操作管理和开发贡献等内容。\n什么是 OneCloud? OneCloud 是一个开源的多云平台。构建在用户分布于多云基础设施之上，通过技术手段将分分布于多云的异构IT资源统一管理，将多底层多云的差异向用户屏蔽，并通过网络和调度实现资源的融合与打通，在多云之上进行抽象，向用户呈现统一的使用界面和API接口，让用户就像使用一个云平台一样使用分布于多云的资源，实现一个统一的“云上之云”的云平台。\nOneCloud 具备以下功能特性:\n  多云资源统一管理\n统一API、镜像、调度、账号体系、监控和计费等操作，能够全面管理 On premises、 私有云、公有云资源。\n  内置私有云\nOneCloud内置完备的私有云实现，提供对用户本地IDC的虚拟机、物理机和负载均衡等资源管理。\n  为多云Kubernetes提供运行环境\nOneCloud自身为运行在Kubernetes的云原生应用，并且能在多云环境部署运行Kubernetes集群。\n  从哪开始? 文档分为以下部分：\n  安装部署: 安装和部署 onecloud 各个服务与组件\n  开发贡献: 搭建开发环境，提交 PR\n  操作管理: 介绍如何操作云平台资源和管理服务\n  ","excerpt":"欢迎查看 OneCloud 文档，本文档会介绍 OneCloud 服务安装部署、资源操作管理和开发贡献等内容。\n什么是 OneCloud? …","ref":"/v3.3/docs/","title":"欢迎来到 OneCloud"}]