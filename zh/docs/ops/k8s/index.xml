<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Cloudpods –
Kubernetes运维</title><link>https://www.cloudpods.org/zh/docs/ops/k8s/</link><description>Recent content in Kubernetes运维 on Cloudpods</description><generator>Hugo -- gohugo.io</generator><lastBuildDate>Wed, 28 Jun 2023 14:45:50 +0800</lastBuildDate><atom:link href="https://www.cloudpods.org/zh/docs/ops/k8s/index.xml" rel="self" type="application/rss+xml"/><item><title>Docs: 排查pod异常</title><link>https://www.cloudpods.org/zh/docs/ops/k8s/poderror/</link><pubDate>Wed, 10 Nov 2021 16:02:27 +0800</pubDate><guid>https://www.cloudpods.org/zh/docs/ops/k8s/poderror/</guid><description>
&lt;h3 id="确认pod状态">确认Pod状态&lt;/h3>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#8f5902;font-style:italic"># 设置默认命名空间，后续执行相关命令时可以不带“-n onecloud” &lt;/span>
$ kubectl config set-context --current --namespace&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>onecloud
&lt;span style="color:#8f5902;font-style:italic"># 查看 pod 状态&lt;/span>
$ kubectl get pod
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="检查pod相关事件">检查pod相关事件&lt;/h3>
&lt;p>当查看到 pod 状态不是 running 状态时，可以通过 describe 命令查看更多信
息。&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#8f5902;font-style:italic"># 举例为查看 host 服务的 pod 的事件信息&lt;/span>
$ kubectl describe pod default-host-z8j5r
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="查看日志">查看日志&lt;/h3>
&lt;p>可以通过检查日志来查看应用程序是否正常运行。&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#8f5902;font-style:italic"># 查看 host 服务的日志信息&lt;/span>
$ kubectl logs default-host-z8j5r -c host -f
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="pod常见错误及处理方法">Pod常见错误及处理方法&lt;/h3>
&lt;h4 id="pod---crashloopbackoff状态">Pod - CrashLoopBackOff状态&lt;/h4>
&lt;p>CrashLoopBackOff 状态说明容器曾经启动了，但又异常退出。此时可以先查看
一下容器的日志。通过 kubectl logs 命令可以发现一些容器退出的原因:&lt;/p>
&lt;ul>
&lt;li>通过查看日志发现是脏数据导致的&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>root@test ~&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>&lt;span style="color:#8f5902;font-style:italic">#kubectl get pod | grep region&lt;/span>
default-region-75bc7d474f-rjpkm 0/1
CrashLoopBackOff &lt;span style="color:#0000cf;font-weight:bold">12&lt;/span> 2d20h
default-region-dns-88s7z 1/1 Running
&lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> 2d20h
&lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>root@test ~&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>&lt;span style="color:#8f5902;font-style:italic"># kubectl logs default-region-75bc7d474f￾rjpkm | less&lt;/span>
&lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>I &lt;span style="color:#0000cf;font-weight:bold">200618&lt;/span> 16:13:32
appsrv.&lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>*Application&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>.ServeHTTP&lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>appsrv.go:237&lt;span style="color:#ce5c00;font-weight:bold">)]&lt;/span>
hlgxXm4i2qF10tkBXu3rAVrCC-w&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">200&lt;/span> b5e0b2 GET
/networks?admin&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>true&lt;span style="color:#000;font-weight:bold">&amp;amp;&lt;/span>&lt;span style="color:#000">delete&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>all&lt;span style="color:#000;font-weight:bold">&amp;amp;&lt;/span>&lt;span style="color:#000">details&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>true&lt;span style="color:#000;font-weight:bold">&amp;amp;&lt;/span>filter.0&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>updated_at.
ge%28%272020-06-
03+07%3A56%3A04%27%29&lt;span style="color:#000;font-weight:bold">&amp;amp;&lt;/span>filter.1&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>manager_id.isnullorempty%28%29&lt;span style="color:#000;font-weight:bold">&amp;amp;&lt;/span>fil
ter.2&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>external_id.isnullorempty%28%29&lt;span style="color:#000;font-weight:bold">&amp;amp;&lt;/span>&lt;span style="color:#000">limit&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>1024&lt;span style="color:#000;font-weight:bold">&amp;amp;&lt;/span>&lt;span style="color:#000">offset&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>0&lt;span style="color:#000;font-weight:bold">&amp;amp;&lt;/span>&lt;span style="color:#000">order&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>a
sc&lt;span style="color:#000;font-weight:bold">&amp;amp;&lt;/span>order_by.0&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>updated_at&lt;span style="color:#000;font-weight:bold">&amp;amp;&lt;/span>&lt;span style="color:#000">pending_delete&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>all &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>10.105.232.12:55236&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
34.50ms
&lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>F &lt;span style="color:#0000cf;font-weight:bold">200618&lt;/span> 16:13:32 models.&lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>*SGuest&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>.GetDriver&lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>guests.go:557&lt;span style="color:#ce5c00;font-weight:bold">)]&lt;/span>
Unsupported hypervisor Aliyun
&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>pod 中对应的配置文件中格式不对&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="../images/configmaperror.png" alt="">&lt;/p>
&lt;h4 id="pod---evicted状态">Pod - Evicted状态&lt;/h4>
&lt;p>出现这种情况，多见于系统内存或硬盘资源不足。通过“kubectl describe命令”查看异常pod。&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>root@test-interface ~&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>&lt;span style="color:#8f5902;font-style:italic"># kubectl describe -n onecloud pod default-ovn-north-7689f47894-tqp2g&lt;/span>
Name: default-ovn-north-7689f47894-tqp2g
Namespace: onecloud
Priority: &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
Node: test-interface/
Start Time: Fri, &lt;span style="color:#0000cf;font-weight:bold">20&lt;/span> Mar &lt;span style="color:#0000cf;font-weight:bold">2020&lt;/span> 18:38:27 +0800
Labels: &lt;span style="color:#000">app&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>ovn-north
app.kubernetes.io/component&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>ovn-north
app.kubernetes.io/instance&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>onecloud-cluster-8p2p
app.kubernetes.io/managed-by&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>onecloud-operator
app.kubernetes.io/name&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>onecloud-cluster
pod-template-hash&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>7689f47894
Annotations: cni.projectcalico.org/podIP: 10.40.180.212/32
onecloud.yunion.io/last-applied-configuration:
&lt;span style="color:#ce5c00;font-weight:bold">{&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;volumes&amp;#34;&lt;/span>:&lt;span style="color:#ce5c00;font-weight:bold">[{&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;name&amp;#34;&lt;/span>:&lt;span style="color:#4e9a06">&amp;#34;certs&amp;#34;&lt;/span>,&lt;span style="color:#4e9a06">&amp;#34;secret&amp;#34;&lt;/span>:&lt;span style="color:#ce5c00;font-weight:bold">{&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;secretName&amp;#34;&lt;/span>:&lt;span style="color:#4e9a06">&amp;#34;default-certs&amp;#34;&lt;/span>,&lt;span style="color:#4e9a06">&amp;#34;items&amp;#34;&lt;/span>:&lt;span style="color:#ce5c00;font-weight:bold">[{&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;key&amp;#34;&lt;/span>:&lt;span style="color:#4e9a06">&amp;#34;ca.crt&amp;#34;&lt;/span>,&lt;span style="color:#4e9a06">&amp;#34;path&amp;#34;&lt;/span>:&lt;span style="color:#4e9a06">&amp;#34;ca.crt&amp;#34;&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">}&lt;/span>,&lt;span style="color:#ce5c00;font-weight:bold">{&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;key&amp;#34;&lt;/span>:&lt;span style="color:#4e9a06">&amp;#34;service.crt&amp;#34;&lt;/span>,&lt;span style="color:#4e9a06">&amp;#34;path&amp;#34;&lt;/span>:&lt;span style="color:#4e9a06">&amp;#34;...
&lt;/span>&lt;span style="color:#4e9a06">Status: Failed
&lt;/span>&lt;span style="color:#4e9a06">Reason: Evicted
&lt;/span>&lt;span style="color:#4e9a06">Message: The node was low on resource: ephemeral-storage. Container ovn-north was using 109956Ki, which exceeds its request of 0.
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="pod---imagepullbackoff状态">Pod - ImagePullBackOff状态&lt;/h4>
&lt;p>通常是镜像名称配置错误或者私有镜像的密钥配置错误导致。通过“kubectl describe命令”查看异常pod。&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">Events:
Type Reason Age From Message
---- ------ ---- ---- -------
Normal Scheduled 35s default-scheduler Successfully assigned onecloud/default-region-85ff9dcd5-mh8cl to yunion320
Normal Pulling 34s kubelet, yunion320 Pulling image &lt;span style="color:#4e9a06">&amp;#34;registry.cn-beijing.aliyuncs.com/yunionio/region:v3.2.1&amp;#34;&lt;/span>
Normal Pulled 33s kubelet, yunion320 Successfully pulled image &lt;span style="color:#4e9a06">&amp;#34;registry.cn-beijing.aliyuncs.com/yunionio/region:v3.2.1&amp;#34;&lt;/span>
Normal Created 33s kubelet, yunion320 Created container init
Normal Started 33s kubelet, yunion320 Started container init
Normal Pulling 15s &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>x2 over 28s&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span> kubelet, yunion320 Pulling image &lt;span style="color:#4e9a06">&amp;#34;registry.cn-beijing.aliyuncs.com/yunionio/region:v3.2.2&amp;#34;&lt;/span>
Warning Failed 15s &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>x2 over 28s&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span> kubelet, yunion320 Failed to pull image &lt;span style="color:#4e9a06">&amp;#34;registry.cn-beijing.aliyuncs.com/yunionio/region:v3.2.2&amp;#34;&lt;/span>: rpc error: &lt;span style="color:#000">code&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> Unknown &lt;span style="color:#000">desc&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> Error response from daemon: manifest &lt;span style="color:#204a87;font-weight:bold">for&lt;/span> registry.cn-beijing.aliyuncs.com/yunionio/region:v3.2.2 not found: manifest unknown: manifest unknown
Warning Failed 15s &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>x2 over 28s&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span> kubelet, yunion320 Error: ErrImagePull
Normal BackOff 3s kubelet, yunion320 Back-off pulling image &lt;span style="color:#4e9a06">&amp;#34;registry.cn-beijing.aliyuncs.com/yunionio/region:v3.2.2&amp;#34;&lt;/span>
Warning Failed 3s kubelet, yunion320 Error: ImagePullBackOff
&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="pod---pending状态">Pod - Pending状态&lt;/h4>
&lt;p>Pending状态，这个状态意味着，Pod的yaml文件已经提交给Kubernetes，API对象已经被创建并保存在Etcd 当中。但是，这个Pod里有些容器因为某种原因而不能被顺利创建。&lt;/p>
&lt;ul>
&lt;li>调度不成功（可以通过 kubectl describe pod 命令查看到当前 Pod 的事件，进而判断为什么没有调度）。&lt;/li>
&lt;li>可能原因： 资源不足（集群内所有的 Node 都不满足该 Pod 请求的 CPU、内存、GPU 等资源）；&lt;/li>
&lt;li>HostPort 已被占用（通常推荐使用 Service 对外开放服务端口）。&lt;/li>
&lt;/ul>
&lt;h4 id="pod---error状态">Pod - Error状态&lt;/h4>
&lt;p>通常处于 Error 状态说明 Pod 启动过程中发生了错误。常见的原因包括：&lt;/p>
&lt;ul>
&lt;li>依赖的 ConfigMap、Secret 或者 PV 等不存在；&lt;/li>
&lt;li>请求的资源超过了管理员设置的限制，比如超过了 LimitRange 等；&lt;/li>
&lt;li>违反集群的安全策略，比如违反了 PodSecurityPolicy 等；&lt;/li>
&lt;li>容器无权操作集群内的资源，比如开启 RBAC 后，需要为 ServiceAccount 配置角色绑定;&lt;/li>
&lt;/ul></description></item><item><title>Docs: 排查Pod网络问题</title><link>https://www.cloudpods.org/zh/docs/ops/k8s/dnserror/</link><pubDate>Fri, 02 Dec 2022 16:02:27 +0800</pubDate><guid>https://www.cloudpods.org/zh/docs/ops/k8s/dnserror/</guid><description>
&lt;p>经常遇到Pod内服务报DNSError的错误，例如：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-json" data-lang="json">&lt;span style="color:#000;font-weight:bold">{&lt;/span>&lt;span style="color:#204a87;font-weight:bold">&amp;#34;error&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:{&lt;/span>&lt;span style="color:#204a87;font-weight:bold">&amp;#34;class&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;DNSError&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#204a87;font-weight:bold">&amp;#34;code&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">499&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#204a87;font-weight:bold">&amp;#34;details&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;Post \&amp;#34;https://default-kevstone:30357/v3/auth/tokens\&amp;#34;: dial tcp: lookup default-kevstone: i/o timeout&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">}}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>这类错误一般意味着Pod之间的网络通信有问题。因为Pod之间通信一般最先要进行对端的DNS解析，由于到达coredns的Pod网络不通，导致DNS解析错误，因此最先暴露出来的是DNSError的错误。&lt;/p>
&lt;h2 id="基本原理">基本原理&lt;/h2>
&lt;p>Pod内通过集群的coredns进行域名解析。CoreDNS配置了10.96.0.10的service IP。访问coredns时，首先由kubeproxy实现service IP到Pod IP的NAT转换，如果Pod在本节点，则直接访问Pod。否则通过tunl0以IP-in-IP或VXLAN隧道发送到对端Pod所在节点，进而解封装投递到目标Pod。&lt;/p>
&lt;p>Cloudpods 在每个节点采用IPVS作为Service IP到Pod IP的NAT转换。需确保节点的IPVS规则表有对应10.96.0.10的NAT规则。&lt;/p>
&lt;p>Cloudpods 采用calico作为容器网络的插件，采用IP-in-IP或VXLAN隧道作为Pod之间报文的封装协议。&lt;/p>
&lt;p>如果采用IP-in-IP隧道，则在每个节点上都有一个 tunl0 的三层虚拟网络接口，该接口作为该节点IP-in-IP隧道的端点。&lt;/p>
&lt;p>如果采用VXLAN隧道，则在每个节点上都有一个 vxlan.calico 的二层虚拟网络接口，该接口作为该节点 VXLAN 隧道的端点。&lt;/p>
&lt;p>Pod的IP从10.40.0.0/16 (该网络前缀可以在ocboot初始化时配置) 随机分配。每个节点上都会为集群中其他节点的Pod所在的/26网段（含64个IP地址）配置通过tunl0且下一跳为该Pod所在节点IP的静态路由。如果缺少对应Pod的路由，则也会出现Pod之间网络不通。&lt;/p>
&lt;h3 id="calico隧道协议的切换">Calico隧道协议的切换&lt;/h3>
&lt;p>Cloudpods默认采用IP-in-IP隧道协议，可以在Kubernetes控制节点执行以下命令将Calico隧道协议切换为 VXLAN。常见切换原因为底层网络不支持IP-in-IP协议。&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#204a87">export&lt;/span> &lt;span style="color:#000">DATASTORE_TYPE&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>kubernetes
calicoctl patch felixconfig default -p &lt;span style="color:#4e9a06">&amp;#39;{&amp;#34;spec&amp;#34;:{&amp;#34;vxlanEnabled&amp;#34;:true}}&amp;#39;&lt;/span>
calicoctl patch ippool default-ipv4-ippool -p &lt;span style="color:#4e9a06">&amp;#39;{&amp;#34;spec&amp;#34;:{&amp;#34;ipipMode&amp;#34;:&amp;#34;Never&amp;#34;, &amp;#34;vxlanMode&amp;#34;:&amp;#34;Always&amp;#34;}}&amp;#39;&lt;/span> &lt;span style="color:#8f5902;font-style:italic">## wait for the vxlan.calico interface to be created and traffic to be routed through it&lt;/span>
calicoctl patch felixconfig default -p &lt;span style="color:#4e9a06">&amp;#39;{&amp;#34;spec&amp;#34;:{&amp;#34;ipipEnabled&amp;#34;:false}}&amp;#39;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="原因排查">原因排查&lt;/h2>
&lt;h3 id="service-ip-nat问题">Service IP NAT问题&lt;/h3>
&lt;p>在无法DNS解析Pod所在节点执行如下命令，确认IPVS的转发表内有相应的表项：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">ipvsadm -Ln &lt;span style="color:#000;font-weight:bold">|&lt;/span> grep -A &lt;span style="color:#0000cf;font-weight:bold">3&lt;/span> 10.96.0.10
&lt;/code>&lt;/pre>&lt;/div>&lt;p>正常应该有三个表项：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">TCP 10.96.0.10:53 rr
-&amp;gt; 10.40.52.149:53 Masq &lt;span style="color:#0000cf;font-weight:bold">1&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
-&amp;gt; 10.40.52.171:53 Masq &lt;span style="color:#0000cf;font-weight:bold">1&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
TCP 10.96.0.10:9153 rr
-&amp;gt; 10.40.52.149:9153 Masq &lt;span style="color:#0000cf;font-weight:bold">1&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
-&amp;gt; 10.40.52.171:9153 Masq &lt;span style="color:#0000cf;font-weight:bold">1&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
UDP 10.96.0.10:53 rr
-&amp;gt; 10.40.52.149:53 Masq &lt;span style="color:#0000cf;font-weight:bold">1&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">6930&lt;/span>
-&amp;gt; 10.40.52.171:53 Masq &lt;span style="color:#0000cf;font-weight:bold">1&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">6859&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="路由问题">路由问题&lt;/h3>
&lt;p>如果上一步确认无误，在无法DNS解析Pod所在节点查看到达coredns的Pod IP的路由是否存在，假设coredns的节点IP为上述10.40.52.149和10.40.52.171，则执行如下命令确认相应路由是否存在：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">ip route &lt;span style="color:#000;font-weight:bold">|&lt;/span> grep 10.40.52
&lt;/code>&lt;/pre>&lt;/div>&lt;p>正确输出如下：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">10.40.52.128/26 via 10.41.1.21 dev tunl0 proto bird onlink
&lt;/code>&lt;/pre>&lt;/div>&lt;p>这里 10.41.1.21 应该是coredns Pod所在节点的IP&lt;/p>
&lt;h3 id="端口问题">端口问题&lt;/h3>
&lt;p>如上一步确认无误，则Pod的报文能够正确通过tunl0经过ip-in-ip隧道发出，则需要确认calico使用哪个端口发送ip-in-ip报文。&lt;/p>
&lt;p>执行如下命令，查看calico-node的配置&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">kubectl -n kube-system edit daemonset calico-node
&lt;/code>&lt;/pre>&lt;/div>&lt;p>注意 IP_AUTODETECTION_METHOD，如果为can-reach=&lt;ip>，则calico选用可以访问该ip的端口来发送ip-in-ip报文，请确认该接口是正确的接口。并且calico从对端接口报文的接口和发送接口是一致的。&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">spec&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">containers&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>- &lt;span style="color:#204a87;font-weight:bold">env&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>- &lt;span style="color:#204a87;font-weight:bold">name&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">IP_AUTODETECTION_METHOD&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">value&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">can-reach=10.61.1.254&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>默认集群配置的 IP_AUTODETECTION_METHOD 为 can-reach=&amp;lt;primary_master_ip&amp;gt; ，比如上面例子中的 10.61.1.254 应该就是第一个 K8s 控制节点的 IP 。&lt;/p>
&lt;p>IP_AUTODETECTION_METHOD 还可以配置为其他的值，可以参考 calico 官方文档：&lt;a href="https://projectcalico.docs.tigera.io/reference/node/configuration#ip-autodetection-methods">Configuring calico/node/Manifest&lt;/a>。&lt;/p>
&lt;p>其中常用的配置可以设置成：&lt;code>IP_AUTODETECTION_METHOD=kubernetes-internal-ip&lt;/code>，这个就会使用 K8s 节点的 Status.Addresses 作为ip-in-ip 发送的端口。&lt;/p>
&lt;h3 id="链路问题">链路问题&lt;/h3>
&lt;p>如上一步确认无误，则需要确认calico的报文能够正常发送到对端节点，可通过tcpdump在源和目的节点抓包确认。&lt;/p>
&lt;p>如果采用IP-in-IP隧道协议，则采用如下命令抓包：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#8f5902;font-style:italic"># 格式为&lt;/span>
&lt;span style="color:#8f5902;font-style:italic"># tcpdump -i &amp;lt;if_of_calico_node&amp;gt; -nnn &amp;#34;ip proto 4&amp;#34; and host &amp;lt;ip_of_dst_node&amp;gt;&lt;/span>
&lt;span style="color:#8f5902;font-style:italic"># 比如要在控制节点的 br0 上抓来自于计算节点(IP: 10.130.0.13) 的 ip-in-ip 包，命令如下：&lt;/span>
$ tcpdump -i br0 -nnn &lt;span style="color:#4e9a06">&amp;#34;ip proto 4&amp;#34;&lt;/span> and host 10.130.0.13
&lt;/code>&lt;/pre>&lt;/div>&lt;p>如果采用VXLAN隧道协议，则采用如下命令抓包：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#8f5902;font-style:italic"># 格式为&lt;/span>
&lt;span style="color:#8f5902;font-style:italic"># tcpdump -i &amp;lt;if_of_calico_node&amp;gt; -nnn udp and port 4789 and host &amp;lt;ip_of_dst_node&amp;gt;&lt;/span>
&lt;span style="color:#8f5902;font-style:italic"># 比如要在控制节点的 br0 上抓来自于计算节点(IP: 10.130.0.13) 的 VXLAN 包，命令如下：&lt;/span>
$ tcpdump -i br0 -nnn udp and port &lt;span style="color:#0000cf;font-weight:bold">4789&lt;/span> and host 10.130.0.13
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="常见故障原因">常见故障原因&lt;/h2>
&lt;h3 id="节点路由问题">节点路由问题&lt;/h3>
&lt;p>由于节点路由配置不一致，导致节点发送和接收ip-in-ip报文的端口IP不一致，导致双方无法通信&lt;/p>
&lt;h3 id="内核问题">内核问题&lt;/h3>
&lt;p>特定内核在开启GSO之后会导致ip-in-ip报文丢弃，可尝试通过下面的命令关闭网卡相关特性，看是否解决问题：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#8f5902;font-style:italic"># 假设 k8s 节点之间通过 eth0 网卡通信&lt;/span>
$ ethtool --offload eth0 rx off tx off
$ ethtool -K eth0 gso off
&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>Docs: 调整驱逐的阈值</title><link>https://www.cloudpods.org/zh/docs/ops/k8s/eviction_threshold/</link><pubDate>Mon, 05 Dec 2022 10:34:27 +0800</pubDate><guid>https://www.cloudpods.org/zh/docs/ops/k8s/eviction_threshold/</guid><description>
&lt;p>Kubernetes 有一个节点驱逐的机制，比如当节点的根分区使用空间大于 85% 就会把节点变成 NotReady 状态，然后驱逐上面的 Pod 。下面介绍如何调整节点的相关配置的阈值，可根据自己的环境适当调整。&lt;/p>
&lt;h2 id="调整-kubelet-阈值配置">调整 kubelet 阈值配置&lt;/h2>
&lt;p>kubelet 所有的配置参数写在了文件 &lt;code>/var/lib/kubelet/config.yaml&lt;/code>，阈值相关的参数如下：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-diff" data-lang="diff">&lt;span style="color:#800080;font-weight:bold">@@ -34,10 +34,10 @@ enforceNodeAllocatable:
&lt;/span>&lt;span style="color:#800080;font-weight:bold">&lt;/span> eventBurst: 10
eventRecordQPS: 5
# 驱逐相关参数
evictionHard:
&lt;span style="color:#a40000">- imagefs.available: 15%
&lt;/span>&lt;span style="color:#a40000">- memory.available: 1024Mi
&lt;/span>&lt;span style="color:#a40000">- nodefs.available: 15%
&lt;/span>&lt;span style="color:#a40000">- nodefs.inodesFree: 15%
&lt;/span>&lt;span style="color:#a40000">&lt;/span>&lt;span style="color:#00a000">+ imagefs.available: 5% # 当容器镜像所在目录的空闲容量小于 5% 的时候触发，imagefs 为 docker 所在目录，配置为 `/opt/docker`
&lt;/span>&lt;span style="color:#00a000">+ memory.available: 100Mi # 当内存不够 100Mi 的时候触发
&lt;/span>&lt;span style="color:#00a000">+ nodefs.available: 5% # 当根分区可用容量不够 5% 的时候触发
&lt;/span>&lt;span style="color:#00a000">+ nodefs.inodesFree: 5% # 当根分区 inodes 不够 5% 的时候触发
&lt;/span>&lt;span style="color:#00a000">&lt;/span> evictionPressureTransitionPeriod: 5m0s
failSwapOn: true
fileCheckFrequency: 20s
&lt;span style="color:#800080;font-weight:bold">@@ -45,8 +45,8 @@ hairpinMode: promiscuous-bridge
&lt;/span>&lt;span style="color:#800080;font-weight:bold">&lt;/span> healthzBindAddress: 127.0.0.1
healthzPort: 10248
httpCheckFrequency: 20s
&lt;span style="color:#a40000">-imageGCHighThresholdPercent: 85
&lt;/span>&lt;span style="color:#a40000">-imageGCLowThresholdPercent: 80
&lt;/span>&lt;span style="color:#a40000">&lt;/span>&lt;span style="color:#00a000">+imageGCHighThresholdPercent: 95 # 当硬盘存储使用率超过imageGCHighThresholdPercent时，会触发Image GC，直到硬盘存储使用率低于imageGCLowThresholdPercent
&lt;/span>&lt;span style="color:#00a000">+imageGCLowThresholdPercent: 90
&lt;/span>&lt;span style="color:#00a000">&lt;/span> imageMinimumGCAge: 2m0s
iptablesDropBit: 15
iptablesMasqueradeBit: 14
&lt;/code>&lt;/pre>&lt;/div>&lt;p>调整完 &lt;code>/var/lib/kubelet/config.yaml&lt;/code> 后，重启 kubelet:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ systemctl restart kubelet
&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>Docs: 暂停集群服务</title><link>https://www.cloudpods.org/zh/docs/ops/k8s/halt_cluster/</link><pubDate>Tue, 22 Nov 2022 18:38:00 +0800</pubDate><guid>https://www.cloudpods.org/zh/docs/ops/k8s/halt_cluster/</guid><description>
&lt;p>在运维维护集群过程中，例如维护集群数据库等，需要暂停集群服务。本文介绍如何不影响虚拟机正常运行的前提下暂停 Cloudpods 服务的方法。&lt;/p>
&lt;h2 id="停止服务">停止服务&lt;/h2>
&lt;p>平台服务由 operator 管理，可以通过给 operator 添加 &amp;lsquo;-stop-services&amp;rsquo; 启动参数，停止大部分控制服务。为了不影响虚拟机的正常运行，部分控制服务应保持继续运行，比如：default-ovn-north、default-influxdb和default-host。&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ kubectl edit deployment -n onecloud onecloud-operator
template:
metadata:
creationTimestamp: null
labels:
k8s-app: onecloud-operator
spec:
containers:
- command:
- /bin/onecloud-controller-manager
- -stop-services &lt;span style="color:#8f5902;font-style:italic"># 改这个地方，加上 &amp;#39;-stop-services&amp;#39; 参数&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>然后 operator 会重建，开始删除控制服务，最终还保留的 pod 如下：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ kubectl get pods -n onecloud
NAME READY STATUS RESTARTS AGE
default-etcd-swbzmncg2x 1/1 Running &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> 16d
default-host-xqwr6 3/3 Running &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> 19h
default-influxdb-7476dbb84c-6qhqm 1/1 Running &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> 10d
default-ovn-north-67b97ffcfd-54lvp 1/1 Running &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> 10d
onecloud-operator-6967685b4-6p2qx 1/1 Running &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> 80s
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="恢复服务">恢复服务&lt;/h2>
&lt;p>删除 onecloud-operator deployment command 里面的 &amp;lsquo;-stop-services&amp;rsquo; 启动参数，operator 会重建之前删除的服务。&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ kubectl edit deployment -n onecloud onecloud-operator
&lt;/code>&lt;/pre>&lt;/div></description></item></channel></rss>