<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Cloudpods –
虚拟机设备透传</title><link>https://www.cloudpods.org/zh/docs/function_principle/onpremise/vminstance/passthrough/</link><description>Recent content in 虚拟机设备透传 on Cloudpods</description><generator>Hugo -- gohugo.io</generator><lastBuildDate>Fri, 19 Jul 2019 18:32:40 +0800</lastBuildDate><atom:link href="https://www.cloudpods.org/zh/docs/function_principle/onpremise/vminstance/passthrough/index.xml" rel="self" type="application/rss+xml"/><item><title>Docs: vGPU</title><link>https://www.cloudpods.org/zh/docs/function_principle/onpremise/vminstance/passthrough/vgpu/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.cloudpods.org/zh/docs/function_principle/onpremise/vminstance/passthrough/vgpu/</guid><description>
&lt;p>NVIDIA 和 AMD 都提供了虚拟 GPU（vgpu）的解决方案，但它们在实现方式上有一些不同之处。&lt;/p>
&lt;p>NVIDIA vGPU 实现方式：&lt;/p>
&lt;ul>
&lt;li>NVIDIA vGPU 是基于 NVIDIA 的 GRID 技术实现的，它使用 NVIDIA 的物理 GPU 并将其划分为多个虚拟 GPU，每个虚拟 GPU 都可以被分配给一个独立的虚拟机实例。&lt;/li>
&lt;li>NVIDIA vGPU 使用专有的虚拟 GPU 管理软件（如NVIDIA Virtual GPU Manager），该软件在物理 GPU 上创建和管理虚拟 GPU，并分配给虚拟机使用。&lt;/li>
&lt;/ul>
&lt;p>AMD vGPU 实现方式：&lt;/p>
&lt;ul>
&lt;li>AMD vGPU 是基于 AMD 的 SR-IOV（Single Root I/O Virtualization）技术实现的，它通过硬件辅助虚拟化技术将物理 GPU 分割为多个虚拟 GPU。&lt;/li>
&lt;/ul>
&lt;h2 id="amd-vgpu-配置">AMD vGPU 配置&lt;/h2>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#8f5902;font-style:italic"># 查看 AMD GPU 设备PCI配置空间，确认打开 SR-IOV&lt;/span>
$ lspci -k -s 04:00.0 -v
04:00.0 VGA compatible controller: Advanced Micro Devices, Inc. &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>AMD/ATI&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> Tonga XT GL &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>FirePro S7150&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>prog-if &lt;span style="color:#0000cf;font-weight:bold">00&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>VGA controller&lt;span style="color:#ce5c00;font-weight:bold">])&lt;/span>
Subsystem: Advanced Micro Devices, Inc. &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>AMD/ATI&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> Device 030c
Flags: bus master, fast devsel, latency 0, IRQ 209, NUMA node &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
Memory at 3bfe0000000 &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>64-bit, prefetchable&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>&lt;span style="color:#000">size&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>256M&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>
Memory at 3bff4000000 &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>64-bit, prefetchable&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>&lt;span style="color:#000">size&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>2M&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>
I/O ports at &lt;span style="color:#0000cf;font-weight:bold">2000&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>&lt;span style="color:#000">size&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>256&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>
Memory at 95c00000 &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>32-bit, non-prefetchable&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>&lt;span style="color:#000">size&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>256K&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>
Expansion ROM at 95c40000 &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>disabled&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>&lt;span style="color:#000">size&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>128K&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>
Capabilities: &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>48&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> Vendor Specific Information: &lt;span style="color:#000">Len&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">08&lt;/span> &amp;lt;?&amp;gt;
Capabilities: &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>50&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> Power Management version &lt;span style="color:#0000cf;font-weight:bold">3&lt;/span>
Capabilities: &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>58&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> Express Legacy Endpoint, MSI &lt;span style="color:#0000cf;font-weight:bold">00&lt;/span>
Capabilities: &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>a0&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> MSI: Enable+ &lt;span style="color:#000">Count&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>1/4 Maskable+ 64bit+
Capabilities: &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>100&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> Vendor Specific Information: &lt;span style="color:#000">ID&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">0001&lt;/span> &lt;span style="color:#000">Rev&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">1&lt;/span> &lt;span style="color:#000">Len&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">010&lt;/span> &amp;lt;?&amp;gt;
Capabilities: &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>150&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> Advanced Error Reporting
Capabilities: &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>200&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> &lt;span style="color:#8f5902;font-style:italic">#15&lt;/span>
Capabilities: &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>270&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> &lt;span style="color:#8f5902;font-style:italic">#19&lt;/span>
Capabilities: &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>2b0&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> Address Translation Service &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>ATS&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
Capabilities: &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>2c0&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> Page Request Interface &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>PRI&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
Capabilities: &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>2d0&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> Process Address Space ID &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>PASID&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
Capabilities: &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>328&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> Alternative Routing-ID Interpretation &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>ARI&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
Capabilities: &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>330&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> Single Root I/O Virtualization &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>SR-IOV&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span> &lt;span style="color:#8f5902;font-style:italic">### 打开了 SR-IOV&lt;/span>
Capabilities: &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>400&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> Vendor Specific Information: &lt;span style="color:#000">ID&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">0002&lt;/span> &lt;span style="color:#000">Rev&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">1&lt;/span> &lt;span style="color:#000">Len&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">070&lt;/span> &amp;lt;?&amp;gt;
Kernel modules: amdgpu
&lt;/code>&lt;/pre>&lt;/div>&lt;p>宿主机上AMD vGPU需要安装 GIM 驱动，参考：
&lt;a href="https://github.com/GPUOpen-LibrariesAndSDKs/MxGPU-Virtualization#how-to-load">https://github.com/GPUOpen-LibrariesAndSDKs/MxGPU-Virtualization#how-to-load&lt;/a>&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ git clone https://github.com/GPUOpen-LibrariesAndSDKs/MxGPU-Virtualization.git &lt;span style="color:#ce5c00;font-weight:bold">&amp;amp;&amp;amp;&lt;/span> &lt;span style="color:#204a87">cd&lt;/span> MxGPU-Virtualization/drv
$ make &lt;span style="color:#ce5c00;font-weight:bold">&amp;amp;&amp;amp;&lt;/span> make install
&lt;span style="color:#8f5902;font-style:italic"># 修改驱动禁用 amdgpu 驱动&lt;/span>
$ vi /etc/modprobe.d/blacklist.conf
blacklist amdgpu
blacklist amdkfd
&lt;span style="color:#8f5902;font-style:italic"># 配置 VF 数量&lt;/span>
$ cat /etc/gim_config
&lt;span style="color:#000">fb_option&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;span style="color:#000">sched_option&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;span style="color:#000">vf_num&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">2&lt;/span> &lt;span style="color:#8f5902;font-style:italic"># vf 数量&lt;/span>
&lt;span style="color:#000">pf_fb&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;span style="color:#000">vf_fb&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;span style="color:#000">sched_interval&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;span style="color:#000">sched_interval_us&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;span style="color:#000">fb_clear&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
$ modprobe gim
&lt;/code>&lt;/pre>&lt;/div>&lt;p>修改 /etc/yunion/host.conf 配置 AMD vGPU&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ vi /etc/yunion/host.conf
AMDVgpuPFs:
- 04:00.0 &lt;span style="color:#8f5902;font-style:italic"># AMD GPU PCI 地址&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>重启 host-agent 服务&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ kubectl -n onecloud rollout restart ds default-host
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="nvidia-vgpu-配置">NVIDIA vGPU 配置&lt;/h2>
&lt;p>NVIDIA 需要安装 GRID 驱动(驱动在NVIDIA官网需要企业注册才能下载):&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ ./NVIDIA-Linux-x86_64-510.85.03-vgpu-kvm.run
&lt;span style="color:#8f5902;font-style:italic"># 安装好后重启服务器&lt;/span>
&lt;span style="color:#8f5902;font-style:italic"># 查看是否加载 nvidia vgpu 驱动&lt;/span>
&lt;span style="color:#8f5902;font-style:italic"># 内核需要支持 vfio 与 vfio-mdev&lt;/span>
$ lsmod &lt;span style="color:#000;font-weight:bold">|&lt;/span> grep nvidia
nvidia_vgpu_vfio &lt;span style="color:#0000cf;font-weight:bold">53248&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">19&lt;/span>
nvidia &lt;span style="color:#0000cf;font-weight:bold">39120896&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">273&lt;/span>
mdev &lt;span style="color:#0000cf;font-weight:bold">24576&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">2&lt;/span> vfio_mdev,nvidia_vgpu_vfio
drm &lt;span style="color:#0000cf;font-weight:bold">491520&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">4&lt;/span> drm_kms_helper,drm_vram_helper,nvidia,ttm
vfio &lt;span style="color:#0000cf;font-weight:bold">32768&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">7&lt;/span> vfio_mdev,nvidia_vgpu_vfio,vfio_iommu_type1,vfio_pci
&lt;span style="color:#8f5902;font-style:italic"># 查看 nvidia vgpu 管理服务状态&lt;/span>
$ systemctl status nvidia-vgpu-mgr.service
&lt;span style="color:#8f5902;font-style:italic"># 配置 vGPU&lt;/span>
&lt;span style="color:#8f5902;font-style:italic"># cd /sys/class/mdev_bus/domain\:bus\:slot.function/mdev_supported_types, eg:&lt;/span>
$ &lt;span style="color:#204a87">cd&lt;/span> /sys/class/mdev_bus/0000:82:00.0/mdev_supported_types &lt;span style="color:#ce5c00;font-weight:bold">&amp;amp;&amp;amp;&lt;/span> ls
nvidia-156 nvidia-241 nvidia-284 nvidia-286 nvidia-46 nvidia-48 nvidia-50 nvidia-52 nvidia-54 nvidia-56 nvidia-58 nvidia-60 nvidia-62
nvidia-215 nvidia-283 nvidia-285 nvidia-287 nvidia-47 nvidia-49 nvidia-51 nvidia-53 nvidia-55 nvidia-57 nvidia-59 nvidia-61
&lt;span style="color:#8f5902;font-style:italic"># 这些目录代表不同的 vGPU 类型，查看 nvidia-46 详细描述&lt;/span>
$ ls nvidia-46
available_instances create description device_api devices/ name
$ cat nvidia-46/description
&lt;span style="color:#000">num_heads&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>4, &lt;span style="color:#000">frl_config&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>60, &lt;span style="color:#000">framebuffer&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>1024M, &lt;span style="color:#000">max_resolution&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>5120x2880, &lt;span style="color:#000">max_instance&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">24&lt;/span>
$ cat nvidia-46/name
GRID P40-1Q
$ cat nvidia-46/available_instances
&lt;span style="color:#0000cf;font-weight:bold">22&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>NVIDIA官网描述如下：&lt;/p>
&lt;ul>
&lt;li>available_instances
This file contains the number of instances of this vGPU type that can still be created. This file is updated any time a vGPU of this type is created on or removed from the physical GPU.&lt;/li>
&lt;li>create
This file is used for creating a vGPU instance. A vGPU instance is created by writing the UUID of the vGPU to this file. The file is write only.&lt;/li>
&lt;li>description
This file contains the following details of the vGPU type:
The maximum number of virtual display heads that the vGPU type supports
The frame rate limiter (FRL) configuration in frames per second
The frame buffer size in Mbytes
The maximum resolution per display head
The maximum number of vGPU instances per physical GPU
For example:
$ cat description
num_heads=4, frl_config=60, framebuffer=2048M, max_resolution=4096x2160, max_instance=4&lt;/li>
&lt;li>device_api
This file contains the string vfio_pci to indicate that a vGPU is a PCI device.&lt;/li>
&lt;li>devices
This directory contains all the mdev devices that are created for the vGPU type. For example:
$ ll devices
total 0
lrwxrwxrwx 1 root root 0 Dec 6 01:52 aa618089-8b16-4d01-a136-25a0f3c73123 -&amp;gt; ../../../aa618089-8b16-4d01-a136-25a0f3c73123&lt;/li>
&lt;li>name
This file contains the name of the vGPU type. For example:
$ cat name
GRID M10-2Q&lt;/li>
&lt;/ul>
&lt;p>可以根据自己的需求配置 vGPU，eg:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#8f5902;font-style:italic"># 生成 uuid 格式的字符串用于配置 vGPU id&lt;/span>
$ uuidgen
070bcb42-18fc-4971-9aa9-67f5ee1281c3
$ &lt;span style="color:#204a87">echo&lt;/span> 070bcb42-18fc-4971-9aa9-67f5ee1281c3 &amp;gt; nvidia-46/create
&lt;span style="color:#8f5902;font-style:italic"># 如果需要持久化的话需要配置到 /etc/rc.local 中：&lt;/span>
&lt;span style="color:#204a87">echo&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;echo 070bcb42-18fc-4971-9aa9-67f5ee1281c3 &amp;gt; /sys/class/mdev_bus/0000:82:00.0/mdev_supported_types/nvidia-46/create&amp;#34;&lt;/span> &amp;gt;&amp;gt; /etc/rc.local
&lt;/code>&lt;/pre>&lt;/div>&lt;p>配置 /etc/yunion/host.conf&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">nvidia_vgpu_pfs:
- 82:00.0
&lt;/code>&lt;/pre>&lt;/div>&lt;p>重启 host-agent 服务&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ kubectl -n onecloud rollout restart ds default-host
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="nvidia-vgpu-虚机配置">NVIDIA vGPU 虚机配置&lt;/h3>
&lt;p>虚机内安装 GIRD 驱动&lt;/p>
&lt;pre>&lt;code>禁用 nouveau 驱动
$ cat /etc/modprobe.d/blacklist-nouveau.conf
blacklist nouveau
options nouveau modeset=0
$ ./NVIDIA-Linux-x86_64-510.85.02-grid.run
# 查看 nvidia-gridd 服务状态
$ systemctl status nvidia-gridd
# 配置 license server 地址
$ cp /etc/nvidia/gridd.conf.template /etc/nvidia/gridd.conf
$ vi /etc/nvidia/gridd.conf # 按需配置
# Description: Set License Server Address
# Data type: string
# Format: &amp;quot;&amp;lt;address&amp;gt;&amp;quot;
ServerAddress= example.com # license server 地址
# Description: Set License Server port number
# Data type: integer
# Format: &amp;lt;port&amp;gt;, default is 7070
ServerPort=7070 # license server 端口
# Description: Set Feature to be enabled
# Data type: integer
# Possible values:
# 0 =&amp;gt; for unlicensed state
# 1 =&amp;gt; for NVIDIA vGPU (Optional, autodetected as per vGPU type)
# 2 =&amp;gt; for NVIDIA RTX Virtual Workstation
# 4 =&amp;gt; for NVIDIA Virtual Compute Server
# All other values reserved
FeatureType=1 #
$ systemctl restart nvidia-gridd
$ nvidia-smi -q
vGPU Software Licensed Product
Product Name : NVIDIA RTX Virtual Workstation
License Status : Licensed (Expiry: 2023-8-14 13:47:59 GMT) # license 状态为 licensed
&lt;/code>&lt;/pre>&lt;p>参考：
&lt;a href="https://github.com/GPUOpen-LibrariesAndSDKs/MxGPU-Virtualization#how-to-load">https://github.com/GPUOpen-LibrariesAndSDKs/MxGPU-Virtualization#how-to-load&lt;/a>
&lt;a href="https://docs.nvidia.com/grid/latest/grid-vgpu-user-guide/index.html#creating-vgpu-device-red-hat-el-kvm">https://docs.nvidia.com/grid/latest/grid-vgpu-user-guide/index.html#creating-vgpu-device-red-hat-el-kvm&lt;/a>
&lt;a href="https://cloud-atlas.readthedocs.io/zh_CN/latest/kvm/vgpu/vgpu_quickstart.html">https://cloud-atlas.readthedocs.io/zh_CN/latest/kvm/vgpu/vgpu_quickstart.html&lt;/a>&lt;/p></description></item><item><title>Docs: GPU透传</title><link>https://www.cloudpods.org/zh/docs/function_principle/onpremise/vminstance/passthrough/gpu/</link><pubDate>Fri, 19 Jul 2019 18:32:40 +0800</pubDate><guid>https://www.cloudpods.org/zh/docs/function_principle/onpremise/vminstance/passthrough/gpu/</guid><description>
&lt;p>支持 Cloudpods KVM 虚拟机使用 GPU，使用的 PCI Passthrough 的方式将宿主机上的 Nvidia/AMD GPU 透传给虚拟机使用。&lt;/p>
&lt;h2 id="宿主机设置">宿主机设置&lt;/h2>
&lt;p>除了常规的PCI/PCIe设备透传设置外，为了避免宿主机Linux内核自带的GPU驱动和vfio争抢设备，需要设置如下额外的内核命令行参数：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#000">rdblacklist&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>nouveau nouveau.modeset&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>同时，需要设置宿主机的 /etc/yunion/host.conf 的 disable_gpu: false（已默认设置）。&lt;/p>
&lt;h2 id="gpu相关命令行">GPU相关命令行&lt;/h2>
&lt;h3 id="创建-gpu-云主机">创建 GPU 云主机&lt;/h3>
&lt;ul>
&lt;li>查询 gpu 列表&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ climc isolated-device-list --gpu
+--------------------------------------+----------+---------------------+---------+------------------+--------------------------------------+
&lt;span style="color:#000;font-weight:bold">|&lt;/span> ID &lt;span style="color:#000;font-weight:bold">|&lt;/span> Dev_type &lt;span style="color:#000;font-weight:bold">|&lt;/span> Model &lt;span style="color:#000;font-weight:bold">|&lt;/span> Addr &lt;span style="color:#000;font-weight:bold">|&lt;/span> Vendor_device_id &lt;span style="color:#000;font-weight:bold">|&lt;/span> Host_id &lt;span style="color:#000;font-weight:bold">|&lt;/span>
+--------------------------------------+----------+---------------------+---------+------------------+--------------------------------------+
&lt;span style="color:#000;font-weight:bold">|&lt;/span> 273f4f72-06b6-49aa-8456-4beceec44997 &lt;span style="color:#000;font-weight:bold">|&lt;/span> GPU-HPC &lt;span style="color:#000;font-weight:bold">|&lt;/span> GeForce GTX &lt;span style="color:#0000cf;font-weight:bold">1050&lt;/span> Ti &lt;span style="color:#000;font-weight:bold">|&lt;/span> 41:00.0 &lt;span style="color:#000;font-weight:bold">|&lt;/span> 10de:1c82 &lt;span style="color:#000;font-weight:bold">|&lt;/span> 3bce9607-2597-469f-8d9b-977345456739 &lt;span style="color:#000;font-weight:bold">|&lt;/span>
&lt;span style="color:#000;font-weight:bold">|&lt;/span> a77333e9-08d9-45c6-87eb-a7d8d902c5f5 &lt;span style="color:#000;font-weight:bold">|&lt;/span> GPU-HPC &lt;span style="color:#000;font-weight:bold">|&lt;/span> Quadro FX &lt;span style="color:#0000cf;font-weight:bold">580&lt;/span> &lt;span style="color:#000;font-weight:bold">|&lt;/span> 05:00.0 &lt;span style="color:#000;font-weight:bold">|&lt;/span> 10de:0659 &lt;span style="color:#000;font-weight:bold">|&lt;/span> 3bce9607-2597-469f-8d9b-977345456739 &lt;span style="color:#000;font-weight:bold">|&lt;/span>
+--------------------------------------+----------+---------------------+---------+------------------+--------------------------------------+
&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>创建 server&lt;/li>
&lt;/ul>
&lt;p>server-create 中的 &lt;code>--isolated-device&lt;/code> 参数指定透传的设备到云主机，可以重复使用多次，透传多个 gpu 到云主机，但要求透传到同一云主机的 gpu 必须在同一宿主机。其余创建参数和创建普通云主机是一样的。&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ climc server-create --hypervisor kvm --isolated-device 273f4f72-06b6-49aa-8456-4beceec44997 ...
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="设置-gpu-设备类型">设置 GPU 设备类型&lt;/h3>
&lt;p>GPU 设备支持的设备类型有：GPU-HPC，GPU-VGA&lt;/p>
&lt;ul>
&lt;li>GPU-HPC: 高性能计算卡（High-Performance Computing），主要用于进行科学计算、数据分析、机器学习等需要大规模并行计算的任务。&lt;/li>
&lt;li>GPU-VGA: 视频图形处理卡（Video Graphics Array），用于图形渲染和显示的目的。&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>注意事项&lt;/strong>
GPU-VGA 类型的 GPU 卡透传给虚机使用时，不在提供模拟的 VGA 设备，需要在镜像内提前安装好显卡驱动。&lt;/p>
&lt;h4 id="设置-gpu-卡类型">设置 GPU 卡类型&lt;/h4>
&lt;pre>&lt;code>$ climc isolated-device-update
Usage: climc isolated-device-update [--reserved-mem RESERVED_MEM] [--reserved-storage RESERVED_STORAGE] [--dev-type {GPU-HPC,GPU-VGA}] [--help] [--reserved-cpu RESERVED_CPU] &amp;lt;ID&amp;gt; ...
# example:
$ climc isolated-device-update --dev-type GPU-VGA b46a7374-6da2-46a4-8eda-abd16c502e0b
&lt;/code>&lt;/pre>&lt;h3 id="查询-gpu-云主机">查询 GPU 云主机&lt;/h3>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ climc server-list --gpu
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="关联-gpu">关联 GPU&lt;/h3>
&lt;p>如果云主机所在的宿主机有可用的 gpu，在主机关机的情况下，可以通过 &lt;code>server-attach-isolated-device&lt;/code> 命令将 gpu 和云主机关联起来，下次主机启动后就可以使用该 gpu 。&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ climc server-attach-isolated-device &amp;lt;server_id&amp;gt; &amp;lt;device_id&amp;gt;
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="卸载-gpu">卸载 GPU&lt;/h3>
&lt;p>如果云主机关联了 gpu，可以通过 &lt;code>server-detach-isolated-device&lt;/code> 卸载主机的某一 gpu。&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ climc server-detach-isolated-device &amp;lt;server_id&amp;gt; &amp;lt;device_id&amp;gt;
&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>Docs: 网卡SR-IOV卸载</title><link>https://www.cloudpods.org/zh/docs/function_principle/onpremise/vminstance/passthrough/sriov/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.cloudpods.org/zh/docs/function_principle/onpremise/vminstance/passthrough/sriov/</guid><description>
&lt;h2 id="sr-iov-介绍">SR-IOV 介绍&lt;/h2>
&lt;p>SR-IOV 技术是一种基于硬件的虚拟化解决方案，可提高性能和可伸缩性。SR-IOV 标准允许在虚拟机之间高效共享 PCIe（Peripheral Component Interconnect Express，快速外设组件互连）设备，并且它是在硬件中实现的，可以获得能够与本机性能媲美的 I/O 性能。SR-IOV 规范定义了新的标准，根据该标准，创建的新设备可允许将虚拟机直接连接到 I/O 设备。&lt;/p>
&lt;p>SR-IOV 规范由 PCI-SIG 在 &lt;a href="http://www.pcisig.com">http://www.pcisig.com&lt;/a> 上进行定义和维护。&lt;/p>
&lt;p>SR-IOV 中的两种新功能类型是：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>物理功能 (Physical Function, PF)
用于支持 SR-IOV 功能的 PCI 功能，如 SR-IOV 规范中定义。PF 包含 SR-IOV 功能结构，用于管理 SR-IOV 功能。PF 是全功能的 PCIe 功能，可以像其他任何 PCIe 设备一样进行发现、管理和处理。PF 拥有完全配置资源，可以用于配置或控制 PCIe 设备。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>虚拟功能 (Virtual Function, VF)
与物理功能关联的一种功能。VF 是一种轻量级 PCIe 功能，可以与物理功能以及与同一物理功能关联的其他 VF 共享一个或多个物理资源。VF 仅允许拥有用于其自身行为的配置资源。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="宿主机开启-sr-iov">宿主机开启 SR-IOV&lt;/h3>
&lt;p>除了常规的PCI/PCIe设备透传设置外，还需确保SR-IOV在宿主机BIOS启用，并且需要对设备的VF进行必要的内核设置，具体方法如下：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>BIOS 中打开设备 SR-IOV 功能(根据机型和设备的型号不同，具体操作方式也可能不一样，具体参考实际机型配置)。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>在宿主机节点上打开 Virtual Functions&lt;/p>
&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#8f5902;font-style:italic"># 对于不同的网卡型号打开的方式也不一样，下面以 Intel I350 网卡为例，设置 7 个 Virtual Function(网卡支持的 virtual function 数量也是不一样的，需要根据具体网卡支持的数量来配置)&lt;/span>
&lt;span style="color:#8f5902;font-style:italic"># 在 grub cmdline 中加上 igb.max_vfs=7&lt;/span>
&lt;span style="color:#000">GRUB_CMDLINE_LINUX&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;...... igb.max_vfs=7&amp;#34;&lt;/span>
&lt;span style="color:#8f5902;font-style:italic"># 重新生成 grub 引导配置文件&lt;/span>
$ grub2-mkconfig -o /boot/grub2/grub.cfg
&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="mellanox-网卡配置">Mellanox 网卡配置&lt;/h4>
&lt;p>Mellanox 网卡需要安装 MLNX_OFED 驱动，参考他们的官方文档：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://enterprise-support.nvidia.com/s/article/howto-install-mlnx-ofed-driver">https://enterprise-support.nvidia.com/s/article/howto-install-mlnx-ofed-driver&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.nvidia.com/networking/display/MLNXOFEDv461000/Installing+Mellanox+OFED">https://docs.nvidia.com/networking/display/MLNXOFEDv461000/Installing+Mellanox+OFED&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://network.nvidia.com/products/infiniband-drivers/linux/mlnx_ofed/">https://network.nvidia.com/products/infiniband-drivers/linux/mlnx_ofed/&lt;/a>&lt;/li>
&lt;/ul>
&lt;pre>&lt;code># 注意要使用 gcc 高版本
$ yum install centos-release-scl
$ yum install -y devtoolset-9
$ scl enable devtoolset-9 bash
# 下载对应操作系统版本的 iso，注意区分 centos7.x
# 可在 nvidia 提供的驱动网站上下载: https://network.nvidia.com/products/infiniband-drivers/linux/mlnx_ofed/
# 可在 nvidia 提供的驱动网站上下载: https://network.nvidia.com/products/infiniband-drivers/linux/mlnx_ofed/
$ wget https://content.mellanox.com/ofed/MLNX_OFED-5.8-1.1.2.1/MLNX_OFED_LINUX-5.8-1.1.2.1-rhel7.9-x86_64.iso
$ mount -o loop MLNX_OFED_LINUX-5.8-1.1.2.1-rhel7.9-x86_64.iso /mnt
$ cd /mnt
# 等待编译
$ ./mlnxofedinstall --add-kernel-support
Restart needed for updates to take effect.
Log File: /tmp/ZXf5cnZzxo
Real log file: /tmp/MLNX_OFED_LINUX.62574.logs/fw_update.log
You may need to update your initramfs before next boot. To do that, run:
dracut -f
To load the new driver, run:
/etc/init.d/openibd restart
$ dracut -f
$ /etc/init.d/openibd restart
$ mst start
# 配置SRIOV VF数量, 重启生效, 具体设备名称查看 mst status -v
$ mlxconfig -d /dev/mst/mt4119_pciconf0 set SRIOV_EN=1 NUM_OF_VFS=64
$ reboot
&lt;/code>&lt;/pre>&lt;ol start="5">
&lt;li>设置好后重启宿主机，查看 /proc/cmdline 确认配置生效。&lt;/li>
&lt;/ol>
&lt;h3 id="host-agent-启用-sr-iov">host-agent 启用 SR-IOV&lt;/h3>
&lt;p>登陆到对应的宿主机节点&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#8f5902;font-style:italic"># SR-IOV 默认是不启用的，需要修改 host-agent 配置&lt;/span>
&lt;span style="color:#8f5902;font-style:italic"># 配置 SR-IOV 对应的网络 eg:&lt;/span>
$ vi /etc/yunion/host.conf
networks:
- eth1/br0/192.168.100.111
- eth2/br1/bcast0
&lt;span style="color:#8f5902;font-style:italic"># networks包含了两种配置方式，第一个参数是物理网卡名称，第二个参数是网桥名称，&lt;/span>
&lt;span style="color:#8f5902;font-style:italic"># 第三个参数有两种，一种是 ip 地址，另外一种是 wire，对于不想配置 ip地址的网卡可以使用 wire 属性，wire 代表的是这个网卡所在的二层网络。&lt;/span>
sriov_nics:
- eth2
&lt;span style="color:#8f5902;font-style:italic"># 为 eth2 网卡打开 sriov&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>修改完成后重启 host-agent 服务: &lt;code>kubectl rollout restart ds default-host&lt;/code>, 重启完成等待 host-agent 服务启动成功后可以在控制节点使用 climc 查看配置的 VF 网卡.&lt;/p>
&lt;p>eg:&lt;/p>
&lt;pre>&lt;code># 例如 I350 Ethernet Controller Virtual Function 就是我们本次配置的 VF 网卡。
$ climc isolated-device-list
+--------------------------------------+----------+-------------------------------------------+---------+------------------+--------------------------------------+--------------------------------------+
| ID | Dev_type | Model | Addr | Vendor_device_id | Host_id | Guest_id |
+--------------------------------------+----------+-------------------------------------------+---------+------------------+--------------------------------------+--------------------------------------+
| 37b2fe7b-f202-428e-8c34-35ccdac82852 | NIC | ConnectX-5 Virtual Function | 0a:01.1 | 15b3:1018 | c48b1b8b-28a3-453a-863f-ddf7c62bcfe2 | |
| 9a0f2b3a-b372-4e37-840f-60427d026479 | NIC | ConnectX-5 Virtual Function | 0a:01.0 | 15b3:1018 | c48b1b8b-28a3-453a-863f-ddf7c62bcfe2 | |
| 37b54017-4da3-44a6-8ffe-056ffc9e853b | NIC | ConnectX-5 Virtual Function | 0a:00.7 | 15b3:1018 | c48b1b8b-28a3-453a-863f-ddf7c62bcfe2 | |
| 74558948-f5e9-453b-86d6-89c6bc00c710 | NIC | ConnectX-5 Virtual Function | 0a:00.6 | 15b3:1018 | c48b1b8b-28a3-453a-863f-ddf7c62bcfe2 | |
| 75df24b3-c27a-49bb-8cf7-385c9f0d2385 | NIC | ConnectX-5 Virtual Function | 0a:00.5 | 15b3:1018 | c48b1b8b-28a3-453a-863f-ddf7c62bcfe2 | |
| 17841618-c3e7-43f6-805a-23d2adbcd70c | NIC | ConnectX-5 Virtual Function | 0a:00.4 | 15b3:1018 | c48b1b8b-28a3-453a-863f-ddf7c62bcfe2 | |
| 51627e5a-22af-40ee-8af5-dc1971bf89c9 | NIC | ConnectX-5 Virtual Function | 0a:00.3 | 15b3:1018 | c48b1b8b-28a3-453a-863f-ddf7c62bcfe2 | |
| f794eba5-fbe7-4bcd-880a-4082523f5c94 | NIC | ConnectX-5 Virtual Function | 0a:00.2 | 15b3:1018 | c48b1b8b-28a3-453a-863f-ddf7c62bcfe2 | |
| 10266e05-8d34-4594-81ca-64afbd365ee7 | NIC | I350 Ethernet Controller Virtual Function | 03:13.0 | 8086:1520 | c48b1b8b-28a3-453a-863f-ddf7c62bcfe2 | |
| a837b5ca-d3ee-4cd8-8de5-447b3ab274d0 | NIC | I350 Ethernet Controller Virtual Function | 03:12.4 | 8086:1520 | c48b1b8b-28a3-453a-863f-ddf7c62bcfe2 | |
| fab303c9-5dbb-4b85-8df9-fada299622f4 | NIC | I350 Ethernet Controller Virtual Function | 03:12.0 | 8086:1520 | c48b1b8b-28a3-453a-863f-ddf7c62bcfe2 | |
| f2cb8fd5-aa26-46a7-8dc2-2eca2b77a887 | NIC | I350 Ethernet Controller Virtual Function | 03:11.4 | 8086:1520 | c48b1b8b-28a3-453a-863f-ddf7c62bcfe2 | |
| b2933d5c-9a3a-45ff-8c80-15ac3291f5c9 | NIC | I350 Ethernet Controller Virtual Function | 03:11.0 | 8086:1520 | c48b1b8b-28a3-453a-863f-ddf7c62bcfe2 | |
| b22e6511-c70b-440c-8c05-6d1041ae7661 | NIC | I350 Ethernet Controller Virtual Function | 03:10.4 | 8086:1520 | c48b1b8b-28a3-453a-863f-ddf7c62bcfe2 | |
| f523f12a-82bf-45a3-80cf-94d5a9649665 | NIC | I350 Ethernet Controller Virtual Function | 03:10.0 | 8086:1520 | c48b1b8b-28a3-453a-863f-ddf7c62bcfe2 | |
+--------------------------------------+----------+-------------------------------------------+---------+------------------+--------------------------------------+--------------------------------------+
*** Total: 24 Pages: 2 Limit: 15 Offset: 0 Page: 1 ***
# 使用 VF 网卡创建虚机，netdesc中可以指定 sriov-nic-model 或者指定 sriov-nic-id
$ climc server-create --disk ae0de3e9-dd45-458e-83b2-4dbc48d70234 \
--net 'sriov-nic-model=I350 Ethernet Controller Virtual Function' \
--ncpu 2 --mem-spec 4G wyq-test-sriov-nic --auto-start
# 挂载 VF 网卡
$ climc server-attach-network c15a5a99-75ea-4b8c-8c7a-521e5f980db4 \
'sriov-nic-model=I350 Ethernet Controller Virtual Function:8056e77e-dc14-44b5-8ef9-e43aff344c0d'
&lt;/code>&lt;/pre>&lt;h2 id="ovs-offload">OVS Offload&lt;/h2>
&lt;p>OVS Offload 是基于 SR-IOV 实现的一种硬件卸载的技术；如果硬件支持 OVS Offload, 则能够让 OVS 数据面卸载到网卡上，OVS 控制面不用做任何更改。
OVS Offload 的基础配置依赖于 SR-IOV 的配置，确保宿主机已经打开了 SR-IOV。然后需要安装开启 OVS Offload 必要的依赖，如 Mellanox 网卡需要安装 MLNX_OFED 驱动。&lt;/p>
&lt;h3 id="安装-ofed驱动配置-sriov-vf">安装 OFED驱动，配置 SRIOV VF&lt;/h3>
&lt;pre>&lt;code># 注意要使用 gcc 高版本
$ yum install centos-release-scl
$ yum install -y devtoolset-9
$ scl enable devtoolset-9 bash
# 下载对应操作系统版本的 iso，注意区分 centos7.x
# 可在 nvidia 提供的驱动网站上下载: https://network.nvidia.com/products/infiniband-drivers/linux/mlnx_ofed/
$ wget https://content.mellanox.com/ofed/MLNX_OFED-5.8-1.1.2.1/MLNX_OFED_LINUX-5.8-1.1.2.1-rhel7.9-x86_64.iso
$ mount -o loop MLNX_OFED_LINUX-5.8-1.1.2.1-rhel7.9-x86_64.iso /mnt
$ cd /mnt
# 等待编译
$ ./mlnxofedinstall --add-kernel-support
Restart needed for updates to take effect.
Log File: /tmp/ZXf5cnZzxo
Real log file: /tmp/MLNX_OFED_LINUX.62574.logs/fw_update.log
You may need to update your initramfs before next boot. To do that, run:
dracut -f
To load the new driver, run:
/etc/init.d/openibd restart
$ dracut -f
$ /etc/init.d/openibd restart
$ mst start
# 配置SRIOV VF数量, 重启生效, 具体设备名称查看 mst status -v
$ mlxconfig -d /dev/mst/mt4119_pciconf0 set SRIOV_EN=1 NUM_OF_VFS=64
$ reboot
&lt;/code>&lt;/pre>&lt;p>Mellanox 网卡安装 MLNX_OFED 驱动参考：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://enterprise-support.nvidia.com/s/article/howto-install-mlnx-ofed-driver">https://enterprise-support.nvidia.com/s/article/howto-install-mlnx-ofed-driver&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.nvidia.com/networking/display/MLNXOFEDv461000/Installing+Mellanox+OFED">https://docs.nvidia.com/networking/display/MLNXOFEDv461000/Installing+Mellanox+OFED&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://network.nvidia.com/products/infiniband-drivers/linux/mlnx_ofed/">https://network.nvidia.com/products/infiniband-drivers/linux/mlnx_ofed/&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>Mellanox 配置参考文档：&lt;/p>
&lt;blockquote>
&lt;p>&lt;a href="https://docs.nvidia.com/networking/display/MLNXOFEDv471001/OVS+Offload+Using+ASAP2+Direct#OVSOffloadUsingASAP2Direct-Overview">https://docs.nvidia.com/networking/display/MLNXOFEDv471001/OVS+Offload+Using+ASAP2+Direct#OVSOffloadUsingASAP2Direct-Overview&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;h3 id="host-agent-启用-sr-iov-1">host-agent 启用 SR-IOV&lt;/h3>
&lt;p>安装好 OFED驱动后配置 Cloudpods 平台启用 offload 网卡&lt;/p>
&lt;h4 id="mellanox-cx6-以下cx5cx4-关闭安全组">Mellanox CX6 以下(CX5/CX4) 关闭安全组&lt;/h4>
&lt;p>Mellanox CX6 以下 ovs offload 对 connection tracking 支持的不好，所以需要关闭安全组：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ kubectl -n onecloud edit cm default-host
disable_security_group: &lt;span style="color:#204a87">true&lt;/span> &lt;span style="color:#8f5902;font-style:italic"># 改为 true&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="配置-hostconf">配置 host.conf&lt;/h3>
&lt;p>登陆到对应的宿主机节点&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#8f5902;font-style:italic"># SR-IOV 默认是不启用的，需要修改 host-agent 配置&lt;/span>
&lt;span style="color:#8f5902;font-style:italic"># 配置 SR-IOV 对应的网络 eg:&lt;/span>
$ vi /etc/yunion/host.conf
networks:
- eth1/br0/192.168.100.111
- eth2/br1/bcast0
&lt;span style="color:#8f5902;font-style:italic"># networks包含了两种配置方式，第一个参数是物理网卡名称，第二个参数是网桥名称，&lt;/span>
&lt;span style="color:#8f5902;font-style:italic"># 第三个参数有两种，一种是 ip 地址，另外一种是 wire，对于不想配置 ip地址的网卡可以使用 wire 属性，wire 代表的是这个网卡所在的二层网络。&lt;/span>
ovs_offload_nics:
- eth2
&lt;span style="color:#8f5902;font-style:italic"># 为 eth2 网卡打开 ovs offload&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>修改完成后重启 host-agent 服务: &lt;code>kubectl rollout restart ds default-host&lt;/code>,在使用上与 SR-IOV 一致。&lt;/p>
&lt;h3 id="offload-网卡配置-bond">offload 网卡配置 bond&lt;/h3>
&lt;p>Mellanox 网卡支持的 bond 模式为:&lt;/p>
&lt;ul>
&lt;li>Active-Backup (mode 1)&lt;/li>
&lt;li>XOR (mode 2)&lt;/li>
&lt;li>LACP (mode 4)&lt;/li>
&lt;/ul>
&lt;p>在 offload 模式下，来自两个 PF 的数据包可以转发到任何一个VF，来自 VF 的流量可以根据 bond 状态转发到两个端口。
这意味着，在 Active-Backup 模式下，只要有一个 PF active，来自任何 VF 的流量都可以通过这个 PF 发送。
在 XOR 或 LACP 模式下，如果两个 PF 都 active，来自 VF 的流量将在这两个 PF 之间分配。&lt;/p>
&lt;p>网卡配置好 bond 后修改 host.conf 配置文件：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ vi /etc/yunion/host.conf
networks:
- bond0/br1/bcast0 &lt;span style="color:#8f5902;font-style:italic"># bond0 为bond口名称&lt;/span>
......
ovs_offload_nics:
- bond0
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="常见问题">常见问题&lt;/h3>
&lt;h4 id="如何验证一个pci设备支持sr-iov">如何验证一个PCI设备支持SR-IOV？&lt;/h4>
&lt;p>执行命令如下命令，查看设备的 capabilities 中是否包含了 SR-IOV：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#8f5902;font-style:italic"># lspci -v -s 01:00.0&lt;/span>
01:00.0 Ethernet controller: Mellanox Technologies MT2894 Family &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>ConnectX-6 Lx&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>
Subsystem: Mellanox Technologies Device &lt;span style="color:#0000cf;font-weight:bold">0001&lt;/span>
Physical Slot: &lt;span style="color:#0000cf;font-weight:bold">4&lt;/span>
Flags: bus master, fast devsel, latency 0, IRQ 60, NUMA node &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
Memory at ea000000 &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>64-bit, prefetchable&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>&lt;span style="color:#000">size&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>32M&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>
Expansion ROM at f0300000 &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>disabled&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>&lt;span style="color:#000">size&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>1M&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>
Capabilities: &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>60&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> Express Endpoint, MSI &lt;span style="color:#0000cf;font-weight:bold">00&lt;/span>
Capabilities: &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>48&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> Vital Product Data
Capabilities: &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>9c&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> MSI-X: Enable+ &lt;span style="color:#000">Count&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">64&lt;/span> Masked-
Capabilities: &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>c0&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> Vendor Specific Information: &lt;span style="color:#000">Len&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">18&lt;/span> &amp;lt;?&amp;gt;
Capabilities: &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>40&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> Power Management version &lt;span style="color:#0000cf;font-weight:bold">3&lt;/span>
Capabilities: &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>100&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> Advanced Error Reporting
Capabilities: &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>150&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> Alternative Routing-ID Interpretation &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>ARI&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
Capabilities: &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>180&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> Single Root I/O Virtualization &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>SR-IOV&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span>
Capabilities: &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>1c0&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> &lt;span style="color:#8f5902;font-style:italic">#19&lt;/span>
Capabilities: &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>230&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> Access Control Services
Capabilities: &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>320&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> &lt;span style="color:#8f5902;font-style:italic">#27&lt;/span>
Capabilities: &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>370&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> &lt;span style="color:#8f5902;font-style:italic">#26&lt;/span>
Capabilities: &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>420&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> &lt;span style="color:#8f5902;font-style:italic">#25&lt;/span>
Kernel driver in use: mlx5_core
Kernel modules: mlx5_core
&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>Docs: 自定义PCI设备透传</title><link>https://www.cloudpods.org/zh/docs/function_principle/onpremise/vminstance/passthrough/custom-pci-devices/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.cloudpods.org/zh/docs/function_principle/onpremise/vminstance/passthrough/custom-pci-devices/</guid><description>
&lt;p>Cloudpods 已经支持透传 GPU, USB, SR-IOV NIC，NVME 等类型的设备，对于这些类型之外的设备，例如通过自定义 PCI 设备类型的方式来支持。&lt;/p>
&lt;p>使用自定义PCI透传设备的步骤如下：&lt;/p>
&lt;ol>
&lt;li>获取该类型PCI设备的vendor_id与device_id&lt;/li>
&lt;li>在平台添加自定义PCI设备类型&lt;/li>
&lt;li>探测挂载在宿主机上的自定义PCI设备&lt;/li>
&lt;li>在平台将PCI设备和虚拟机绑定，在虚拟机内使用该设备&lt;/li>
&lt;/ol>
&lt;h2 id="获取-pci-设备-vendor_id-与-device_id">获取 PCI 设备 vendor_id 与 device_id&lt;/h2>
&lt;p>添加自定义PCI设备类型之前需要获取设备的 vendor_id 和 device_id&lt;/p>
&lt;pre>&lt;code>登陆到有该设备的宿主机执行 lspci找到对应的 pci 设备的地址：
eg:
$ lspci
00:00.0 Host bridge: Intel Corporation Xeon E7 v2/Xeon E5 v2/Core i7 DMI2 (rev 04)
00:01.0 PCI bridge: Intel Corporation Xeon E7 v2/Xeon E5 v2/Core i7 PCI Express Root Port 1a (rev 04)
00:02.0 PCI bridge: Intel Corporation Xeon E7 v2/Xeon E5 v2/Core i7 PCI Express Root Port 2a (rev 04)
00:03.0 PCI bridge: Intel Corporation Xeon E7 v2/Xeon E5 v2/Core i7 PCI Express Root Port 3a (rev 04)
00:05.0 System peripheral: Intel Corporation Xeon E7 v2/Xeon E5 v2/Core i7 VTd/Memory Map/Misc (rev 04)
00:05.2 System peripheral: Intel Corporation Xeon E7 v2/Xeon E5 v2/Core i7 IIO RAS (rev 04)
00:05.4 PIC: Intel Corporation Xeon E7 v2/Xeon E5 v2/Core i7 IOAPIC (rev 04)
00:11.0 PCI bridge: Intel Corporation C600/X79 series chipset PCI Express Virtual Root Port (rev 06)
00:16.0 Communication controller: Intel Corporation C600/X79 series chipset MEI Controller #1 (rev 05)
00:19.0 Ethernet controller: Intel Corporation 82579LM Gigabit Network Connection (Lewisville) (rev 06)
00:1a.0 USB controller: Intel Corporation C600/X79 series chipset USB2 Enhanced Host Controller #2 (rev 06)
00:1b.0 Audio device: Intel Corporation C600/X79 series chipset High Definition Audio Controller (rev 06)
00:1c.0 PCI bridge: Intel Corporation C600/X79 series chipset PCI Express Root Port 3 (rev b6)
00:1c.4 PCI bridge: Intel Corporation C600/X79 series chipset PCI Express Root Port 5 (rev b6)
00:1d.0 USB controller: Intel Corporation C600/X79 series chipset USB2 Enhanced Host Controller #1 (rev 06)
00:1e.0 PCI bridge: Intel Corporation 82801 PCI Bridge (rev a6)
00:1f.0 ISA bridge: Intel Corporation C600/X79 series chipset LPC Controller (rev 06)
00:1f.2 RAID bus controller: Intel Corporation C600/X79 series chipset SATA RAID Controller (rev 06)
00:1f.3 SMBus: Intel Corporation C600/X79 series chipset SMBus Host Controller (rev 06)
02:00.0 VGA compatible controller: NVIDIA Corporation GK107GL [Quadro K420] (rev a1)
根据 pci 地址获取 vendor_id 与 device_id:
lspci -n -s &amp;lt;PCI_ADDR&amp;gt;
eg:
lspci -n -s 02:00.0
02:00.0 0300: 10de:0ff3 (rev a1)
10de 为 vendor_id, 0ff3 为 device_id
&lt;/code>&lt;/pre>&lt;h2 id="添加自定义-pci-设备类型">添加自定义 PCI 设备类型&lt;/h2>
&lt;p>在云平台创建自定义pci设备类型&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">climc isolated-device-model-create
Usage: climc isolated-device-model-create &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>--help&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>--hosts HOSTS&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span> &amp;lt;MODEL&amp;gt; &amp;lt;DEV_TYPE&amp;gt; &amp;lt;VENDOR_ID&amp;gt; &amp;lt;DEVICE_ID&amp;gt;
&lt;span style="color:#8f5902;font-style:italic"># --hosts 为需要探测扫描 PCI 设备的宿主机，如果未填可重启 host-agent 生效。如果宿主机数量较多建议直接重启 host-agent&lt;/span>
&lt;span style="color:#8f5902;font-style:italic"># &amp;lt;MODEL&amp;gt; 为 PCI 设备型号&lt;/span>
&lt;span style="color:#8f5902;font-style:italic"># &amp;lt;DEV_TYPE&amp;gt; 为设备类型，如 NPU。对于已经支持的设备类型 USB, GPU-HPC, GPU-VGA, NIC 等不能再次创建。&lt;/span>
&lt;span style="color:#8f5902;font-style:italic"># &amp;lt;VENDOR_ID&amp;gt; &amp;lt;DEVICE_ID&amp;gt; 为厂商ID和设备ID&lt;/span>
eg:
climc isolated-device-model-create --hosts host1 Atlas-800 NPU 1a03 &lt;span style="color:#0000cf;font-weight:bold">2000&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="探测自定义pci设备">探测自定义PCI设备&lt;/h2>
&lt;p>定义自定义PCI设备类型后，需要在指定宿主机探测并上报该宿主机上挂载的自定义PCI设备，具体方法有：&lt;/p>
&lt;ul>
&lt;li>使用如下climc命令&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ climc isolated-device-list --host oc-node-1-192-168-121-21
&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>
&lt;p>访问前端WebUI，指定指定宿主机的详情-透传设备列表&lt;/p>
&lt;/li>
&lt;li>
&lt;p>重启该宿主机上的default-host容器&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>执行以上任意操作后，如果配置正确，则可以在该宿主机的透传设备列表查看到上报的透传设备&lt;/p>
&lt;h2 id="使用自定义pci设备">使用自定义PCI设备&lt;/h2>
&lt;p>添加自定义 PCI 设备类型完成后，可以在创建虚机选择自定义设备类型。&lt;/p>
&lt;pre>&lt;code>climc server-create --isolated-device 'Atlas-800' ......
&lt;/code>&lt;/pre>&lt;p>查看自定义 PCI 设备类型列表&lt;/p>
&lt;pre>&lt;code>climc isolated-device-model-list
&lt;/code>&lt;/pre>&lt;h2 id="宿主机禁用自定义pci设备">宿主机禁用自定义PCI设备&lt;/h2>
&lt;p>在 /etc/yunion/host.conf 中添加&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#204a87;font-weight:bold">disable_custom_device&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">true&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>Docs: USB 透传</title><link>https://www.cloudpods.org/zh/docs/function_principle/onpremise/vminstance/passthrough/usb-passthrough/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.cloudpods.org/zh/docs/function_principle/onpremise/vminstance/passthrough/usb-passthrough/</guid><description>
&lt;p>支持版本：&amp;gt;=3.8&lt;/p>
&lt;p>目前只有内置私有云平台的虚拟机可以使用宿主机上的 USB 设备。前提条件是宿主机需要有 &lt;code>lsusb&lt;/code> 这个工具，如果没有请安装 &lt;code>usbutils&lt;/code> 这个包。&lt;/p>
&lt;h2 id="配置宿主机">配置宿主机&lt;/h2>
&lt;p>查看宿主机上的 USB 设备，命令如下：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ lsusb
Bus &lt;span style="color:#0000cf;font-weight:bold">002&lt;/span> Device 002: ID 0951:1666 Kingston Technology DataTraveler &lt;span style="color:#0000cf;font-weight:bold">100&lt;/span> G3/G4/SE9 G2/50
Bus &lt;span style="color:#0000cf;font-weight:bold">002&lt;/span> Device 001: ID 1d6b:0003 Linux Foundation 3.0 root hub
Bus &lt;span style="color:#0000cf;font-weight:bold">001&lt;/span> Device 002: ID 0627:0001 Adomax Technology Co., Ltd
Bus &lt;span style="color:#0000cf;font-weight:bold">001&lt;/span> Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub
&lt;/code>&lt;/pre>&lt;/div>&lt;p>默认情况下宿主机透传 USB 设备功能是禁用的，需要在 &lt;code>/etc/yunion/host.conf&lt;/code> 配置文件里面设置 &lt;code>disable_usb: false&lt;/code> 。&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ vim /etc/yunion/host.conf
...
disable_usb: &lt;span style="color:#204a87">false&lt;/span>
...
&lt;/code>&lt;/pre>&lt;/div>&lt;p>假设宿主机 hostname 为 &lt;code>oc-node-1&lt;/code>，然后重启宿主机服务，登录到控制节点，执行下面的命令：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#8f5902;font-style:italic"># 先找到对应的宿主机服务&lt;/span>
$ kubectl get pods -n onecloud -o wide &lt;span style="color:#000;font-weight:bold">|&lt;/span> grep host &lt;span style="color:#000;font-weight:bold">|&lt;/span> grep oc-node-1 &lt;span style="color:#000;font-weight:bold">|&lt;/span> egrep -v &lt;span style="color:#4e9a06">&amp;#39;deployer|image&amp;#39;&lt;/span>
default-host-59k76 3/3 Running &lt;span style="color:#0000cf;font-weight:bold">7&lt;/span> 3d22h 192.168.121.21 oc-node-1 &amp;lt;none&amp;gt; &amp;lt;none&amp;gt;
&lt;span style="color:#8f5902;font-style:italic"># 删除宿主机上的 pod ，等待重建&lt;/span>
$ kubectl delete pods -n onecloud default-host-59k76
pod &lt;span style="color:#4e9a06">&amp;#34;default-host-59k76&amp;#34;&lt;/span> deleted
&lt;span style="color:#8f5902;font-style:italic"># 查看新创建的 host 服务&lt;/span>
$ kubectl get pods -n onecloud -o wide &lt;span style="color:#000;font-weight:bold">|&lt;/span> grep host &lt;span style="color:#000;font-weight:bold">|&lt;/span> grep oc-node-1 &lt;span style="color:#000;font-weight:bold">|&lt;/span> egrep -v &lt;span style="color:#4e9a06">&amp;#39;deployer|image&amp;#39;&lt;/span>
default-host-6cl8w 3/3 Running &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> 17s 192.168.121.21 oc-node-1 &amp;lt;none&amp;gt; &amp;lt;none&amp;gt;
&lt;span style="color:#8f5902;font-style:italic"># 确保该服务变成 Running ，然后到云平台查看透传 USB 设备&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>如果宿主机很多，也可以使用 &lt;code>kubectl -n rollout restart daemonset default-host&lt;/code> 命令来重启所有宿主机上的 host 服务。&lt;/p>
&lt;h2 id="查看-usb-透传设备">查看 USB 透传设备&lt;/h2>
&lt;h3 id="climc-命令行查看透传设备">climc 命令行查看透传设备&lt;/h3>
&lt;p>使用命令行 &lt;code>climc isolated-device-list --details&lt;/code> 查看设备：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ climc isolated-device-list --details
+--------------------------------------+----------+------------------------------------------------------+---------+------------------+--------------------------------------+--------------------------+----------+-------+--------------+
&lt;span style="color:#000;font-weight:bold">|&lt;/span> ID &lt;span style="color:#000;font-weight:bold">|&lt;/span> Dev_type &lt;span style="color:#000;font-weight:bold">|&lt;/span> Model &lt;span style="color:#000;font-weight:bold">|&lt;/span> Addr &lt;span style="color:#000;font-weight:bold">|&lt;/span> Vendor_device_id &lt;span style="color:#000;font-weight:bold">|&lt;/span> Host_id &lt;span style="color:#000;font-weight:bold">|&lt;/span> Host &lt;span style="color:#000;font-weight:bold">|&lt;/span> Guest_id &lt;span style="color:#000;font-weight:bold">|&lt;/span> Guest &lt;span style="color:#000;font-weight:bold">|&lt;/span> Guest_status &lt;span style="color:#000;font-weight:bold">|&lt;/span>
+--------------------------------------+----------+------------------------------------------------------+---------+------------------+--------------------------------------+--------------------------+----------+-------+--------------+
&lt;span style="color:#000;font-weight:bold">|&lt;/span> 1541047f-0203-488a-8226-2de740da061f &lt;span style="color:#000;font-weight:bold">|&lt;/span> USB &lt;span style="color:#000;font-weight:bold">|&lt;/span> Adomax Technology Co., Ltd &lt;span style="color:#000;font-weight:bold">|&lt;/span> 001:002 &lt;span style="color:#000;font-weight:bold">|&lt;/span> 0627:0001 &lt;span style="color:#000;font-weight:bold">|&lt;/span> 7a11731f-dcc0-41e5-8d64-68eb36defcbe &lt;span style="color:#000;font-weight:bold">|&lt;/span> oc-node-1-192-168-121-21 &lt;span style="color:#000;font-weight:bold">|&lt;/span> &lt;span style="color:#000;font-weight:bold">|&lt;/span> &lt;span style="color:#000;font-weight:bold">|&lt;/span> &lt;span style="color:#000;font-weight:bold">|&lt;/span>
&lt;span style="color:#000;font-weight:bold">|&lt;/span> a3fa9bd4-236c-4c5b-8056-f7afa807138d &lt;span style="color:#000;font-weight:bold">|&lt;/span> USB &lt;span style="color:#000;font-weight:bold">|&lt;/span> Kingston Technology DataTraveler &lt;span style="color:#0000cf;font-weight:bold">100&lt;/span> G3/G4/SE9 G2/50 &lt;span style="color:#000;font-weight:bold">|&lt;/span> 002:002 &lt;span style="color:#000;font-weight:bold">|&lt;/span> 0951:1666 &lt;span style="color:#000;font-weight:bold">|&lt;/span> 7a11731f-dcc0-41e5-8d64-68eb36defcbe &lt;span style="color:#000;font-weight:bold">|&lt;/span> oc-node-1-192-168-121-21 &lt;span style="color:#000;font-weight:bold">|&lt;/span> &lt;span style="color:#000;font-weight:bold">|&lt;/span> &lt;span style="color:#000;font-weight:bold">|&lt;/span> &lt;span style="color:#000;font-weight:bold">|&lt;/span>
+--------------------------------------+----------+------------------------------------------------------+---------+------------------+--------------------------------------+--------------------------+----------+-------+--------------+
*** Total: &lt;span style="color:#0000cf;font-weight:bold">2&lt;/span> Pages: &lt;span style="color:#0000cf;font-weight:bold">1&lt;/span> Limit: &lt;span style="color:#0000cf;font-weight:bold">20&lt;/span> Offset: &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> Page: &lt;span style="color:#0000cf;font-weight:bold">1&lt;/span> ***
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="web界面查看透传设备">web界面查看透传设备&lt;/h3>
&lt;ol>
&lt;li>在透传设备页面，可以查看到宿主机上的USB透传设备。&lt;/li>
&lt;/ol>
&lt;p>现在云平台就有了宿主机 oc-node-1 上的 USB 透传设备，接下来就可以把这些设备给虚拟机使用。&lt;/p>
&lt;h2 id="虚拟机挂载-usb">虚拟机挂载 USB&lt;/h2>
&lt;p>USB 可以在虚拟机运行状态下挂载进去，可以在前端的透传设备列表那里把 USB 挂载到虚拟机里面，一个虚拟机可关联多个USB透传设备。但是一个USB透传设备仅可被一个虚拟机使用。&lt;/p>
&lt;h3 id="web界面挂载usb">web界面挂载USB&lt;/h3>
&lt;p>&lt;strong>在虚拟机页面挂载USB透传设备&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>在左侧导航栏，选择 &lt;strong>&lt;em>&amp;ldquo;主机/主机/虚拟机&amp;rdquo;&lt;/em>&lt;/strong> 菜单项，进入虚拟机页面。&lt;/li>
&lt;li>单击虚拟机右侧操作列 &lt;strong>&lt;em>&amp;ldquo;更多&amp;rdquo;&lt;/em>&lt;/strong> 按钮，选择下拉菜单 &lt;strong>&lt;em>&amp;ldquo;实例设置-设置USB透传&amp;rdquo;&lt;/em>&lt;/strong> 菜单项，弹出设置USB透传对话框。&lt;/li>
&lt;li>配置以下参数：
&lt;ul>
&lt;li>是否绑定：选择绑定USB透传设备。&lt;/li>
&lt;li>USB设备：当启用绑定USB透传设备后，显示该项，并选择具体的透传设备。&lt;/li>
&lt;li>自动启动：挂载USB设备成功后虚拟机是否自动启动，仅虚拟机关机状态下生效。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>单击 &lt;strong>&lt;em>&amp;ldquo;确定&amp;rdquo;&lt;/em>&lt;/strong> 按钮，挂载或取消挂载USB透传设备。&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>在透传设备页面关联虚拟机&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>在透传设备页面，单击USB类型透传设备右侧操作列 &lt;strong>&lt;em>&amp;ldquo;关联虚拟机&amp;rdquo;&lt;/em>&lt;/strong> 按钮，弹出关联虚拟机对话框。&lt;/li>
&lt;li>配置以下参数：
&lt;ul>
&lt;li>选择虚拟机：选择需要关联透传设备的虚拟机。&lt;/li>
&lt;li>自动启动：挂载USB设备成功后虚拟机是否自动启动，仅虚拟机关机状态下生效。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>单击 &lt;strong>&lt;em>&amp;ldquo;确定&amp;rdquo;&lt;/em>&lt;/strong> 按钮，为USB透传设备关联虚拟机。&lt;/li>
&lt;/ol>
&lt;h3 id="climc命令行挂载usb设备">Climc命令行挂载USB设备&lt;/h3>
&lt;p>对应命令行操作如下 &lt;code>climc server-attach-isolated-device $server_id $device_id&lt;/code>：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#8f5902;font-style:italic"># 比如虚拟机名称为 testvm，透传设备 id 为 a3fa9bd4-236c-4c5b-8056-f7afa807138d&lt;/span>
$ climc server-attach-isolated-device testvm a3fa9bd4-236c-4c5b-8056-f7afa807138d
&lt;span style="color:#8f5902;font-style:italic"># 然后登录到 testvm 虚拟机里面，执行 lsusb 就能看到宿主机的 USB 设备&lt;/span>
&lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>root@testvm ~&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>&lt;span style="color:#8f5902;font-style:italic"># lsusb&lt;/span>
Bus &lt;span style="color:#0000cf;font-weight:bold">002&lt;/span> Device 002: ID 0951:1666 Kingston Technology DataTraveler &lt;span style="color:#0000cf;font-weight:bold">100&lt;/span> G3/G4/SE9 G2/50
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="虚拟机卸载-usb">虚拟机卸载 USB&lt;/h2>
&lt;p>USB 可以在虚拟机运行状态下卸载 USB ，可以在前端的透传设备列表那里卸载 USB 对应的虚拟机。&lt;/p>
&lt;h3 id="web界面卸载usb">web界面卸载USB&lt;/h3>
&lt;p>&lt;strong>在虚拟机页面卸载USB透传设备&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>在左侧导航栏，选择 &lt;strong>&lt;em>&amp;ldquo;主机/主机/虚拟机&amp;rdquo;&lt;/em>&lt;/strong> 菜单项，进入虚拟机页面。&lt;/li>
&lt;li>单击虚拟机右侧操作列 &lt;strong>&lt;em>&amp;ldquo;更多&amp;rdquo;&lt;/em>&lt;/strong> 按钮，选择下拉菜单 &lt;strong>&lt;em>&amp;ldquo;实例设置-设置USB透传&amp;rdquo;&lt;/em>&lt;/strong> 菜单项，弹出设置USB透传对话框。&lt;/li>
&lt;li>配置以下参数：
&lt;ul>
&lt;li>是否绑定：关闭绑定USB透传设备。&lt;/li>
&lt;li>自动启动：挂载USB设备成功后虚拟机是否自动启动，仅虚拟机关机状态下生效。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>单击 &lt;strong>&lt;em>&amp;ldquo;确定&amp;rdquo;&lt;/em>&lt;/strong> 按钮，挂载或取消挂载USB透传设备。&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>在透传设备页面取消关联虚拟机&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>在透传设备页面，单击USB类型透传设备右侧操作列 &lt;strong>&lt;em>&amp;ldquo;取消关联虚拟机&amp;rdquo;&lt;/em>&lt;/strong> 按钮，弹出关联虚拟机对话框。&lt;/li>
&lt;li>配置以下参数：
&lt;ul>
&lt;li>自动启动：卸载USB设备成功后虚拟机是否自动启动，仅虚拟机关机状态下生效。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>单击 &lt;strong>&lt;em>&amp;ldquo;确定&amp;rdquo;&lt;/em>&lt;/strong> 按钮，USB透传设备取消关联虚拟机。&lt;/li>
&lt;/ol>
&lt;h3 id="climc命令卸载usb">Climc命令卸载USB&lt;/h3>
&lt;p>对应命令行操作如下 &lt;code>climc server-detach-isolated-device $server_id $device_id&lt;/code>：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#8f5902;font-style:italic"># 比如虚拟机名称为 testvm，透传设备 id 为 a3fa9bd4-236c-4c5b-8056-f7afa807138d&lt;/span>
$ climc server-detach-isolated-device testvm a3fa9bd4-236c-4c5b-8056-f7afa807138d
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="宿主机刷新设备">宿主机刷新设备&lt;/h2>
&lt;p>有些情况会频繁在宿主机上插拔 USB 设备，这样会导致云平台记录的 USB 设备信息和宿主机上的实际设备信息不一致，可以使用下面的命令 &lt;code>climc host-probe-isolated-devices $host_id&lt;/code> 进行设备信息同步：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#8f5902;font-style:italic"># 假设宿主机名称为 oc-node-1-192-168-121-21，看下目前的设备列表&lt;/span>
$ lsusb
Bus &lt;span style="color:#0000cf;font-weight:bold">002&lt;/span> Device 002: ID 0951:1666 Kingston Technology DataTraveler &lt;span style="color:#0000cf;font-weight:bold">100&lt;/span> G3/G4/SE9 G2/50
Bus &lt;span style="color:#0000cf;font-weight:bold">001&lt;/span> Device 002: ID 0627:0001 Adomax Technology Co., Ltd
&lt;span style="color:#8f5902;font-style:italic"># 对应云平台的设备列表是一致的&lt;/span>
$ climc isolated-device-list --host oc-node-1-192-168-121-21
+--------------------------------------+----------+------------------------------------------------------+---------+------------------+--------------------------------------+
&lt;span style="color:#000;font-weight:bold">|&lt;/span> ID &lt;span style="color:#000;font-weight:bold">|&lt;/span> Dev_type &lt;span style="color:#000;font-weight:bold">|&lt;/span> Model &lt;span style="color:#000;font-weight:bold">|&lt;/span> Addr &lt;span style="color:#000;font-weight:bold">|&lt;/span> Vendor_device_id &lt;span style="color:#000;font-weight:bold">|&lt;/span> Host_id &lt;span style="color:#000;font-weight:bold">|&lt;/span>
+--------------------------------------+----------+------------------------------------------------------+---------+------------------+--------------------------------------+
&lt;span style="color:#000;font-weight:bold">|&lt;/span> 1541047f-0203-488a-8226-2de740da061f &lt;span style="color:#000;font-weight:bold">|&lt;/span> USB &lt;span style="color:#000;font-weight:bold">|&lt;/span> Adomax Technology Co., Ltd &lt;span style="color:#000;font-weight:bold">|&lt;/span> 001:002 &lt;span style="color:#000;font-weight:bold">|&lt;/span> 0627:0001 &lt;span style="color:#000;font-weight:bold">|&lt;/span> 7a11731f-dcc0-41e5-8d64-68eb36defcbe &lt;span style="color:#000;font-weight:bold">|&lt;/span>
&lt;span style="color:#000;font-weight:bold">|&lt;/span> a3fa9bd4-236c-4c5b-8056-f7afa807138d &lt;span style="color:#000;font-weight:bold">|&lt;/span> USB &lt;span style="color:#000;font-weight:bold">|&lt;/span> Kingston Technology DataTraveler &lt;span style="color:#0000cf;font-weight:bold">100&lt;/span> G3/G4/SE9 G2/50 &lt;span style="color:#000;font-weight:bold">|&lt;/span> 002:002 &lt;span style="color:#000;font-weight:bold">|&lt;/span> 0951:1666 &lt;span style="color:#000;font-weight:bold">|&lt;/span> 7a11731f-dcc0-41e5-8d64-68eb36defcbe &lt;span style="color:#000;font-weight:bold">|&lt;/span>
+--------------------------------------+----------+------------------------------------------------------+---------+------------------+--------------------------------------+
*** Total: &lt;span style="color:#0000cf;font-weight:bold">2&lt;/span> Pages: &lt;span style="color:#0000cf;font-weight:bold">1&lt;/span> Limit: &lt;span style="color:#0000cf;font-weight:bold">20&lt;/span> Offset: &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> Page: &lt;span style="color:#0000cf;font-weight:bold">1&lt;/span> ***
&lt;span style="color:#8f5902;font-style:italic"># 从上面看到有两个 USB 设备列表，然后我把 Kingston U 盘拔掉&lt;/span>
$ lsusb
Bus &lt;span style="color:#0000cf;font-weight:bold">001&lt;/span> Device 002: ID 0627:0001 Adomax Technology Co., Ltd
&lt;span style="color:#8f5902;font-style:italic"># 执行命令同步当前宿主机设备信息&lt;/span>
$ climc host-probe-isolated-devices oc-node-1-192-168-121-21
&lt;span style="color:#8f5902;font-style:italic"># 再查看设备列表就只有一个了，Kingston U 盘记录已经被删掉&lt;/span>
$ climc isolated-device-list --host oc-node-1-192-168-121-21
+--------------------------------------+----------+----------------------------+---------+------------------+--------------------------------------+
&lt;span style="color:#000;font-weight:bold">|&lt;/span> ID &lt;span style="color:#000;font-weight:bold">|&lt;/span> Dev_type &lt;span style="color:#000;font-weight:bold">|&lt;/span> Model &lt;span style="color:#000;font-weight:bold">|&lt;/span> Addr &lt;span style="color:#000;font-weight:bold">|&lt;/span> Vendor_device_id &lt;span style="color:#000;font-weight:bold">|&lt;/span> Host_id &lt;span style="color:#000;font-weight:bold">|&lt;/span>
+--------------------------------------+----------+----------------------------+---------+------------------+--------------------------------------+
&lt;span style="color:#000;font-weight:bold">|&lt;/span> fa3cdbbd-7c54-4d2a-87cd-9362aa590a7d &lt;span style="color:#000;font-weight:bold">|&lt;/span> USB &lt;span style="color:#000;font-weight:bold">|&lt;/span> Adomax Technology Co., Ltd &lt;span style="color:#000;font-weight:bold">|&lt;/span> 001:002 &lt;span style="color:#000;font-weight:bold">|&lt;/span> 0627:0001 &lt;span style="color:#000;font-weight:bold">|&lt;/span> 7a11731f-dcc0-41e5-8d64-68eb36defcbe &lt;span style="color:#000;font-weight:bold">|&lt;/span>
+--------------------------------------+----------+----------------------------+---------+------------------+--------------------------------------+
*** Total: &lt;span style="color:#0000cf;font-weight:bold">1&lt;/span> Pages: &lt;span style="color:#0000cf;font-weight:bold">1&lt;/span> Limit: &lt;span style="color:#0000cf;font-weight:bold">20&lt;/span> Offset: &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> Page: &lt;span style="color:#0000cf;font-weight:bold">1&lt;/span> ***
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="webui动态刷新usb设备">WebUI动态刷新USB设备&lt;/h3>
&lt;p>为了方便用户使用，WebUI会在以下场景自动刷新指定宿主机的透传USB设备列表：&lt;/p>
&lt;ol>
&lt;li>访问宿主机-详情-透传设备，会自动刷新指定宿主机的透传设备&lt;/li>
&lt;li>访问虚拟机-设置USB透传&lt;/li>
&lt;/ol>
&lt;h2 id="指定usb控制器">指定USB控制器&lt;/h2>
&lt;p>默认采用qemu-xhci的USB控制器，该控制器支持版本为USB 3.0，向下兼容2.0。对于老版本的操作系统，例如 Windows Server 2008 R2，不识别USB 3.0的控制器，此时需要改为USB 2.0的控制器 usb-ehci。可以通过一下climc命令行更改虚拟机使用的USB控制器：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">climc server-set-qemu-params &amp;lt;sid&amp;gt; --usb-controller-type &amp;lt;usb-ehci&lt;span style="color:#000;font-weight:bold">|&lt;/span>qemu-xhci&amp;gt;
&lt;/code>&lt;/pre>&lt;/div>&lt;p>更改后，请请重启虚拟机。&lt;/p></description></item><item><title>Docs: 串口COM透传</title><link>https://www.cloudpods.org/zh/docs/function_principle/onpremise/vminstance/passthrough/com-passthrough/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.cloudpods.org/zh/docs/function_principle/onpremise/vminstance/passthrough/com-passthrough/</guid><description>
&lt;p>本文介绍如何将宿主机的串口（COM）透传到虚拟机内使用。&lt;/p>
&lt;h2 id="配置宿主机">配置宿主机&lt;/h2>
&lt;p>查看宿主机上的 COM 设备，采用命令 setserial 查看：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#8f5902;font-style:italic"># 查看板载串口设备&lt;/span>
$ sudo setserial -g /dev/ttyS&lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>0123&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>
/dev/ttyS0, UART: 16550A, Port: 0x03f8, IRQ: &lt;span style="color:#0000cf;font-weight:bold">4&lt;/span>
/dev/ttyS1, UART: 16550A, Port: 0x1020, IRQ: &lt;span style="color:#0000cf;font-weight:bold">18&lt;/span>
/dev/ttyS2, UART: unknown, Port: 0x03e8, IRQ: &lt;span style="color:#0000cf;font-weight:bold">4&lt;/span>
/dev/ttyS3, UART: unknown, Port: 0x02e8, IRQ: &lt;span style="color:#0000cf;font-weight:bold">3&lt;/span>
&lt;span style="color:#8f5902;font-style:italic"># 查看USB串口&lt;/span>
$ sudo setserial -g /dev/ttyUSB&lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>01&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>
/dev/ttyUSB0, UART: unknown, Port: 0x0000, IRQ: &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>找到宿主机上待透传的串口设备路径，例如 /dev/ttyUSB0&lt;/p>
&lt;p>在QEMU增加如下命令行参数将该串口设备传入虚拟机：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">-chardev tty,path&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>/dev/ttyUSB0,id&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>hostusbserial
-device pci-serial,chardev&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>hostusbserial
&lt;/code>&lt;/pre>&lt;/div>&lt;p>通过如下climc命令为指定宿主机设置以上命令行参数：&lt;/p>
&lt;pre>&lt;code>climc server-add-extra-options &amp;lt;sid&amp;gt; chardev tty,path=/dev/ttyUSB0,id=hostusbserial
climc server-add-extra-options &amp;lt;sid&amp;gt; device pci-serial,chardev=hostusbserial
&lt;/code>&lt;/pre>&lt;p>重启该虚拟机，在虚拟机详情页面查看命令行参数中是否增加了以上参数。&lt;/p></description></item></channel></rss>